{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N-FPN-Rock-Paper-Scissors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlz2gGuNyNmQ"
      },
      "source": [
        "# N-FPN Rock Paper Scissors Toy Problem\n",
        "\n",
        "We perform a rock-paper-scissors experiment. Each player's actions are restricted to the unit simplex $\\Delta^3 \\triangleq \\{ x \\in \\mathbb{R}^{3}_{\\geq0} : \\|x\\|_1 = 1\\} \\subset\\mathbb{R}^3$ so that  $\\mathcal{C} = \\Delta^3 \\times \\Delta^3$ and actions  $x_i$ are interpreted as probability distributions over  three choices: rock, paper and scissors. \n",
        "Equilibria $x_d^\\star$ are VI solutions, _i.e._\n",
        "\n",
        "$$ \\left< F(x_d^\\star;d), x - x_d^\\star\\right> \\geq 0,\\quad \\mbox{for all $x\\in \\mathcal{C}$},$$\n",
        "\n",
        "using the game gradient \n",
        "\n",
        "$$F = [\\nabla_{x_1} u_k(x;d)^\\top, \\ \\nabla_{x_2} u_k(x;d)^\\top ]^\\top $$\n",
        "\n",
        "with    cost functions given by \n",
        "$$\n",
        "    u_1(x;d) \\triangleq \\left< x_1, B(d)x_2\\right>\n",
        "    \\quad \\mbox{and}\\quad \n",
        "    u_2(x;d) \\triangleq -\\left< x_1, B(d) x_2\\right>.\n",
        "$$\n",
        "where the antisymmetric payoff matrix $B(d) \\in \\mathbb{R}^{3\\times 3}$  is defined in the paper is used to define the players' cost functions and each vectors $w^i \\in \\mathbb{R}^{3}$ is drawn uniformly in $[0,1]^3$ for $i \\in [3]$. \n",
        "Contextual data $d$ are drawn from a distribution $\\mathcal{D}$ that is uniform over $[0,1]^3$. An N-FPN is trained to predict $x_d^\\star$ from $d$ using  training data   context-action pairs $\\{(d^i,x_{d^i}^\\star)\\}_{i=1}^{1000}$, without using knowledge of $F$. The learned $F_{\\Theta}$ has two fully connected layers with a leaky ReLU activation, and forward propagation uses projected gradient. This notebook generates data for two plots. The first plot shows convergence of the test loss while training the N-FPN.\n",
        "The final plot simulates play between an optimal Nash player with access to $u_1(\\cdot,d)$ and an N-FPN player that only has access to $d$ and training data.\n",
        "The final plot measures performance using \n",
        "\\begin{equation}\n",
        "    \\mbox{(Expected Nash Player $k$-Game Cost Variance)} \\equiv y^k \\triangleq \\mathbb{E}_{d\\sim\\mathcal{D}}\\left[\\left(\\dfrac{1}{k} \\sum_{\\ell=1}^k  u_1^2\\Big(s^\\ell; d \\Big) \\right)^{1/2}\\right],\n",
        "\\end{equation}\n",
        "where $s$ is a tuple of two one-hot vectors $s_1^k \\sim x_d^\\star$ and $s_2^k \\sim \\mathcal{N}_\\Theta(d)$.\n",
        "Because rock-paper-scissors is a zero-sum game, if the N-FPN plays optimally, then the average reward of the Nash player converges to zero as the number of games increases.\n",
        "That is, optimal $\\mathcal{N}_\\Theta$ yields $y^k\\rightarrow 0$, as shown in the final plot of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH3IyNVIGLIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb02e146-89f6-4970-efac-d1e1e5ecf9c1"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn               as nn\n",
        "import torch.optim            as optim\n",
        "import numpy                  as np\n",
        "import matplotlib.pyplot      as plt\n",
        "from torch.utils.data         import Dataset, TensorDataset, DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "context       = torch.tensor\n",
        "action        = torch.tensor\n",
        "weight_matrix = torch.tensor\n",
        "payoff_matrix = torch.tensor\n",
        "\n",
        "seed = 30\n",
        "torch.manual_seed(seed)\n",
        "W = torch.rand(3, 3) * torch.tensor([0.5, 10, 20])\n",
        "W = W.permute(1,0)\n",
        "print(W)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4504,  0.4369,  0.4473],\n",
            "        [ 7.4636,  7.4026,  6.2383],\n",
            "        [ 9.4323, 15.6801,  8.5520]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCUBjVzaAwPi"
      },
      "source": [
        "## Generate Synthetic Training Data\n",
        "\n",
        "\n",
        "Notes: \n",
        "\n",
        "1) The analytic solutions are generated using the Extra Gradient Scheme as in (1.2) and (1.3) of this [paper](http://math.haifa.ac.il/agibali/Web/Extensions%20of%20Korpelevich's%20extragradient%20method%20for%20the%20variational%20inequality%20problem%20in%20Euclidean%20space.pdf).\n",
        "\n",
        "2) The simplex projection is performed using Algorithm 1 in this [paper](https://arxiv.org/pdf/1309.1541.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scj-uG9SwKQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a24ee1-574f-44d0-f1c7-385888007b83"
      },
      "source": [
        "def sample_context(num_samples: int) -> context:\n",
        "    return torch.rand(num_samples, 3) \n",
        "\n",
        "\n",
        "def project_simplex(y: action, action_size=3, num_players=2) -> action:\n",
        "    num_samples = y.shape[0] \n",
        "    proj        = torch.zeros(y.shape)\n",
        "    for i in range(num_players):\n",
        "        ind   = [i * action_size + j for j in range(action_size)]\n",
        "        u     = torch.flip(torch.sort(y[:, ind], dim=1)[0], dims=(1,))\n",
        "        u_sum = torch.cumsum(u, dim=1)\n",
        "        j     = torch.arange(1, action_size + 1, dtype=y.dtype, device=y.device)\n",
        "        pos_u_expr   = u * j + 1.0 - u_sum  > 0 \n",
        "        pos_u_expr   = pos_u_expr.float() \n",
        "        rho          = torch.sum(pos_u_expr, dim=1, keepdim=True)\n",
        "        rho          = rho.long()\n",
        "        lambd        = [(1 - u_sum[sample, rho[sample]-1]) / rho[sample] \n",
        "                        for sample in range(num_samples)]\n",
        "        lambd        = torch.tensor(lambd)\n",
        "        lambd        = lambd.view(lambd.shape[0], 1)\n",
        "        proj[:, ind] = torch.clamp(y[:, ind] + lambd, min=0)\n",
        "    return proj\n",
        "\n",
        "\n",
        "def create_payoff_matrix(d: context) -> payoff_matrix:\n",
        "    num_samples = d.shape[0] \n",
        "    action_size = d.shape[1]\n",
        "    Wd          = d.mm(W.permute(1,0)) \n",
        "    B           = torch.zeros(num_samples, action_size, action_size)\n",
        "    B[:,0,1]    = -Wd[:, 0]\n",
        "    B[:,0,2]    =  Wd[:, 1]\n",
        "    B[:,1,2]    = -Wd[:, 2]\n",
        "    B          -= B.permute(0, 2, 1)\n",
        "    return B\n",
        "\n",
        "\n",
        "def F(x: action, d: context, player_size=3) -> action:\n",
        "    B    = create_payoff_matrix(d) \n",
        "    x    = x.view(x.shape[0], x.shape[1], 1)\n",
        "    Fx_1 = B.bmm(x[:, player_size:, :])\n",
        "    Bt   = B.permute(0, 2, 1)\n",
        "    Fx_2 = -Bt.bmm(x[:, :player_size, :])\n",
        "    Fx   = torch.cat((Fx_1, Fx_2), dim=1)\n",
        "    return Fx.view(Fx.shape[0], Fx.shape[1])\n",
        "\n",
        "\n",
        "def get_nash_eq(d: context, fxd_pt_tol=1e-5, max_iter=10000, step_size=5e-3,\n",
        "                action_size=6, debug_mode=False) -> action:\n",
        "    num_samples = d.shape[0]\n",
        "    x           = torch.rand(num_samples, action_size)\n",
        "    conv        = False\n",
        "    step        = 0\n",
        "    while not conv and step < max_iter:\n",
        "        x_prev = x.clone()\n",
        "        y      = project_simplex(x - step_size * F(x, d))\n",
        "        x      = project_simplex(x - step_size * F(y, d))\n",
        "        res    = torch.max(torch.norm(x - x_prev, dim=1)) \n",
        "        step  += 1\n",
        "        conv   = res < fxd_pt_tol \n",
        "        if step % 5 == 0 and debug_mode:\n",
        "            fmt_str = \"Step {:5d}: |xk - xk_prev| = {:2.2e}   x[0,:] = \"\n",
        "            print(fmt_str.format(step, res) + str(x[0,:]))\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_data(train_batch_size=200, test_batch_size=100, \n",
        "                train_size=1000,  test_size=100): \n",
        "    d_context = sample_context(train_size + test_size)\n",
        "    x_true    = get_nash_eq(d_context, debug_mode=True)\n",
        "    dataset   = TensorDataset(x_true, d_context)  \n",
        "\n",
        "    train_dataset, test_dataset = random_split(dataset, \n",
        "                                               [train_size, test_size]) \n",
        "    train_loader  = DataLoader(dataset=train_dataset,  \n",
        "                               batch_size=train_batch_size, shuffle=True) \n",
        "    test_loader   = DataLoader(dataset=test_dataset,   \n",
        "                               batch_size=test_batch_size,  shuffle=False) \n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "if not 'train_loader' in globals():\n",
        "    train_loader, test_loader = create_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step     5: |xk - xk_prev| = 1.48e-01   x[0,:] = tensor([0.4481, 0.4214, 0.1305, 0.0943, 0.8389, 0.0668])\n",
            "Step    10: |xk - xk_prev| = 1.34e-01   x[0,:] = tensor([0.5126, 0.4874, 0.0000, 0.1333, 0.8667, 0.0000])\n",
            "Step    15: |xk - xk_prev| = 1.08e-01   x[0,:] = tensor([0.5249, 0.4751, 0.0000, 0.1456, 0.8544, 0.0000])\n",
            "Step    20: |xk - xk_prev| = 8.69e-02   x[0,:] = tensor([0.5371, 0.4629, 0.0000, 0.1579, 0.8421, 0.0000])\n",
            "Step    25: |xk - xk_prev| = 6.22e-02   x[0,:] = tensor([0.5494, 0.4506, 0.0000, 0.1701, 0.8299, 0.0000])\n",
            "Step    30: |xk - xk_prev| = 5.13e-02   x[0,:] = tensor([0.5617, 0.4383, 0.0000, 0.1824, 0.8176, 0.0000])\n",
            "Step    35: |xk - xk_prev| = 4.67e-02   x[0,:] = tensor([0.5739, 0.4261, 0.0000, 0.1947, 0.8053, 0.0000])\n",
            "Step    40: |xk - xk_prev| = 4.13e-02   x[0,:] = tensor([0.5862, 0.4138, 0.0000, 0.2069, 0.7931, 0.0000])\n",
            "Step    45: |xk - xk_prev| = 3.42e-02   x[0,:] = tensor([0.5985, 0.4015, 0.0000, 0.2192, 0.7808, 0.0000])\n",
            "Step    50: |xk - xk_prev| = 3.09e-02   x[0,:] = tensor([0.6107, 0.3893, 0.0000, 0.2315, 0.7685, 0.0000])\n",
            "Step    55: |xk - xk_prev| = 2.46e-02   x[0,:] = tensor([0.6221, 0.3779, 0.0000, 0.2415, 0.7540, 0.0045])\n",
            "Step    60: |xk - xk_prev| = 2.19e-02   x[0,:] = tensor([0.6290, 0.3710, 0.0000, 0.2484, 0.7364, 0.0152])\n",
            "Step    65: |xk - xk_prev| = 2.18e-02   x[0,:] = tensor([0.6294, 0.3706, 0.0000, 0.2542, 0.7177, 0.0281])\n",
            "Step    70: |xk - xk_prev| = 2.18e-02   x[0,:] = tensor([0.6235, 0.3765, 0.0000, 0.2613, 0.7002, 0.0386])\n",
            "Step    75: |xk - xk_prev| = 2.02e-02   x[0,:] = tensor([0.6139, 0.3861, 0.0000, 0.2712, 0.6856, 0.0432])\n",
            "Step    80: |xk - xk_prev| = 2.01e-02   x[0,:] = tensor([0.6041, 0.3959, 0.0000, 0.2847, 0.6746, 0.0407])\n",
            "Step    85: |xk - xk_prev| = 2.01e-02   x[0,:] = tensor([0.5974, 0.4026, 0.0000, 0.3011, 0.6664, 0.0325])\n",
            "Step    90: |xk - xk_prev| = 2.01e-02   x[0,:] = tensor([0.5961, 0.4039, 0.0000, 0.3187, 0.6595, 0.0218])\n",
            "Step    95: |xk - xk_prev| = 1.13e-02   x[0,:] = tensor([0.6001, 0.3999, 0.0000, 0.3356, 0.6519, 0.0125])\n",
            "Step   100: |xk - xk_prev| = 1.13e-02   x[0,:] = tensor([0.6077, 0.3923, 0.0000, 0.3503, 0.6420, 0.0076])\n",
            "Step   105: |xk - xk_prev| = 1.12e-02   x[0,:] = tensor([0.6161, 0.3839, 0.0000, 0.3621, 0.6293, 0.0086])\n",
            "Step   110: |xk - xk_prev| = 1.12e-02   x[0,:] = tensor([0.6222, 0.3778, 0.0000, 0.3713, 0.6140, 0.0147])\n",
            "Step   115: |xk - xk_prev| = 1.03e-02   x[0,:] = tensor([0.6242, 0.3758, 0.0000, 0.3793, 0.5973, 0.0234])\n",
            "Step   120: |xk - xk_prev| = 1.03e-02   x[0,:] = tensor([0.6217, 0.3783, 0.0000, 0.3874, 0.5810, 0.0316])\n",
            "Step   125: |xk - xk_prev| = 1.03e-02   x[0,:] = tensor([0.6157, 0.3843, 0.0000, 0.3972, 0.5663, 0.0365])\n",
            "Step   130: |xk - xk_prev| = 1.03e-02   x[0,:] = tensor([0.6087, 0.3913, 0.0000, 0.4095, 0.5539, 0.0366])\n",
            "Step   135: |xk - xk_prev| = 1.03e-02   x[0,:] = tensor([0.6031, 0.3969, 0.0000, 0.4239, 0.5439, 0.0322])\n",
            "Step   140: |xk - xk_prev| = 1.03e-02   x[0,:] = tensor([0.6007, 0.3993, 0.0000, 0.4397, 0.5351, 0.0252])\n",
            "Step   145: |xk - xk_prev| = 5.83e-03   x[0,:] = tensor([0.6022, 0.3978, 0.0000, 0.4555, 0.5264, 0.0181])\n",
            "Step   150: |xk - xk_prev| = 5.83e-03   x[0,:] = tensor([0.6067, 0.3933, 0.0000, 0.4701, 0.5165, 0.0134])\n",
            "Step   155: |xk - xk_prev| = 5.83e-03   x[0,:] = tensor([0.6125, 0.3875, 0.0000, 0.4828, 0.5046, 0.0125])\n",
            "Step   160: |xk - xk_prev| = 5.83e-03   x[0,:] = tensor([0.6176, 0.3824, 0.0000, 0.4936, 0.4909, 0.0156])\n",
            "Step   165: |xk - xk_prev| = 5.83e-03   x[0,:] = tensor([0.6201, 0.3799, 0.0000, 0.5031, 0.4758, 0.0211])\n",
            "Step   170: |xk - xk_prev| = 5.83e-03   x[0,:] = tensor([0.6195, 0.3805, 0.0000, 0.5123, 0.4605, 0.0272])\n",
            "Step   175: |xk - xk_prev| = 5.83e-03   x[0,:] = tensor([0.6161, 0.3839, 0.0000, 0.5224, 0.4460, 0.0316])\n",
            "Step   180: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.6113, 0.3887, 0.0000, 0.5340, 0.4331, 0.0329])\n",
            "Step   185: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.6069, 0.3931, 0.0000, 0.5472, 0.4218, 0.0310])\n",
            "Step   190: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.6043, 0.3957, 0.0000, 0.5617, 0.4117, 0.0266])\n",
            "Step   195: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.6044, 0.3956, 0.0000, 0.5765, 0.4020, 0.0215])\n",
            "Step   200: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.6068, 0.3932, 0.0000, 0.5908, 0.3917, 0.0175])\n",
            "Step   205: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([6.1064e-01, 3.8931e-01, 5.3708e-05, 6.0385e-01, 3.8030e-01, 1.5853e-02])\n",
            "Step   210: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.6119, 0.3829, 0.0052, 0.6144, 0.3686, 0.0170])\n",
            "Step   215: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.6089, 0.3748, 0.0163, 0.6191, 0.3605, 0.0203])\n",
            "Step   220: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.6028, 0.3680, 0.0292, 0.6168, 0.3586, 0.0246])\n",
            "Step   225: |xk - xk_prev| = 5.82e-03   x[0,:] = tensor([0.5961, 0.3647, 0.0392, 0.6087, 0.3631, 0.0282])\n",
            "Step   230: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.5910, 0.3658, 0.0432, 0.5980, 0.3720, 0.0300])\n",
            "Step   235: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.5892, 0.3706, 0.0402, 0.5886, 0.3819, 0.0295])\n",
            "Step   240: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.5912, 0.3772, 0.0317, 0.5836, 0.3894, 0.0270])\n",
            "Step   245: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.5958, 0.3832, 0.0209, 0.5845, 0.3920, 0.0235])\n",
            "Step   250: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.6015, 0.3866, 0.0119, 0.5905, 0.3892, 0.0203])\n",
            "Step   255: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.6061, 0.3864, 0.0075, 0.5992, 0.3823, 0.0185])\n",
            "Step   260: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.6081, 0.3829, 0.0089, 0.6075, 0.3740, 0.0185])\n",
            "Step   265: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.6071, 0.3775, 0.0154, 0.6124, 0.3672, 0.0204])\n",
            "Step   270: |xk - xk_prev| = 5.81e-03   x[0,:] = tensor([0.6035, 0.3723, 0.0242, 0.6126, 0.3642, 0.0232])\n",
            "Step   275: |xk - xk_prev| = 3.72e-03   x[0,:] = tensor([0.5989, 0.3689, 0.0322, 0.6083, 0.3657, 0.0260])\n",
            "Step   280: |xk - xk_prev| = 3.68e-03   x[0,:] = tensor([0.5948, 0.3685, 0.0367, 0.6013, 0.3710, 0.0277])\n",
            "Step   285: |xk - xk_prev| = 3.64e-03   x[0,:] = tensor([0.5926, 0.3710, 0.0364, 0.5942, 0.3779, 0.0280])\n",
            "Step   290: |xk - xk_prev| = 3.59e-03   x[0,:] = tensor([0.5930, 0.3753, 0.0317, 0.5894, 0.3839, 0.0267])\n",
            "Step   295: |xk - xk_prev| = 3.52e-03   x[0,:] = tensor([0.5956, 0.3798, 0.0245, 0.5885, 0.3871, 0.0244])\n",
            "Step   300: |xk - xk_prev| = 3.46e-03   x[0,:] = tensor([0.5994, 0.3830, 0.0176, 0.5914, 0.3865, 0.0221])\n",
            "Step   305: |xk - xk_prev| = 3.43e-03   x[0,:] = tensor([0.6030, 0.3838, 0.0132, 0.5970, 0.3826, 0.0204])\n",
            "Step   310: |xk - xk_prev| = 3.38e-03   x[0,:] = tensor([0.6052, 0.3821, 0.0126, 0.6031, 0.3770, 0.0199])\n",
            "Step   315: |xk - xk_prev| = 3.35e-03   x[0,:] = tensor([0.6053, 0.3788, 0.0160, 0.6075, 0.3717, 0.0208])\n",
            "Step   320: |xk - xk_prev| = 3.32e-03   x[0,:] = tensor([0.6034, 0.3750, 0.0217, 0.6089, 0.3685, 0.0225])\n",
            "Step   325: |xk - xk_prev| = 3.29e-03   x[0,:] = tensor([0.6003, 0.3720, 0.0277, 0.6070, 0.3684, 0.0246])\n",
            "Step   330: |xk - xk_prev| = 3.27e-03   x[0,:] = tensor([0.5972, 0.3710, 0.0318, 0.6027, 0.3712, 0.0261])\n",
            "Step   335: |xk - xk_prev| = 3.24e-03   x[0,:] = tensor([0.5951, 0.3720, 0.0329, 0.5976, 0.3757, 0.0267])\n",
            "Step   340: |xk - xk_prev| = 3.22e-03   x[0,:] = tensor([0.5947, 0.3746, 0.0307, 0.5935, 0.3803, 0.0262])\n",
            "Step   345: |xk - xk_prev| = 3.18e-03   x[0,:] = tensor([0.5960, 0.3778, 0.0262, 0.5918, 0.3834, 0.0248])\n",
            "Step   350: |xk - xk_prev| = 3.12e-03   x[0,:] = tensor([0.5985, 0.3804, 0.0211, 0.5929, 0.3840, 0.0231])\n",
            "Step   355: |xk - xk_prev| = 3.06e-03   x[0,:] = tensor([0.6011, 0.3816, 0.0172, 0.5962, 0.3820, 0.0217])\n",
            "Step   360: |xk - xk_prev| = 3.00e-03   x[0,:] = tensor([0.6031, 0.3811, 0.0158, 0.6005, 0.3785, 0.0211])\n",
            "Step   365: |xk - xk_prev| = 2.94e-03   x[0,:] = tensor([0.6037, 0.3791, 0.0172, 0.6041, 0.3745, 0.0213])\n",
            "Step   370: |xk - xk_prev| = 2.89e-03   x[0,:] = tensor([0.6028, 0.3765, 0.0207, 0.6059, 0.3717, 0.0224])\n",
            "Step   375: |xk - xk_prev| = 2.85e-03   x[0,:] = tensor([0.6009, 0.3741, 0.0249, 0.6055, 0.3708, 0.0238])\n",
            "Step   380: |xk - xk_prev| = 2.81e-03   x[0,:] = tensor([0.5987, 0.3729, 0.0284, 0.6030, 0.3720, 0.0250])\n",
            "Step   385: |xk - xk_prev| = 2.77e-03   x[0,:] = tensor([0.5969, 0.3730, 0.0300, 0.5995, 0.3748, 0.0257])\n",
            "Step   390: |xk - xk_prev| = 2.73e-03   x[0,:] = tensor([0.5962, 0.3745, 0.0293, 0.5963, 0.3781, 0.0256])\n",
            "Step   395: |xk - xk_prev| = 2.72e-03   x[0,:] = tensor([0.5967, 0.3767, 0.0267, 0.5944, 0.3807, 0.0248])\n",
            "Step   400: |xk - xk_prev| = 2.69e-03   x[0,:] = tensor([0.5981, 0.3787, 0.0232, 0.5945, 0.3818, 0.0237])\n",
            "Step   405: |xk - xk_prev| = 2.67e-03   x[0,:] = tensor([0.6000, 0.3800, 0.0201, 0.5963, 0.3811, 0.0226])\n",
            "Step   410: |xk - xk_prev| = 2.66e-03   x[0,:] = tensor([0.6016, 0.3800, 0.0184, 0.5991, 0.3790, 0.0220])\n",
            "Step   415: |xk - xk_prev| = 2.64e-03   x[0,:] = tensor([0.6024, 0.3790, 0.0186, 0.6019, 0.3762, 0.0219])\n",
            "Step   420: |xk - xk_prev| = 2.63e-03   x[0,:] = tensor([0.6021, 0.3773, 0.0206, 0.6037, 0.3739, 0.0224])\n",
            "Step   425: |xk - xk_prev| = 2.61e-03   x[0,:] = tensor([0.6011, 0.3755, 0.0234, 0.6039, 0.3727, 0.0234])\n",
            "Step   430: |xk - xk_prev| = 2.59e-03   x[0,:] = tensor([0.5995, 0.3743, 0.0262, 0.6027, 0.3730, 0.0243])\n",
            "Step   435: |xk - xk_prev| = 2.55e-03   x[0,:] = tensor([0.5981, 0.3740, 0.0278, 0.6005, 0.3746, 0.0249])\n",
            "Step   440: |xk - xk_prev| = 2.52e-03   x[0,:] = tensor([0.5973, 0.3748, 0.0279, 0.5981, 0.3769, 0.0251])\n",
            "Step   445: |xk - xk_prev| = 2.49e-03   x[0,:] = tensor([0.5974, 0.3761, 0.0265, 0.5964, 0.3789, 0.0247])\n",
            "Step   450: |xk - xk_prev| = 2.46e-03   x[0,:] = tensor([0.5981, 0.3776, 0.0242, 0.5959, 0.3801, 0.0240])\n",
            "Step   455: |xk - xk_prev| = 2.44e-03   x[0,:] = tensor([0.5994, 0.3787, 0.0219, 0.5967, 0.3801, 0.0232])\n",
            "Step   460: |xk - xk_prev| = 2.42e-03   x[0,:] = tensor([0.6006, 0.3791, 0.0203, 0.5985, 0.3789, 0.0226])\n",
            "Step   465: |xk - xk_prev| = 2.40e-03   x[0,:] = tensor([0.6014, 0.3787, 0.0200, 0.6005, 0.3771, 0.0224])\n",
            "Step   470: |xk - xk_prev| = 2.39e-03   x[0,:] = tensor([0.6015, 0.3776, 0.0209, 0.6021, 0.3753, 0.0226])\n",
            "Step   475: |xk - xk_prev| = 2.37e-03   x[0,:] = tensor([0.6009, 0.3763, 0.0227, 0.6027, 0.3742, 0.0232])\n",
            "Step   480: |xk - xk_prev| = 2.34e-03   x[0,:] = tensor([0.6000, 0.3753, 0.0247, 0.6022, 0.3740, 0.0238])\n",
            "Step   485: |xk - xk_prev| = 2.31e-03   x[0,:] = tensor([0.5989, 0.3749, 0.0262, 0.6008, 0.3748, 0.0244])\n",
            "Step   490: |xk - xk_prev| = 2.28e-03   x[0,:] = tensor([0.5982, 0.3751, 0.0267, 0.5991, 0.3763, 0.0246])\n",
            "Step   495: |xk - xk_prev| = 2.25e-03   x[0,:] = tensor([0.5980, 0.3759, 0.0261, 0.5977, 0.3778, 0.0245])\n",
            "Step   500: |xk - xk_prev| = 2.22e-03   x[0,:] = tensor([0.5983, 0.3770, 0.0247, 0.5970, 0.3789, 0.0241])\n",
            "Step   505: |xk - xk_prev| = 2.20e-03   x[0,:] = tensor([0.5991, 0.3779, 0.0230, 0.5973, 0.3792, 0.0235])\n",
            "Step   510: |xk - xk_prev| = 2.19e-03   x[0,:] = tensor([0.6000, 0.3784, 0.0216, 0.5983, 0.3786, 0.0230])\n",
            "Step   515: |xk - xk_prev| = 2.18e-03   x[0,:] = tensor([0.6007, 0.3783, 0.0211, 0.5997, 0.3775, 0.0228])\n",
            "Step   520: |xk - xk_prev| = 2.17e-03   x[0,:] = tensor([0.6009, 0.3777, 0.0214, 0.6009, 0.3762, 0.0228])\n",
            "Step   525: |xk - xk_prev| = 2.16e-03   x[0,:] = tensor([0.6007, 0.3768, 0.0225, 0.6016, 0.3752, 0.0232])\n",
            "Step   530: |xk - xk_prev| = 2.15e-03   x[0,:] = tensor([0.6001, 0.3760, 0.0239, 0.6016, 0.3748, 0.0236])\n",
            "Step   535: |xk - xk_prev| = 2.14e-03   x[0,:] = tensor([0.5994, 0.3755, 0.0251, 0.6008, 0.3751, 0.0240])\n",
            "Step   540: |xk - xk_prev| = 2.12e-03   x[0,:] = tensor([0.5988, 0.3755, 0.0257, 0.5997, 0.3760, 0.0243])\n",
            "Step   545: |xk - xk_prev| = 2.09e-03   x[0,:] = tensor([0.5985, 0.3760, 0.0256, 0.5986, 0.3771, 0.0243])\n",
            "Step   550: |xk - xk_prev| = 2.07e-03   x[0,:] = tensor([0.5986, 0.3767, 0.0248, 0.5979, 0.3780, 0.0241])\n",
            "Step   555: |xk - xk_prev| = 2.05e-03   x[0,:] = tensor([0.5990, 0.3774, 0.0236, 0.5979, 0.3784, 0.0237])\n",
            "Step   560: |xk - xk_prev| = 2.03e-03   x[0,:] = tensor([0.5996, 0.3778, 0.0226, 0.5984, 0.3783, 0.0233])\n",
            "Step   565: |xk - xk_prev| = 2.01e-03   x[0,:] = tensor([0.6002, 0.3779, 0.0219, 0.5993, 0.3776, 0.0231])\n",
            "Step   570: |xk - xk_prev| = 1.99e-03   x[0,:] = tensor([0.6005, 0.3776, 0.0219, 0.6002, 0.3767, 0.0230])\n",
            "Step   575: |xk - xk_prev| = 1.97e-03   x[0,:] = tensor([0.6005, 0.3770, 0.0225, 0.6009, 0.3759, 0.0232])\n",
            "Step   580: |xk - xk_prev| = 1.95e-03   x[0,:] = tensor([0.6001, 0.3764, 0.0234, 0.6010, 0.3755, 0.0235])\n",
            "Step   585: |xk - xk_prev| = 1.94e-03   x[0,:] = tensor([0.5996, 0.3760, 0.0244, 0.6007, 0.3755, 0.0238])\n",
            "Step   590: |xk - xk_prev| = 1.93e-03   x[0,:] = tensor([0.5992, 0.3759, 0.0250, 0.6000, 0.3760, 0.0240])\n",
            "Step   595: |xk - xk_prev| = 1.92e-03   x[0,:] = tensor([0.5989, 0.3761, 0.0251, 0.5992, 0.3767, 0.0241])\n",
            "Step   600: |xk - xk_prev| = 1.90e-03   x[0,:] = tensor([0.5988, 0.3765, 0.0247, 0.5986, 0.3774, 0.0240])\n",
            "Step   605: |xk - xk_prev| = 1.89e-03   x[0,:] = tensor([0.5991, 0.3770, 0.0239, 0.5984, 0.3779, 0.0238])\n",
            "Step   610: |xk - xk_prev| = 1.88e-03   x[0,:] = tensor([0.5995, 0.3774, 0.0231, 0.5986, 0.3779, 0.0235])\n",
            "Step   615: |xk - xk_prev| = 1.87e-03   x[0,:] = tensor([0.5999, 0.3776, 0.0226, 0.5991, 0.3776, 0.0233])\n",
            "Step   620: |xk - xk_prev| = 1.86e-03   x[0,:] = tensor([0.6002, 0.3774, 0.0224, 0.5998, 0.3770, 0.0232])\n",
            "Step   625: |xk - xk_prev| = 1.84e-03   x[0,:] = tensor([0.6002, 0.3771, 0.0227, 0.6003, 0.3764, 0.0233])\n",
            "Step   630: |xk - xk_prev| = 1.83e-03   x[0,:] = tensor([0.6001, 0.3767, 0.0232, 0.6006, 0.3760, 0.0234])\n",
            "Step   635: |xk - xk_prev| = 1.82e-03   x[0,:] = tensor([0.5997, 0.3764, 0.0239, 0.6005, 0.3759, 0.0237])\n",
            "Step   640: |xk - xk_prev| = 1.81e-03   x[0,:] = tensor([0.5994, 0.3762, 0.0244, 0.6000, 0.3761, 0.0239])\n",
            "Step   645: |xk - xk_prev| = 1.80e-03   x[0,:] = tensor([0.5991, 0.3762, 0.0246, 0.5995, 0.3766, 0.0239])\n",
            "Step   650: |xk - xk_prev| = 1.78e-03   x[0,:] = tensor([0.5990, 0.3765, 0.0245, 0.5990, 0.3771, 0.0239])\n",
            "Step   655: |xk - xk_prev| = 1.77e-03   x[0,:] = tensor([0.5991, 0.3768, 0.0240, 0.5988, 0.3775, 0.0238])\n",
            "Step   660: |xk - xk_prev| = 1.76e-03   x[0,:] = tensor([0.5994, 0.3771, 0.0235, 0.5988, 0.3776, 0.0236])\n",
            "Step   665: |xk - xk_prev| = 1.75e-03   x[0,:] = tensor([0.5997, 0.3773, 0.0230, 0.5991, 0.3774, 0.0234])\n",
            "Step   670: |xk - xk_prev| = 1.74e-03   x[0,:] = tensor([0.5999, 0.3773, 0.0228, 0.5996, 0.3771, 0.0233])\n",
            "Step   675: |xk - xk_prev| = 1.73e-03   x[0,:] = tensor([0.6000, 0.3771, 0.0229, 0.6000, 0.3767, 0.0234])\n",
            "Step   680: |xk - xk_prev| = 1.72e-03   x[0,:] = tensor([0.6000, 0.3768, 0.0232, 0.6002, 0.3763, 0.0234])\n",
            "Step   685: |xk - xk_prev| = 1.71e-03   x[0,:] = tensor([0.5998, 0.3766, 0.0236, 0.6003, 0.3762, 0.0236])\n",
            "Step   690: |xk - xk_prev| = 1.69e-03   x[0,:] = tensor([0.5995, 0.3764, 0.0241, 0.6000, 0.3762, 0.0237])\n",
            "Step   695: |xk - xk_prev| = 1.68e-03   x[0,:] = tensor([0.5993, 0.3764, 0.0243, 0.5997, 0.3765, 0.0238])\n",
            "Step   700: |xk - xk_prev| = 1.67e-03   x[0,:] = tensor([0.5992, 0.3765, 0.0243, 0.5993, 0.3769, 0.0238])\n",
            "Step   705: |xk - xk_prev| = 1.66e-03   x[0,:] = tensor([0.5992, 0.3767, 0.0240, 0.5991, 0.3772, 0.0238])\n",
            "Step   710: |xk - xk_prev| = 1.65e-03   x[0,:] = tensor([0.5994, 0.3770, 0.0237, 0.5990, 0.3773, 0.0237])\n",
            "Step   715: |xk - xk_prev| = 1.64e-03   x[0,:] = tensor([0.5996, 0.3771, 0.0233, 0.5992, 0.3773, 0.0235])\n",
            "Step   720: |xk - xk_prev| = 1.63e-03   x[0,:] = tensor([0.5998, 0.3772, 0.0231, 0.5994, 0.3771, 0.0234])\n",
            "Step   725: |xk - xk_prev| = 1.62e-03   x[0,:] = tensor([0.5999, 0.3771, 0.0230, 0.5998, 0.3768, 0.0234])\n",
            "Step   730: |xk - xk_prev| = 1.61e-03   x[0,:] = tensor([0.5999, 0.3769, 0.0232, 0.6000, 0.3765, 0.0235])\n",
            "Step   735: |xk - xk_prev| = 1.60e-03   x[0,:] = tensor([0.5998, 0.3767, 0.0235, 0.6001, 0.3764, 0.0236])\n",
            "Step   740: |xk - xk_prev| = 1.59e-03   x[0,:] = tensor([0.5996, 0.3766, 0.0238, 0.6000, 0.3764, 0.0237])\n",
            "Step   745: |xk - xk_prev| = 1.59e-03   x[0,:] = tensor([0.5995, 0.3765, 0.0240, 0.5997, 0.3765, 0.0237])\n",
            "Step   750: |xk - xk_prev| = 1.58e-03   x[0,:] = tensor([0.5994, 0.3766, 0.0241, 0.5995, 0.3767, 0.0238])\n",
            "Step   755: |xk - xk_prev| = 1.57e-03   x[0,:] = tensor([0.5993, 0.3767, 0.0240, 0.5993, 0.3770, 0.0237])\n",
            "Step   760: |xk - xk_prev| = 1.56e-03   x[0,:] = tensor([0.5994, 0.3769, 0.0237, 0.5992, 0.3771, 0.0237])\n",
            "Step   765: |xk - xk_prev| = 1.55e-03   x[0,:] = tensor([0.5995, 0.3770, 0.0235, 0.5992, 0.3772, 0.0236])\n",
            "Step   770: |xk - xk_prev| = 1.54e-03   x[0,:] = tensor([0.5997, 0.3771, 0.0233, 0.5994, 0.3771, 0.0235])\n",
            "Step   775: |xk - xk_prev| = 1.54e-03   x[0,:] = tensor([0.5998, 0.3770, 0.0232, 0.5996, 0.3769, 0.0235])\n",
            "Step   780: |xk - xk_prev| = 1.53e-03   x[0,:] = tensor([0.5998, 0.3769, 0.0233, 0.5998, 0.3767, 0.0235])\n",
            "Step   785: |xk - xk_prev| = 1.53e-03   x[0,:] = tensor([0.5997, 0.3768, 0.0235, 0.5999, 0.3765, 0.0236])\n",
            "Step   790: |xk - xk_prev| = 1.53e-03   x[0,:] = tensor([0.5996, 0.3767, 0.0237, 0.5999, 0.3765, 0.0236])\n",
            "Step   795: |xk - xk_prev| = 1.52e-03   x[0,:] = tensor([0.5995, 0.3766, 0.0239, 0.5998, 0.3766, 0.0237])\n",
            "Step   800: |xk - xk_prev| = 1.52e-03   x[0,:] = tensor([0.5994, 0.3766, 0.0239, 0.5996, 0.3767, 0.0237])\n",
            "Step   805: |xk - xk_prev| = 1.51e-03   x[0,:] = tensor([0.5994, 0.3767, 0.0239, 0.5994, 0.3769, 0.0237])\n",
            "Step   810: |xk - xk_prev| = 1.51e-03   x[0,:] = tensor([0.5994, 0.3768, 0.0238, 0.5993, 0.3770, 0.0237])\n",
            "Step   815: |xk - xk_prev| = 1.50e-03   x[0,:] = tensor([0.5995, 0.3769, 0.0236, 0.5993, 0.3771, 0.0236])\n",
            "Step   820: |xk - xk_prev| = 1.50e-03   x[0,:] = tensor([0.5996, 0.3770, 0.0234, 0.5994, 0.3770, 0.0236])\n",
            "Step   825: |xk - xk_prev| = 1.49e-03   x[0,:] = tensor([0.5997, 0.3770, 0.0233, 0.5996, 0.3769, 0.0235])\n",
            "Step   830: |xk - xk_prev| = 1.49e-03   x[0,:] = tensor([0.5997, 0.3769, 0.0234, 0.5997, 0.3768, 0.0235])\n",
            "Step   835: |xk - xk_prev| = 1.48e-03   x[0,:] = tensor([0.5997, 0.3768, 0.0235, 0.5998, 0.3767, 0.0236])\n",
            "Step   840: |xk - xk_prev| = 1.48e-03   x[0,:] = tensor([0.5997, 0.3767, 0.0236, 0.5998, 0.3766, 0.0236])\n",
            "Step   845: |xk - xk_prev| = 1.47e-03   x[0,:] = tensor([0.5996, 0.3767, 0.0237, 0.5997, 0.3766, 0.0236])\n",
            "Step   850: |xk - xk_prev| = 1.47e-03   x[0,:] = tensor([0.5995, 0.3767, 0.0238, 0.5996, 0.3767, 0.0237])\n",
            "Step   855: |xk - xk_prev| = 1.46e-03   x[0,:] = tensor([0.5995, 0.3767, 0.0238, 0.5995, 0.3768, 0.0237])\n",
            "Step   860: |xk - xk_prev| = 1.46e-03   x[0,:] = tensor([0.5995, 0.3768, 0.0238, 0.5994, 0.3769, 0.0237])\n",
            "Step   865: |xk - xk_prev| = 1.46e-03   x[0,:] = tensor([0.5995, 0.3768, 0.0236, 0.5994, 0.3770, 0.0236])\n",
            "Step   870: |xk - xk_prev| = 1.45e-03   x[0,:] = tensor([0.5996, 0.3769, 0.0235, 0.5994, 0.3770, 0.0236])\n",
            "Step   875: |xk - xk_prev| = 1.45e-03   x[0,:] = tensor([0.5996, 0.3769, 0.0234, 0.5995, 0.3769, 0.0236])\n",
            "Step   880: |xk - xk_prev| = 1.44e-03   x[0,:] = tensor([0.5997, 0.3769, 0.0234, 0.5996, 0.3768, 0.0236])\n",
            "Step   885: |xk - xk_prev| = 1.44e-03   x[0,:] = tensor([0.5997, 0.3768, 0.0235, 0.5997, 0.3767, 0.0236])\n",
            "Step   890: |xk - xk_prev| = 1.43e-03   x[0,:] = tensor([0.5997, 0.3768, 0.0236, 0.5997, 0.3767, 0.0236])\n",
            "Step   895: |xk - xk_prev| = 1.43e-03   x[0,:] = tensor([0.5996, 0.3767, 0.0237, 0.5997, 0.3767, 0.0236])\n",
            "Step   900: |xk - xk_prev| = 1.42e-03   x[0,:] = tensor([0.5995, 0.3767, 0.0237, 0.5996, 0.3767, 0.0237])\n",
            "Step   905: |xk - xk_prev| = 1.42e-03   x[0,:] = tensor([0.5995, 0.3767, 0.0238, 0.5996, 0.3768, 0.0237])\n",
            "Step   910: |xk - xk_prev| = 1.42e-03   x[0,:] = tensor([0.5995, 0.3768, 0.0237, 0.5995, 0.3769, 0.0237])\n",
            "Step   915: |xk - xk_prev| = 1.41e-03   x[0,:] = tensor([0.5995, 0.3768, 0.0237, 0.5995, 0.3769, 0.0236])\n",
            "Step   920: |xk - xk_prev| = 1.41e-03   x[0,:] = tensor([0.5996, 0.3769, 0.0236, 0.5995, 0.3769, 0.0236])\n",
            "Step   925: |xk - xk_prev| = 1.40e-03   x[0,:] = tensor([0.5996, 0.3769, 0.0235, 0.5995, 0.3769, 0.0236])\n",
            "Step   930: |xk - xk_prev| = 1.40e-03   x[0,:] = tensor([0.5996, 0.3769, 0.0235, 0.5996, 0.3768, 0.0236])\n",
            "Step   935: |xk - xk_prev| = 1.39e-03   x[0,:] = tensor([0.5997, 0.3768, 0.0235, 0.5997, 0.3768, 0.0236])\n",
            "Step   940: |xk - xk_prev| = 1.39e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5997, 0.3767, 0.0236])\n",
            "Step   945: |xk - xk_prev| = 1.38e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5997, 0.3767, 0.0236])\n",
            "Step   950: |xk - xk_prev| = 1.38e-03   x[0,:] = tensor([0.5996, 0.3767, 0.0237, 0.5996, 0.3767, 0.0236])\n",
            "Step   955: |xk - xk_prev| = 1.38e-03   x[0,:] = tensor([0.5995, 0.3767, 0.0237, 0.5996, 0.3768, 0.0236])\n",
            "Step   960: |xk - xk_prev| = 1.37e-03   x[0,:] = tensor([0.5995, 0.3768, 0.0237, 0.5995, 0.3768, 0.0236])\n",
            "Step   965: |xk - xk_prev| = 1.37e-03   x[0,:] = tensor([0.5995, 0.3768, 0.0237, 0.5995, 0.3769, 0.0236])\n",
            "Step   970: |xk - xk_prev| = 1.36e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5995, 0.3769, 0.0236])\n",
            "Step   975: |xk - xk_prev| = 1.36e-03   x[0,:] = tensor([0.5996, 0.3769, 0.0236, 0.5995, 0.3769, 0.0236])\n",
            "Step   980: |xk - xk_prev| = 1.35e-03   x[0,:] = tensor([0.5996, 0.3769, 0.0235, 0.5996, 0.3768, 0.0236])\n",
            "Step   985: |xk - xk_prev| = 1.35e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0235, 0.5996, 0.3768, 0.0236])\n",
            "Step   990: |xk - xk_prev| = 1.35e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step   995: |xk - xk_prev| = 1.34e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5997, 0.3767, 0.0236])\n",
            "Step  1000: |xk - xk_prev| = 1.34e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0237, 0.5996, 0.3767, 0.0236])\n",
            "Step  1005: |xk - xk_prev| = 1.33e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0237, 0.5996, 0.3768, 0.0236])\n",
            "Step  1010: |xk - xk_prev| = 1.33e-03   x[0,:] = tensor([0.5995, 0.3768, 0.0237, 0.5996, 0.3768, 0.0236])\n",
            "Step  1015: |xk - xk_prev| = 1.33e-03   x[0,:] = tensor([0.5995, 0.3768, 0.0237, 0.5995, 0.3768, 0.0236])\n",
            "Step  1020: |xk - xk_prev| = 1.32e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5995, 0.3769, 0.0236])\n",
            "Step  1025: |xk - xk_prev| = 1.32e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5995, 0.3769, 0.0236])\n",
            "Step  1030: |xk - xk_prev| = 1.31e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1035: |xk - xk_prev| = 1.31e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1040: |xk - xk_prev| = 1.31e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1045: |xk - xk_prev| = 1.30e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1050: |xk - xk_prev| = 1.30e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1055: |xk - xk_prev| = 1.29e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0237, 0.5996, 0.3768, 0.0236])\n",
            "Step  1060: |xk - xk_prev| = 1.29e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0237, 0.5996, 0.3768, 0.0236])\n",
            "Step  1065: |xk - xk_prev| = 1.28e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0237, 0.5996, 0.3768, 0.0236])\n",
            "Step  1070: |xk - xk_prev| = 1.28e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5995, 0.3768, 0.0236])\n",
            "Step  1075: |xk - xk_prev| = 1.28e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5995, 0.3768, 0.0236])\n",
            "Step  1080: |xk - xk_prev| = 1.27e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1085: |xk - xk_prev| = 1.27e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1090: |xk - xk_prev| = 1.27e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1095: |xk - xk_prev| = 1.26e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1100: |xk - xk_prev| = 1.26e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1105: |xk - xk_prev| = 1.25e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1110: |xk - xk_prev| = 1.25e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0237, 0.5996, 0.3768, 0.0236])\n",
            "Step  1115: |xk - xk_prev| = 1.25e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1120: |xk - xk_prev| = 1.24e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1125: |xk - xk_prev| = 1.24e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1130: |xk - xk_prev| = 1.23e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1135: |xk - xk_prev| = 1.23e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1140: |xk - xk_prev| = 1.23e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1145: |xk - xk_prev| = 1.22e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1150: |xk - xk_prev| = 1.22e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1155: |xk - xk_prev| = 1.21e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1160: |xk - xk_prev| = 1.21e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1165: |xk - xk_prev| = 1.21e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1170: |xk - xk_prev| = 1.20e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1175: |xk - xk_prev| = 1.20e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1180: |xk - xk_prev| = 1.20e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1185: |xk - xk_prev| = 1.19e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1190: |xk - xk_prev| = 1.19e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1195: |xk - xk_prev| = 1.18e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1200: |xk - xk_prev| = 1.18e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1205: |xk - xk_prev| = 1.18e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1210: |xk - xk_prev| = 1.17e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1215: |xk - xk_prev| = 1.17e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1220: |xk - xk_prev| = 1.17e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1225: |xk - xk_prev| = 1.16e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1230: |xk - xk_prev| = 1.16e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1235: |xk - xk_prev| = 1.16e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1240: |xk - xk_prev| = 1.15e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1245: |xk - xk_prev| = 1.15e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1250: |xk - xk_prev| = 1.14e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1255: |xk - xk_prev| = 1.14e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1260: |xk - xk_prev| = 1.14e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1265: |xk - xk_prev| = 1.13e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1270: |xk - xk_prev| = 1.13e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1275: |xk - xk_prev| = 1.13e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1280: |xk - xk_prev| = 1.12e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1285: |xk - xk_prev| = 1.12e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1290: |xk - xk_prev| = 1.12e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1295: |xk - xk_prev| = 1.11e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1300: |xk - xk_prev| = 1.11e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1305: |xk - xk_prev| = 1.11e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1310: |xk - xk_prev| = 1.10e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1315: |xk - xk_prev| = 1.10e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1320: |xk - xk_prev| = 1.10e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1325: |xk - xk_prev| = 1.09e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1330: |xk - xk_prev| = 1.09e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1335: |xk - xk_prev| = 1.09e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1340: |xk - xk_prev| = 1.08e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1345: |xk - xk_prev| = 1.08e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1350: |xk - xk_prev| = 1.08e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1355: |xk - xk_prev| = 1.07e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1360: |xk - xk_prev| = 1.07e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1365: |xk - xk_prev| = 1.07e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1370: |xk - xk_prev| = 1.06e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1375: |xk - xk_prev| = 1.06e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1380: |xk - xk_prev| = 1.06e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1385: |xk - xk_prev| = 1.05e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1390: |xk - xk_prev| = 1.05e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1395: |xk - xk_prev| = 1.05e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1400: |xk - xk_prev| = 1.04e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1405: |xk - xk_prev| = 1.04e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1410: |xk - xk_prev| = 1.04e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1415: |xk - xk_prev| = 1.03e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1420: |xk - xk_prev| = 1.03e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1425: |xk - xk_prev| = 1.03e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1430: |xk - xk_prev| = 1.02e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1435: |xk - xk_prev| = 1.02e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1440: |xk - xk_prev| = 1.02e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1445: |xk - xk_prev| = 1.01e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1450: |xk - xk_prev| = 1.01e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1455: |xk - xk_prev| = 1.01e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1460: |xk - xk_prev| = 1.00e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1465: |xk - xk_prev| = 1.00e-03   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1470: |xk - xk_prev| = 9.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1475: |xk - xk_prev| = 9.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1480: |xk - xk_prev| = 9.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1485: |xk - xk_prev| = 9.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1490: |xk - xk_prev| = 9.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1495: |xk - xk_prev| = 9.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1500: |xk - xk_prev| = 9.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1505: |xk - xk_prev| = 9.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1510: |xk - xk_prev| = 9.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1515: |xk - xk_prev| = 9.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1520: |xk - xk_prev| = 9.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1525: |xk - xk_prev| = 9.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1530: |xk - xk_prev| = 9.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1535: |xk - xk_prev| = 9.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1540: |xk - xk_prev| = 9.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1545: |xk - xk_prev| = 9.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1550: |xk - xk_prev| = 9.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1555: |xk - xk_prev| = 9.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1560: |xk - xk_prev| = 9.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1565: |xk - xk_prev| = 9.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1570: |xk - xk_prev| = 9.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1575: |xk - xk_prev| = 9.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1580: |xk - xk_prev| = 9.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1585: |xk - xk_prev| = 9.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1590: |xk - xk_prev| = 9.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1595: |xk - xk_prev| = 9.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1600: |xk - xk_prev| = 9.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1605: |xk - xk_prev| = 9.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1610: |xk - xk_prev| = 9.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1615: |xk - xk_prev| = 9.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1620: |xk - xk_prev| = 9.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1625: |xk - xk_prev| = 9.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1630: |xk - xk_prev| = 9.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1635: |xk - xk_prev| = 9.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1640: |xk - xk_prev| = 8.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1645: |xk - xk_prev| = 8.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1650: |xk - xk_prev| = 8.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1655: |xk - xk_prev| = 8.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1660: |xk - xk_prev| = 8.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1665: |xk - xk_prev| = 8.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1670: |xk - xk_prev| = 8.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1675: |xk - xk_prev| = 8.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1680: |xk - xk_prev| = 8.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1685: |xk - xk_prev| = 8.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1690: |xk - xk_prev| = 8.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1695: |xk - xk_prev| = 8.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1700: |xk - xk_prev| = 8.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1705: |xk - xk_prev| = 8.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1710: |xk - xk_prev| = 8.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1715: |xk - xk_prev| = 8.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1720: |xk - xk_prev| = 8.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1725: |xk - xk_prev| = 8.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1730: |xk - xk_prev| = 8.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1735: |xk - xk_prev| = 8.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1740: |xk - xk_prev| = 8.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1745: |xk - xk_prev| = 8.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1750: |xk - xk_prev| = 8.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1755: |xk - xk_prev| = 8.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1760: |xk - xk_prev| = 8.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1765: |xk - xk_prev| = 8.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1770: |xk - xk_prev| = 8.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1775: |xk - xk_prev| = 8.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1780: |xk - xk_prev| = 8.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1785: |xk - xk_prev| = 8.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1790: |xk - xk_prev| = 8.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1795: |xk - xk_prev| = 8.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1800: |xk - xk_prev| = 8.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1805: |xk - xk_prev| = 8.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1810: |xk - xk_prev| = 8.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1815: |xk - xk_prev| = 8.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1820: |xk - xk_prev| = 8.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1825: |xk - xk_prev| = 8.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1830: |xk - xk_prev| = 8.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1835: |xk - xk_prev| = 8.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1840: |xk - xk_prev| = 8.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1845: |xk - xk_prev| = 8.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1850: |xk - xk_prev| = 8.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1855: |xk - xk_prev| = 8.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1860: |xk - xk_prev| = 8.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1865: |xk - xk_prev| = 8.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1870: |xk - xk_prev| = 8.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1875: |xk - xk_prev| = 8.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1880: |xk - xk_prev| = 7.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1885: |xk - xk_prev| = 7.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1890: |xk - xk_prev| = 7.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1895: |xk - xk_prev| = 7.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1900: |xk - xk_prev| = 7.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1905: |xk - xk_prev| = 7.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1910: |xk - xk_prev| = 7.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1915: |xk - xk_prev| = 7.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1920: |xk - xk_prev| = 7.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1925: |xk - xk_prev| = 7.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1930: |xk - xk_prev| = 7.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1935: |xk - xk_prev| = 7.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1940: |xk - xk_prev| = 7.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1945: |xk - xk_prev| = 7.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1950: |xk - xk_prev| = 7.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1955: |xk - xk_prev| = 7.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1960: |xk - xk_prev| = 7.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1965: |xk - xk_prev| = 7.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1970: |xk - xk_prev| = 7.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1975: |xk - xk_prev| = 7.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1980: |xk - xk_prev| = 7.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1985: |xk - xk_prev| = 7.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1990: |xk - xk_prev| = 7.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  1995: |xk - xk_prev| = 7.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2000: |xk - xk_prev| = 7.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2005: |xk - xk_prev| = 7.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2010: |xk - xk_prev| = 7.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2015: |xk - xk_prev| = 7.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2020: |xk - xk_prev| = 7.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2025: |xk - xk_prev| = 7.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2030: |xk - xk_prev| = 7.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2035: |xk - xk_prev| = 7.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2040: |xk - xk_prev| = 7.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2045: |xk - xk_prev| = 7.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2050: |xk - xk_prev| = 7.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2055: |xk - xk_prev| = 7.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2060: |xk - xk_prev| = 7.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2065: |xk - xk_prev| = 7.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2070: |xk - xk_prev| = 7.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2075: |xk - xk_prev| = 7.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2080: |xk - xk_prev| = 7.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2085: |xk - xk_prev| = 7.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2090: |xk - xk_prev| = 7.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2095: |xk - xk_prev| = 7.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2100: |xk - xk_prev| = 7.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2105: |xk - xk_prev| = 7.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2110: |xk - xk_prev| = 7.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2115: |xk - xk_prev| = 7.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2120: |xk - xk_prev| = 7.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2125: |xk - xk_prev| = 7.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2130: |xk - xk_prev| = 7.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2135: |xk - xk_prev| = 7.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2140: |xk - xk_prev| = 7.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2145: |xk - xk_prev| = 7.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2150: |xk - xk_prev| = 7.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2155: |xk - xk_prev| = 7.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2160: |xk - xk_prev| = 7.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2165: |xk - xk_prev| = 7.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2170: |xk - xk_prev| = 7.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2175: |xk - xk_prev| = 7.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2180: |xk - xk_prev| = 7.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2185: |xk - xk_prev| = 7.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2190: |xk - xk_prev| = 7.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2195: |xk - xk_prev| = 7.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2200: |xk - xk_prev| = 7.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2205: |xk - xk_prev| = 7.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2210: |xk - xk_prev| = 7.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2215: |xk - xk_prev| = 7.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2220: |xk - xk_prev| = 7.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2225: |xk - xk_prev| = 7.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2230: |xk - xk_prev| = 7.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2235: |xk - xk_prev| = 7.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2240: |xk - xk_prev| = 7.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2245: |xk - xk_prev| = 7.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2250: |xk - xk_prev| = 7.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2255: |xk - xk_prev| = 7.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2260: |xk - xk_prev| = 7.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2265: |xk - xk_prev| = 7.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2270: |xk - xk_prev| = 7.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2275: |xk - xk_prev| = 7.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2280: |xk - xk_prev| = 7.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2285: |xk - xk_prev| = 7.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2290: |xk - xk_prev| = 7.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2295: |xk - xk_prev| = 7.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2300: |xk - xk_prev| = 7.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2305: |xk - xk_prev| = 7.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2310: |xk - xk_prev| = 7.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2315: |xk - xk_prev| = 7.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2320: |xk - xk_prev| = 7.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2325: |xk - xk_prev| = 7.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2330: |xk - xk_prev| = 7.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2335: |xk - xk_prev| = 7.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2340: |xk - xk_prev| = 7.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2345: |xk - xk_prev| = 7.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2350: |xk - xk_prev| = 7.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2355: |xk - xk_prev| = 7.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2360: |xk - xk_prev| = 7.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2365: |xk - xk_prev| = 7.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2370: |xk - xk_prev| = 7.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2375: |xk - xk_prev| = 7.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2380: |xk - xk_prev| = 7.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2385: |xk - xk_prev| = 7.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2390: |xk - xk_prev| = 7.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2395: |xk - xk_prev| = 7.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2400: |xk - xk_prev| = 7.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2405: |xk - xk_prev| = 7.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2410: |xk - xk_prev| = 7.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2415: |xk - xk_prev| = 7.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2420: |xk - xk_prev| = 7.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2425: |xk - xk_prev| = 6.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2430: |xk - xk_prev| = 6.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2435: |xk - xk_prev| = 6.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2440: |xk - xk_prev| = 6.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2445: |xk - xk_prev| = 6.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2450: |xk - xk_prev| = 6.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2455: |xk - xk_prev| = 6.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2460: |xk - xk_prev| = 6.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2465: |xk - xk_prev| = 6.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2470: |xk - xk_prev| = 6.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2475: |xk - xk_prev| = 6.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2480: |xk - xk_prev| = 6.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2485: |xk - xk_prev| = 6.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2490: |xk - xk_prev| = 6.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2495: |xk - xk_prev| = 6.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2500: |xk - xk_prev| = 6.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2505: |xk - xk_prev| = 6.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2510: |xk - xk_prev| = 6.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2515: |xk - xk_prev| = 6.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2520: |xk - xk_prev| = 6.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2525: |xk - xk_prev| = 6.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2530: |xk - xk_prev| = 6.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2535: |xk - xk_prev| = 6.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2540: |xk - xk_prev| = 6.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2545: |xk - xk_prev| = 6.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2550: |xk - xk_prev| = 6.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2555: |xk - xk_prev| = 6.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2560: |xk - xk_prev| = 6.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2565: |xk - xk_prev| = 6.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2570: |xk - xk_prev| = 6.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2575: |xk - xk_prev| = 6.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2580: |xk - xk_prev| = 6.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2585: |xk - xk_prev| = 6.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2590: |xk - xk_prev| = 6.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2595: |xk - xk_prev| = 6.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2600: |xk - xk_prev| = 6.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2605: |xk - xk_prev| = 6.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2610: |xk - xk_prev| = 6.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2615: |xk - xk_prev| = 6.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2620: |xk - xk_prev| = 6.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2625: |xk - xk_prev| = 6.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2630: |xk - xk_prev| = 6.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2635: |xk - xk_prev| = 6.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2640: |xk - xk_prev| = 6.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2645: |xk - xk_prev| = 6.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2650: |xk - xk_prev| = 6.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2655: |xk - xk_prev| = 6.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2660: |xk - xk_prev| = 6.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2665: |xk - xk_prev| = 6.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2670: |xk - xk_prev| = 6.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2675: |xk - xk_prev| = 6.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2680: |xk - xk_prev| = 6.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2685: |xk - xk_prev| = 6.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2690: |xk - xk_prev| = 6.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2695: |xk - xk_prev| = 6.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2700: |xk - xk_prev| = 6.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2705: |xk - xk_prev| = 6.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2710: |xk - xk_prev| = 6.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2715: |xk - xk_prev| = 6.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2720: |xk - xk_prev| = 6.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2725: |xk - xk_prev| = 6.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2730: |xk - xk_prev| = 6.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2735: |xk - xk_prev| = 6.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2740: |xk - xk_prev| = 6.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2745: |xk - xk_prev| = 6.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2750: |xk - xk_prev| = 6.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2755: |xk - xk_prev| = 6.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2760: |xk - xk_prev| = 6.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2765: |xk - xk_prev| = 6.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2770: |xk - xk_prev| = 6.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2775: |xk - xk_prev| = 6.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2780: |xk - xk_prev| = 6.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2785: |xk - xk_prev| = 6.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2790: |xk - xk_prev| = 6.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2795: |xk - xk_prev| = 6.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2800: |xk - xk_prev| = 6.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2805: |xk - xk_prev| = 6.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2810: |xk - xk_prev| = 6.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2815: |xk - xk_prev| = 6.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2820: |xk - xk_prev| = 6.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2825: |xk - xk_prev| = 6.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2830: |xk - xk_prev| = 6.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2835: |xk - xk_prev| = 6.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2840: |xk - xk_prev| = 6.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2845: |xk - xk_prev| = 6.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2850: |xk - xk_prev| = 6.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2855: |xk - xk_prev| = 6.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2860: |xk - xk_prev| = 6.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2865: |xk - xk_prev| = 6.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2870: |xk - xk_prev| = 6.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2875: |xk - xk_prev| = 6.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2880: |xk - xk_prev| = 6.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2885: |xk - xk_prev| = 6.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2890: |xk - xk_prev| = 6.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2895: |xk - xk_prev| = 6.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2900: |xk - xk_prev| = 6.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2905: |xk - xk_prev| = 6.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2910: |xk - xk_prev| = 6.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2915: |xk - xk_prev| = 6.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2920: |xk - xk_prev| = 6.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2925: |xk - xk_prev| = 6.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2930: |xk - xk_prev| = 6.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2935: |xk - xk_prev| = 6.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2940: |xk - xk_prev| = 6.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2945: |xk - xk_prev| = 6.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2950: |xk - xk_prev| = 6.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2955: |xk - xk_prev| = 6.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2960: |xk - xk_prev| = 6.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2965: |xk - xk_prev| = 6.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2970: |xk - xk_prev| = 6.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2975: |xk - xk_prev| = 6.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2980: |xk - xk_prev| = 6.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2985: |xk - xk_prev| = 6.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2990: |xk - xk_prev| = 6.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  2995: |xk - xk_prev| = 6.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3000: |xk - xk_prev| = 6.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3005: |xk - xk_prev| = 6.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3010: |xk - xk_prev| = 6.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3015: |xk - xk_prev| = 6.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3020: |xk - xk_prev| = 6.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3025: |xk - xk_prev| = 6.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3030: |xk - xk_prev| = 6.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3035: |xk - xk_prev| = 6.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3040: |xk - xk_prev| = 6.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3045: |xk - xk_prev| = 6.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3050: |xk - xk_prev| = 6.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3055: |xk - xk_prev| = 6.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3060: |xk - xk_prev| = 6.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3065: |xk - xk_prev| = 6.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3070: |xk - xk_prev| = 6.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3075: |xk - xk_prev| = 6.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3080: |xk - xk_prev| = 6.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3085: |xk - xk_prev| = 6.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3090: |xk - xk_prev| = 6.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3095: |xk - xk_prev| = 6.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3100: |xk - xk_prev| = 6.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3105: |xk - xk_prev| = 6.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3110: |xk - xk_prev| = 6.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3115: |xk - xk_prev| = 6.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3120: |xk - xk_prev| = 6.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3125: |xk - xk_prev| = 6.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3130: |xk - xk_prev| = 6.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3135: |xk - xk_prev| = 6.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3140: |xk - xk_prev| = 6.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3145: |xk - xk_prev| = 6.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3150: |xk - xk_prev| = 6.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3155: |xk - xk_prev| = 6.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3160: |xk - xk_prev| = 6.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3165: |xk - xk_prev| = 6.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3170: |xk - xk_prev| = 6.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3175: |xk - xk_prev| = 6.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3180: |xk - xk_prev| = 6.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3185: |xk - xk_prev| = 6.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3190: |xk - xk_prev| = 6.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3195: |xk - xk_prev| = 6.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3200: |xk - xk_prev| = 6.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3205: |xk - xk_prev| = 6.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3210: |xk - xk_prev| = 6.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3215: |xk - xk_prev| = 6.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3220: |xk - xk_prev| = 6.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3225: |xk - xk_prev| = 6.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3230: |xk - xk_prev| = 6.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3235: |xk - xk_prev| = 6.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3240: |xk - xk_prev| = 6.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3245: |xk - xk_prev| = 6.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3250: |xk - xk_prev| = 6.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3255: |xk - xk_prev| = 6.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3260: |xk - xk_prev| = 6.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3265: |xk - xk_prev| = 6.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3270: |xk - xk_prev| = 6.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3275: |xk - xk_prev| = 6.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3280: |xk - xk_prev| = 6.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3285: |xk - xk_prev| = 6.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3290: |xk - xk_prev| = 6.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3295: |xk - xk_prev| = 6.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3300: |xk - xk_prev| = 6.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3305: |xk - xk_prev| = 6.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3310: |xk - xk_prev| = 6.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3315: |xk - xk_prev| = 6.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3320: |xk - xk_prev| = 6.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3325: |xk - xk_prev| = 6.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3330: |xk - xk_prev| = 6.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3335: |xk - xk_prev| = 6.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3340: |xk - xk_prev| = 6.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3345: |xk - xk_prev| = 6.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3350: |xk - xk_prev| = 6.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3355: |xk - xk_prev| = 6.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3360: |xk - xk_prev| = 6.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3365: |xk - xk_prev| = 6.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3370: |xk - xk_prev| = 6.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3375: |xk - xk_prev| = 6.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3380: |xk - xk_prev| = 6.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3385: |xk - xk_prev| = 6.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3390: |xk - xk_prev| = 6.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3395: |xk - xk_prev| = 6.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3400: |xk - xk_prev| = 6.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3405: |xk - xk_prev| = 6.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3410: |xk - xk_prev| = 6.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3415: |xk - xk_prev| = 6.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3420: |xk - xk_prev| = 6.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3425: |xk - xk_prev| = 6.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3430: |xk - xk_prev| = 6.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3435: |xk - xk_prev| = 6.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3440: |xk - xk_prev| = 6.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3445: |xk - xk_prev| = 6.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3450: |xk - xk_prev| = 6.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3455: |xk - xk_prev| = 6.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3460: |xk - xk_prev| = 6.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3465: |xk - xk_prev| = 6.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3470: |xk - xk_prev| = 6.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3475: |xk - xk_prev| = 6.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3480: |xk - xk_prev| = 6.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3485: |xk - xk_prev| = 6.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3490: |xk - xk_prev| = 6.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3495: |xk - xk_prev| = 6.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3500: |xk - xk_prev| = 6.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3505: |xk - xk_prev| = 6.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3510: |xk - xk_prev| = 6.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3515: |xk - xk_prev| = 5.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3520: |xk - xk_prev| = 5.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3525: |xk - xk_prev| = 5.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3530: |xk - xk_prev| = 5.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3535: |xk - xk_prev| = 5.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3540: |xk - xk_prev| = 5.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3545: |xk - xk_prev| = 5.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3550: |xk - xk_prev| = 5.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3555: |xk - xk_prev| = 5.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3560: |xk - xk_prev| = 5.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3565: |xk - xk_prev| = 5.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3570: |xk - xk_prev| = 5.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3575: |xk - xk_prev| = 5.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3580: |xk - xk_prev| = 5.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3585: |xk - xk_prev| = 5.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3590: |xk - xk_prev| = 5.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3595: |xk - xk_prev| = 5.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3600: |xk - xk_prev| = 5.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3605: |xk - xk_prev| = 5.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3610: |xk - xk_prev| = 5.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3615: |xk - xk_prev| = 5.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3620: |xk - xk_prev| = 5.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3625: |xk - xk_prev| = 5.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3630: |xk - xk_prev| = 5.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3635: |xk - xk_prev| = 5.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3640: |xk - xk_prev| = 5.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3645: |xk - xk_prev| = 5.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3650: |xk - xk_prev| = 5.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3655: |xk - xk_prev| = 5.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3660: |xk - xk_prev| = 5.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3665: |xk - xk_prev| = 5.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3670: |xk - xk_prev| = 5.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3675: |xk - xk_prev| = 5.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3680: |xk - xk_prev| = 5.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3685: |xk - xk_prev| = 5.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3690: |xk - xk_prev| = 5.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3695: |xk - xk_prev| = 5.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3700: |xk - xk_prev| = 5.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3705: |xk - xk_prev| = 5.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3710: |xk - xk_prev| = 5.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3715: |xk - xk_prev| = 5.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3720: |xk - xk_prev| = 5.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3725: |xk - xk_prev| = 5.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3730: |xk - xk_prev| = 5.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3735: |xk - xk_prev| = 5.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3740: |xk - xk_prev| = 5.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3745: |xk - xk_prev| = 5.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3750: |xk - xk_prev| = 5.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3755: |xk - xk_prev| = 5.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3760: |xk - xk_prev| = 5.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3765: |xk - xk_prev| = 5.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3770: |xk - xk_prev| = 5.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3775: |xk - xk_prev| = 5.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3780: |xk - xk_prev| = 5.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3785: |xk - xk_prev| = 5.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3790: |xk - xk_prev| = 5.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3795: |xk - xk_prev| = 5.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3800: |xk - xk_prev| = 5.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3805: |xk - xk_prev| = 5.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3810: |xk - xk_prev| = 5.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3815: |xk - xk_prev| = 5.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3820: |xk - xk_prev| = 5.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3825: |xk - xk_prev| = 5.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3830: |xk - xk_prev| = 5.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3835: |xk - xk_prev| = 5.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3840: |xk - xk_prev| = 5.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3845: |xk - xk_prev| = 5.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3850: |xk - xk_prev| = 5.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3855: |xk - xk_prev| = 5.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3860: |xk - xk_prev| = 5.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3865: |xk - xk_prev| = 5.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3870: |xk - xk_prev| = 5.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3875: |xk - xk_prev| = 5.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3880: |xk - xk_prev| = 5.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3885: |xk - xk_prev| = 5.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3890: |xk - xk_prev| = 5.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3895: |xk - xk_prev| = 5.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3900: |xk - xk_prev| = 5.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3905: |xk - xk_prev| = 5.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3910: |xk - xk_prev| = 5.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3915: |xk - xk_prev| = 5.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3920: |xk - xk_prev| = 5.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3925: |xk - xk_prev| = 5.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3930: |xk - xk_prev| = 5.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3935: |xk - xk_prev| = 5.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3940: |xk - xk_prev| = 5.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3945: |xk - xk_prev| = 5.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3950: |xk - xk_prev| = 5.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3955: |xk - xk_prev| = 5.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3960: |xk - xk_prev| = 5.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3965: |xk - xk_prev| = 5.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3970: |xk - xk_prev| = 5.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3975: |xk - xk_prev| = 5.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3980: |xk - xk_prev| = 5.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3985: |xk - xk_prev| = 5.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3990: |xk - xk_prev| = 5.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  3995: |xk - xk_prev| = 5.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4000: |xk - xk_prev| = 5.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4005: |xk - xk_prev| = 5.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4010: |xk - xk_prev| = 5.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4015: |xk - xk_prev| = 5.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4020: |xk - xk_prev| = 5.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4025: |xk - xk_prev| = 5.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4030: |xk - xk_prev| = 5.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4035: |xk - xk_prev| = 5.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4040: |xk - xk_prev| = 5.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4045: |xk - xk_prev| = 5.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4050: |xk - xk_prev| = 5.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4055: |xk - xk_prev| = 5.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4060: |xk - xk_prev| = 5.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4065: |xk - xk_prev| = 5.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4070: |xk - xk_prev| = 5.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4075: |xk - xk_prev| = 5.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4080: |xk - xk_prev| = 5.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4085: |xk - xk_prev| = 5.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4090: |xk - xk_prev| = 5.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4095: |xk - xk_prev| = 5.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4100: |xk - xk_prev| = 5.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4105: |xk - xk_prev| = 5.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4110: |xk - xk_prev| = 5.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4115: |xk - xk_prev| = 5.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4120: |xk - xk_prev| = 5.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4125: |xk - xk_prev| = 5.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4130: |xk - xk_prev| = 5.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4135: |xk - xk_prev| = 5.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4140: |xk - xk_prev| = 5.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4145: |xk - xk_prev| = 5.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4150: |xk - xk_prev| = 5.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4155: |xk - xk_prev| = 5.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4160: |xk - xk_prev| = 5.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4165: |xk - xk_prev| = 5.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4170: |xk - xk_prev| = 5.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4175: |xk - xk_prev| = 5.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4180: |xk - xk_prev| = 5.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4185: |xk - xk_prev| = 5.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4190: |xk - xk_prev| = 5.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4195: |xk - xk_prev| = 5.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4200: |xk - xk_prev| = 5.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4205: |xk - xk_prev| = 5.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4210: |xk - xk_prev| = 5.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4215: |xk - xk_prev| = 5.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4220: |xk - xk_prev| = 5.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4225: |xk - xk_prev| = 5.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4230: |xk - xk_prev| = 5.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4235: |xk - xk_prev| = 5.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4240: |xk - xk_prev| = 5.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4245: |xk - xk_prev| = 5.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4250: |xk - xk_prev| = 5.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4255: |xk - xk_prev| = 5.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4260: |xk - xk_prev| = 5.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4265: |xk - xk_prev| = 5.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4270: |xk - xk_prev| = 5.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4275: |xk - xk_prev| = 5.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4280: |xk - xk_prev| = 5.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4285: |xk - xk_prev| = 5.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4290: |xk - xk_prev| = 5.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4295: |xk - xk_prev| = 5.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4300: |xk - xk_prev| = 5.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4305: |xk - xk_prev| = 5.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4310: |xk - xk_prev| = 5.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4315: |xk - xk_prev| = 5.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4320: |xk - xk_prev| = 5.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4325: |xk - xk_prev| = 5.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4330: |xk - xk_prev| = 5.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4335: |xk - xk_prev| = 5.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4340: |xk - xk_prev| = 5.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4345: |xk - xk_prev| = 5.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4350: |xk - xk_prev| = 5.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4355: |xk - xk_prev| = 5.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4360: |xk - xk_prev| = 5.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4365: |xk - xk_prev| = 5.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4370: |xk - xk_prev| = 5.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4375: |xk - xk_prev| = 5.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4380: |xk - xk_prev| = 5.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4385: |xk - xk_prev| = 5.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4390: |xk - xk_prev| = 5.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4395: |xk - xk_prev| = 5.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4400: |xk - xk_prev| = 5.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4405: |xk - xk_prev| = 5.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4410: |xk - xk_prev| = 5.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4415: |xk - xk_prev| = 5.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4420: |xk - xk_prev| = 5.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4425: |xk - xk_prev| = 5.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4430: |xk - xk_prev| = 5.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4435: |xk - xk_prev| = 5.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4440: |xk - xk_prev| = 5.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4445: |xk - xk_prev| = 5.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4450: |xk - xk_prev| = 5.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4455: |xk - xk_prev| = 5.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4460: |xk - xk_prev| = 5.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4465: |xk - xk_prev| = 5.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4470: |xk - xk_prev| = 5.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4475: |xk - xk_prev| = 5.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4480: |xk - xk_prev| = 5.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4485: |xk - xk_prev| = 5.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4490: |xk - xk_prev| = 5.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4495: |xk - xk_prev| = 5.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4500: |xk - xk_prev| = 5.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4505: |xk - xk_prev| = 5.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4510: |xk - xk_prev| = 5.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4515: |xk - xk_prev| = 5.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4520: |xk - xk_prev| = 5.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4525: |xk - xk_prev| = 5.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4530: |xk - xk_prev| = 5.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4535: |xk - xk_prev| = 5.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4540: |xk - xk_prev| = 5.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4545: |xk - xk_prev| = 5.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4550: |xk - xk_prev| = 5.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4555: |xk - xk_prev| = 5.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4560: |xk - xk_prev| = 5.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4565: |xk - xk_prev| = 5.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4570: |xk - xk_prev| = 5.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4575: |xk - xk_prev| = 5.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4580: |xk - xk_prev| = 5.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4585: |xk - xk_prev| = 5.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4590: |xk - xk_prev| = 5.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4595: |xk - xk_prev| = 5.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4600: |xk - xk_prev| = 5.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4605: |xk - xk_prev| = 5.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4610: |xk - xk_prev| = 5.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4615: |xk - xk_prev| = 5.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4620: |xk - xk_prev| = 5.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4625: |xk - xk_prev| = 5.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4630: |xk - xk_prev| = 5.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4635: |xk - xk_prev| = 5.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4640: |xk - xk_prev| = 5.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4645: |xk - xk_prev| = 5.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4650: |xk - xk_prev| = 5.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4655: |xk - xk_prev| = 5.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4660: |xk - xk_prev| = 5.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4665: |xk - xk_prev| = 5.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4670: |xk - xk_prev| = 5.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4675: |xk - xk_prev| = 5.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4680: |xk - xk_prev| = 5.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4685: |xk - xk_prev| = 5.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4690: |xk - xk_prev| = 5.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4695: |xk - xk_prev| = 5.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4700: |xk - xk_prev| = 5.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4705: |xk - xk_prev| = 5.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4710: |xk - xk_prev| = 5.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4715: |xk - xk_prev| = 5.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4720: |xk - xk_prev| = 5.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4725: |xk - xk_prev| = 5.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4730: |xk - xk_prev| = 5.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4735: |xk - xk_prev| = 5.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4740: |xk - xk_prev| = 5.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4745: |xk - xk_prev| = 5.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4750: |xk - xk_prev| = 5.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4755: |xk - xk_prev| = 5.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4760: |xk - xk_prev| = 5.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4765: |xk - xk_prev| = 5.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4770: |xk - xk_prev| = 5.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4775: |xk - xk_prev| = 5.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4780: |xk - xk_prev| = 5.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4785: |xk - xk_prev| = 5.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4790: |xk - xk_prev| = 5.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4795: |xk - xk_prev| = 5.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4800: |xk - xk_prev| = 5.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4805: |xk - xk_prev| = 5.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4810: |xk - xk_prev| = 4.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4815: |xk - xk_prev| = 4.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4820: |xk - xk_prev| = 4.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4825: |xk - xk_prev| = 4.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4830: |xk - xk_prev| = 4.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4835: |xk - xk_prev| = 4.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4840: |xk - xk_prev| = 4.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4845: |xk - xk_prev| = 4.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4850: |xk - xk_prev| = 4.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4855: |xk - xk_prev| = 4.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4860: |xk - xk_prev| = 4.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4865: |xk - xk_prev| = 4.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4870: |xk - xk_prev| = 4.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4875: |xk - xk_prev| = 4.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4880: |xk - xk_prev| = 4.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4885: |xk - xk_prev| = 4.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4890: |xk - xk_prev| = 4.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4895: |xk - xk_prev| = 4.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4900: |xk - xk_prev| = 4.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4905: |xk - xk_prev| = 4.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4910: |xk - xk_prev| = 4.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4915: |xk - xk_prev| = 4.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4920: |xk - xk_prev| = 4.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4925: |xk - xk_prev| = 4.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4930: |xk - xk_prev| = 4.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4935: |xk - xk_prev| = 4.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4940: |xk - xk_prev| = 4.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4945: |xk - xk_prev| = 4.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4950: |xk - xk_prev| = 4.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4955: |xk - xk_prev| = 4.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4960: |xk - xk_prev| = 4.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4965: |xk - xk_prev| = 4.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4970: |xk - xk_prev| = 4.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4975: |xk - xk_prev| = 4.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4980: |xk - xk_prev| = 4.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4985: |xk - xk_prev| = 4.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4990: |xk - xk_prev| = 4.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  4995: |xk - xk_prev| = 4.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5000: |xk - xk_prev| = 4.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5005: |xk - xk_prev| = 4.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5010: |xk - xk_prev| = 4.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5015: |xk - xk_prev| = 4.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5020: |xk - xk_prev| = 4.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5025: |xk - xk_prev| = 4.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5030: |xk - xk_prev| = 4.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5035: |xk - xk_prev| = 4.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5040: |xk - xk_prev| = 4.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5045: |xk - xk_prev| = 4.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5050: |xk - xk_prev| = 4.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5055: |xk - xk_prev| = 4.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5060: |xk - xk_prev| = 4.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5065: |xk - xk_prev| = 4.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5070: |xk - xk_prev| = 4.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5075: |xk - xk_prev| = 4.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5080: |xk - xk_prev| = 4.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5085: |xk - xk_prev| = 4.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5090: |xk - xk_prev| = 4.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5095: |xk - xk_prev| = 4.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5100: |xk - xk_prev| = 4.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5105: |xk - xk_prev| = 4.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5110: |xk - xk_prev| = 4.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5115: |xk - xk_prev| = 4.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5120: |xk - xk_prev| = 4.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5125: |xk - xk_prev| = 4.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5130: |xk - xk_prev| = 4.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5135: |xk - xk_prev| = 4.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5140: |xk - xk_prev| = 4.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5145: |xk - xk_prev| = 4.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5150: |xk - xk_prev| = 4.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5155: |xk - xk_prev| = 4.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5160: |xk - xk_prev| = 4.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5165: |xk - xk_prev| = 4.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5170: |xk - xk_prev| = 4.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5175: |xk - xk_prev| = 4.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5180: |xk - xk_prev| = 4.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5185: |xk - xk_prev| = 4.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5190: |xk - xk_prev| = 4.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5195: |xk - xk_prev| = 4.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5200: |xk - xk_prev| = 4.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5205: |xk - xk_prev| = 4.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5210: |xk - xk_prev| = 4.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5215: |xk - xk_prev| = 4.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5220: |xk - xk_prev| = 4.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5225: |xk - xk_prev| = 4.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5230: |xk - xk_prev| = 4.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5235: |xk - xk_prev| = 4.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5240: |xk - xk_prev| = 4.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5245: |xk - xk_prev| = 4.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5250: |xk - xk_prev| = 4.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5255: |xk - xk_prev| = 4.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5260: |xk - xk_prev| = 4.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5265: |xk - xk_prev| = 4.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5270: |xk - xk_prev| = 4.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5275: |xk - xk_prev| = 4.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5280: |xk - xk_prev| = 4.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5285: |xk - xk_prev| = 4.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5290: |xk - xk_prev| = 4.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5295: |xk - xk_prev| = 4.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5300: |xk - xk_prev| = 4.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5305: |xk - xk_prev| = 4.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5310: |xk - xk_prev| = 4.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5315: |xk - xk_prev| = 4.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5320: |xk - xk_prev| = 4.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5325: |xk - xk_prev| = 4.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5330: |xk - xk_prev| = 4.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5335: |xk - xk_prev| = 4.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5340: |xk - xk_prev| = 4.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5345: |xk - xk_prev| = 4.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5350: |xk - xk_prev| = 4.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5355: |xk - xk_prev| = 4.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5360: |xk - xk_prev| = 4.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5365: |xk - xk_prev| = 4.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5370: |xk - xk_prev| = 4.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5375: |xk - xk_prev| = 4.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5380: |xk - xk_prev| = 4.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5385: |xk - xk_prev| = 4.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5390: |xk - xk_prev| = 4.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5395: |xk - xk_prev| = 4.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5400: |xk - xk_prev| = 4.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5405: |xk - xk_prev| = 4.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5410: |xk - xk_prev| = 4.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5415: |xk - xk_prev| = 4.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5420: |xk - xk_prev| = 4.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5425: |xk - xk_prev| = 4.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5430: |xk - xk_prev| = 4.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5435: |xk - xk_prev| = 4.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5440: |xk - xk_prev| = 4.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5445: |xk - xk_prev| = 4.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5450: |xk - xk_prev| = 4.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5455: |xk - xk_prev| = 4.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5460: |xk - xk_prev| = 4.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5465: |xk - xk_prev| = 4.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5470: |xk - xk_prev| = 4.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5475: |xk - xk_prev| = 4.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5480: |xk - xk_prev| = 4.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5485: |xk - xk_prev| = 4.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5490: |xk - xk_prev| = 4.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5495: |xk - xk_prev| = 4.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5500: |xk - xk_prev| = 4.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5505: |xk - xk_prev| = 4.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5510: |xk - xk_prev| = 4.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5515: |xk - xk_prev| = 4.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5520: |xk - xk_prev| = 4.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5525: |xk - xk_prev| = 4.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5530: |xk - xk_prev| = 4.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5535: |xk - xk_prev| = 4.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5540: |xk - xk_prev| = 4.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5545: |xk - xk_prev| = 4.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5550: |xk - xk_prev| = 4.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5555: |xk - xk_prev| = 4.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5560: |xk - xk_prev| = 4.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5565: |xk - xk_prev| = 4.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5570: |xk - xk_prev| = 4.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5575: |xk - xk_prev| = 4.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5580: |xk - xk_prev| = 4.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5585: |xk - xk_prev| = 4.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5590: |xk - xk_prev| = 4.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5595: |xk - xk_prev| = 4.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5600: |xk - xk_prev| = 4.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5605: |xk - xk_prev| = 4.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5610: |xk - xk_prev| = 4.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5615: |xk - xk_prev| = 4.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5620: |xk - xk_prev| = 4.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5625: |xk - xk_prev| = 4.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5630: |xk - xk_prev| = 4.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5635: |xk - xk_prev| = 4.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5640: |xk - xk_prev| = 4.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5645: |xk - xk_prev| = 4.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5650: |xk - xk_prev| = 4.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5655: |xk - xk_prev| = 4.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5660: |xk - xk_prev| = 4.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5665: |xk - xk_prev| = 4.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5670: |xk - xk_prev| = 4.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5675: |xk - xk_prev| = 4.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5680: |xk - xk_prev| = 4.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5685: |xk - xk_prev| = 4.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5690: |xk - xk_prev| = 4.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5695: |xk - xk_prev| = 4.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5700: |xk - xk_prev| = 4.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5705: |xk - xk_prev| = 4.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5710: |xk - xk_prev| = 4.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5715: |xk - xk_prev| = 4.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5720: |xk - xk_prev| = 4.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5725: |xk - xk_prev| = 4.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5730: |xk - xk_prev| = 4.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5735: |xk - xk_prev| = 4.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5740: |xk - xk_prev| = 4.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5745: |xk - xk_prev| = 4.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5750: |xk - xk_prev| = 4.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5755: |xk - xk_prev| = 4.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5760: |xk - xk_prev| = 4.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5765: |xk - xk_prev| = 4.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5770: |xk - xk_prev| = 4.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5775: |xk - xk_prev| = 4.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5780: |xk - xk_prev| = 4.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5785: |xk - xk_prev| = 4.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5790: |xk - xk_prev| = 4.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5795: |xk - xk_prev| = 4.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5800: |xk - xk_prev| = 4.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5805: |xk - xk_prev| = 4.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5810: |xk - xk_prev| = 4.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5815: |xk - xk_prev| = 4.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5820: |xk - xk_prev| = 4.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5825: |xk - xk_prev| = 4.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5830: |xk - xk_prev| = 4.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5835: |xk - xk_prev| = 4.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5840: |xk - xk_prev| = 4.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5845: |xk - xk_prev| = 4.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5850: |xk - xk_prev| = 4.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5855: |xk - xk_prev| = 4.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5860: |xk - xk_prev| = 4.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5865: |xk - xk_prev| = 4.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5870: |xk - xk_prev| = 4.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5875: |xk - xk_prev| = 4.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5880: |xk - xk_prev| = 4.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5885: |xk - xk_prev| = 4.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5890: |xk - xk_prev| = 4.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5895: |xk - xk_prev| = 4.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5900: |xk - xk_prev| = 4.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5905: |xk - xk_prev| = 4.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5910: |xk - xk_prev| = 4.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5915: |xk - xk_prev| = 4.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5920: |xk - xk_prev| = 4.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5925: |xk - xk_prev| = 4.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5930: |xk - xk_prev| = 4.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5935: |xk - xk_prev| = 4.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5940: |xk - xk_prev| = 4.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5945: |xk - xk_prev| = 4.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5950: |xk - xk_prev| = 4.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5955: |xk - xk_prev| = 4.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5960: |xk - xk_prev| = 4.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5965: |xk - xk_prev| = 4.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5970: |xk - xk_prev| = 4.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5975: |xk - xk_prev| = 4.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5980: |xk - xk_prev| = 4.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5985: |xk - xk_prev| = 4.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5990: |xk - xk_prev| = 4.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  5995: |xk - xk_prev| = 4.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6000: |xk - xk_prev| = 4.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6005: |xk - xk_prev| = 4.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6010: |xk - xk_prev| = 4.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6015: |xk - xk_prev| = 4.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6020: |xk - xk_prev| = 4.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6025: |xk - xk_prev| = 4.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6030: |xk - xk_prev| = 4.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6035: |xk - xk_prev| = 4.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6040: |xk - xk_prev| = 4.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6045: |xk - xk_prev| = 4.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6050: |xk - xk_prev| = 4.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6055: |xk - xk_prev| = 4.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6060: |xk - xk_prev| = 4.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6065: |xk - xk_prev| = 4.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6070: |xk - xk_prev| = 4.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6075: |xk - xk_prev| = 4.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6080: |xk - xk_prev| = 4.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6085: |xk - xk_prev| = 4.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6090: |xk - xk_prev| = 4.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6095: |xk - xk_prev| = 4.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6100: |xk - xk_prev| = 4.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6105: |xk - xk_prev| = 4.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6110: |xk - xk_prev| = 4.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6115: |xk - xk_prev| = 4.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6120: |xk - xk_prev| = 4.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6125: |xk - xk_prev| = 4.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6130: |xk - xk_prev| = 4.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6135: |xk - xk_prev| = 4.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6140: |xk - xk_prev| = 4.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6145: |xk - xk_prev| = 4.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6150: |xk - xk_prev| = 4.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6155: |xk - xk_prev| = 4.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6160: |xk - xk_prev| = 4.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6165: |xk - xk_prev| = 4.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6170: |xk - xk_prev| = 4.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6175: |xk - xk_prev| = 4.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6180: |xk - xk_prev| = 4.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6185: |xk - xk_prev| = 4.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6190: |xk - xk_prev| = 4.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6195: |xk - xk_prev| = 4.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6200: |xk - xk_prev| = 4.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6205: |xk - xk_prev| = 4.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6210: |xk - xk_prev| = 4.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6215: |xk - xk_prev| = 4.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6220: |xk - xk_prev| = 4.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6225: |xk - xk_prev| = 4.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6230: |xk - xk_prev| = 4.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6235: |xk - xk_prev| = 4.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6240: |xk - xk_prev| = 4.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6245: |xk - xk_prev| = 4.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6250: |xk - xk_prev| = 4.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6255: |xk - xk_prev| = 4.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6260: |xk - xk_prev| = 4.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6265: |xk - xk_prev| = 4.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6270: |xk - xk_prev| = 4.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6275: |xk - xk_prev| = 4.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6280: |xk - xk_prev| = 4.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6285: |xk - xk_prev| = 4.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6290: |xk - xk_prev| = 4.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6295: |xk - xk_prev| = 4.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6300: |xk - xk_prev| = 4.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6305: |xk - xk_prev| = 4.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6310: |xk - xk_prev| = 4.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6315: |xk - xk_prev| = 4.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6320: |xk - xk_prev| = 4.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6325: |xk - xk_prev| = 4.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6330: |xk - xk_prev| = 4.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6335: |xk - xk_prev| = 4.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6340: |xk - xk_prev| = 4.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6345: |xk - xk_prev| = 4.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6350: |xk - xk_prev| = 4.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6355: |xk - xk_prev| = 4.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6360: |xk - xk_prev| = 4.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6365: |xk - xk_prev| = 4.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6370: |xk - xk_prev| = 4.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6375: |xk - xk_prev| = 4.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6380: |xk - xk_prev| = 4.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6385: |xk - xk_prev| = 4.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6390: |xk - xk_prev| = 4.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6395: |xk - xk_prev| = 3.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6400: |xk - xk_prev| = 3.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6405: |xk - xk_prev| = 3.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6410: |xk - xk_prev| = 3.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6415: |xk - xk_prev| = 3.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6420: |xk - xk_prev| = 3.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6425: |xk - xk_prev| = 3.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6430: |xk - xk_prev| = 3.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6435: |xk - xk_prev| = 3.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6440: |xk - xk_prev| = 3.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6445: |xk - xk_prev| = 3.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6450: |xk - xk_prev| = 3.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6455: |xk - xk_prev| = 3.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6460: |xk - xk_prev| = 3.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6465: |xk - xk_prev| = 3.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6470: |xk - xk_prev| = 3.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6475: |xk - xk_prev| = 3.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6480: |xk - xk_prev| = 3.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6485: |xk - xk_prev| = 3.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6490: |xk - xk_prev| = 3.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6495: |xk - xk_prev| = 3.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6500: |xk - xk_prev| = 3.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6505: |xk - xk_prev| = 3.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6510: |xk - xk_prev| = 3.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6515: |xk - xk_prev| = 3.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6520: |xk - xk_prev| = 3.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6525: |xk - xk_prev| = 3.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6530: |xk - xk_prev| = 3.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6535: |xk - xk_prev| = 3.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6540: |xk - xk_prev| = 3.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6545: |xk - xk_prev| = 3.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6550: |xk - xk_prev| = 3.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6555: |xk - xk_prev| = 3.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6560: |xk - xk_prev| = 3.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6565: |xk - xk_prev| = 3.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6570: |xk - xk_prev| = 3.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6575: |xk - xk_prev| = 3.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6580: |xk - xk_prev| = 3.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6585: |xk - xk_prev| = 3.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6590: |xk - xk_prev| = 3.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6595: |xk - xk_prev| = 3.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6600: |xk - xk_prev| = 3.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6605: |xk - xk_prev| = 3.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6610: |xk - xk_prev| = 3.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6615: |xk - xk_prev| = 3.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6620: |xk - xk_prev| = 3.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6625: |xk - xk_prev| = 3.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6630: |xk - xk_prev| = 3.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6635: |xk - xk_prev| = 3.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6640: |xk - xk_prev| = 3.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6645: |xk - xk_prev| = 3.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6650: |xk - xk_prev| = 3.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6655: |xk - xk_prev| = 3.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6660: |xk - xk_prev| = 3.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6665: |xk - xk_prev| = 3.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6670: |xk - xk_prev| = 3.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6675: |xk - xk_prev| = 3.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6680: |xk - xk_prev| = 3.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6685: |xk - xk_prev| = 3.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6690: |xk - xk_prev| = 3.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6695: |xk - xk_prev| = 3.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6700: |xk - xk_prev| = 3.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6705: |xk - xk_prev| = 3.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6710: |xk - xk_prev| = 3.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6715: |xk - xk_prev| = 3.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6720: |xk - xk_prev| = 3.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6725: |xk - xk_prev| = 3.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6730: |xk - xk_prev| = 3.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6735: |xk - xk_prev| = 3.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6740: |xk - xk_prev| = 3.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6745: |xk - xk_prev| = 3.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6750: |xk - xk_prev| = 3.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6755: |xk - xk_prev| = 3.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6760: |xk - xk_prev| = 3.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6765: |xk - xk_prev| = 3.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6770: |xk - xk_prev| = 3.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6775: |xk - xk_prev| = 3.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6780: |xk - xk_prev| = 3.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6785: |xk - xk_prev| = 3.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6790: |xk - xk_prev| = 3.78e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6795: |xk - xk_prev| = 3.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6800: |xk - xk_prev| = 3.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6805: |xk - xk_prev| = 3.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6810: |xk - xk_prev| = 3.77e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6815: |xk - xk_prev| = 3.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6820: |xk - xk_prev| = 3.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6825: |xk - xk_prev| = 3.76e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6830: |xk - xk_prev| = 3.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6835: |xk - xk_prev| = 3.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6840: |xk - xk_prev| = 3.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6845: |xk - xk_prev| = 3.75e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6850: |xk - xk_prev| = 3.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6855: |xk - xk_prev| = 3.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6860: |xk - xk_prev| = 3.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6865: |xk - xk_prev| = 3.74e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6870: |xk - xk_prev| = 3.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6875: |xk - xk_prev| = 3.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6880: |xk - xk_prev| = 3.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6885: |xk - xk_prev| = 3.73e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6890: |xk - xk_prev| = 3.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6895: |xk - xk_prev| = 3.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6900: |xk - xk_prev| = 3.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6905: |xk - xk_prev| = 3.72e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6910: |xk - xk_prev| = 3.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6915: |xk - xk_prev| = 3.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6920: |xk - xk_prev| = 3.71e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6925: |xk - xk_prev| = 3.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6930: |xk - xk_prev| = 3.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6935: |xk - xk_prev| = 3.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6940: |xk - xk_prev| = 3.70e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6945: |xk - xk_prev| = 3.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6950: |xk - xk_prev| = 3.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6955: |xk - xk_prev| = 3.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6960: |xk - xk_prev| = 3.69e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6965: |xk - xk_prev| = 3.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6970: |xk - xk_prev| = 3.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6975: |xk - xk_prev| = 3.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6980: |xk - xk_prev| = 3.68e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6985: |xk - xk_prev| = 3.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6990: |xk - xk_prev| = 3.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  6995: |xk - xk_prev| = 3.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7000: |xk - xk_prev| = 3.67e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7005: |xk - xk_prev| = 3.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7010: |xk - xk_prev| = 3.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7015: |xk - xk_prev| = 3.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7020: |xk - xk_prev| = 3.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7025: |xk - xk_prev| = 3.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7030: |xk - xk_prev| = 3.66e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7035: |xk - xk_prev| = 3.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7040: |xk - xk_prev| = 3.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7045: |xk - xk_prev| = 3.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7050: |xk - xk_prev| = 3.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7055: |xk - xk_prev| = 3.65e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7060: |xk - xk_prev| = 3.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7065: |xk - xk_prev| = 3.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7070: |xk - xk_prev| = 3.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7075: |xk - xk_prev| = 3.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7080: |xk - xk_prev| = 3.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7085: |xk - xk_prev| = 3.64e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7090: |xk - xk_prev| = 3.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7095: |xk - xk_prev| = 3.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7100: |xk - xk_prev| = 3.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7105: |xk - xk_prev| = 3.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7110: |xk - xk_prev| = 3.63e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7115: |xk - xk_prev| = 3.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7120: |xk - xk_prev| = 3.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7125: |xk - xk_prev| = 3.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7130: |xk - xk_prev| = 3.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7135: |xk - xk_prev| = 3.62e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7140: |xk - xk_prev| = 3.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7145: |xk - xk_prev| = 3.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7150: |xk - xk_prev| = 3.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7155: |xk - xk_prev| = 3.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7160: |xk - xk_prev| = 3.61e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7165: |xk - xk_prev| = 3.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7170: |xk - xk_prev| = 3.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7175: |xk - xk_prev| = 3.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7180: |xk - xk_prev| = 3.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7185: |xk - xk_prev| = 3.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7190: |xk - xk_prev| = 3.60e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7195: |xk - xk_prev| = 3.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7200: |xk - xk_prev| = 3.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7205: |xk - xk_prev| = 3.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7210: |xk - xk_prev| = 3.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7215: |xk - xk_prev| = 3.59e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7220: |xk - xk_prev| = 3.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7225: |xk - xk_prev| = 3.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7230: |xk - xk_prev| = 3.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7235: |xk - xk_prev| = 3.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7240: |xk - xk_prev| = 3.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7245: |xk - xk_prev| = 3.58e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7250: |xk - xk_prev| = 3.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7255: |xk - xk_prev| = 3.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7260: |xk - xk_prev| = 3.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7265: |xk - xk_prev| = 3.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7270: |xk - xk_prev| = 3.57e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7275: |xk - xk_prev| = 3.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7280: |xk - xk_prev| = 3.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7285: |xk - xk_prev| = 3.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7290: |xk - xk_prev| = 3.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7295: |xk - xk_prev| = 3.56e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7300: |xk - xk_prev| = 3.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7305: |xk - xk_prev| = 3.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7310: |xk - xk_prev| = 3.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7315: |xk - xk_prev| = 3.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7320: |xk - xk_prev| = 3.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7325: |xk - xk_prev| = 3.55e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7330: |xk - xk_prev| = 3.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7335: |xk - xk_prev| = 3.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7340: |xk - xk_prev| = 3.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7345: |xk - xk_prev| = 3.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7350: |xk - xk_prev| = 3.54e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7355: |xk - xk_prev| = 3.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7360: |xk - xk_prev| = 3.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7365: |xk - xk_prev| = 3.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7370: |xk - xk_prev| = 3.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7375: |xk - xk_prev| = 3.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7380: |xk - xk_prev| = 3.53e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7385: |xk - xk_prev| = 3.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7390: |xk - xk_prev| = 3.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7395: |xk - xk_prev| = 3.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7400: |xk - xk_prev| = 3.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7405: |xk - xk_prev| = 3.52e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7410: |xk - xk_prev| = 3.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7415: |xk - xk_prev| = 3.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7420: |xk - xk_prev| = 3.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7425: |xk - xk_prev| = 3.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7430: |xk - xk_prev| = 3.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7435: |xk - xk_prev| = 3.51e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7440: |xk - xk_prev| = 3.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7445: |xk - xk_prev| = 3.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7450: |xk - xk_prev| = 3.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7455: |xk - xk_prev| = 3.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7460: |xk - xk_prev| = 3.50e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7465: |xk - xk_prev| = 3.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7470: |xk - xk_prev| = 3.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7475: |xk - xk_prev| = 3.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7480: |xk - xk_prev| = 3.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7485: |xk - xk_prev| = 3.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7490: |xk - xk_prev| = 3.49e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7495: |xk - xk_prev| = 3.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7500: |xk - xk_prev| = 3.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7505: |xk - xk_prev| = 3.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7510: |xk - xk_prev| = 3.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7515: |xk - xk_prev| = 3.48e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7520: |xk - xk_prev| = 3.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7525: |xk - xk_prev| = 3.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7530: |xk - xk_prev| = 3.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7535: |xk - xk_prev| = 3.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7540: |xk - xk_prev| = 3.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7545: |xk - xk_prev| = 3.47e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7550: |xk - xk_prev| = 3.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7555: |xk - xk_prev| = 3.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7560: |xk - xk_prev| = 3.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7565: |xk - xk_prev| = 3.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7570: |xk - xk_prev| = 3.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7575: |xk - xk_prev| = 3.46e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7580: |xk - xk_prev| = 3.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7585: |xk - xk_prev| = 3.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7590: |xk - xk_prev| = 3.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7595: |xk - xk_prev| = 3.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7600: |xk - xk_prev| = 3.45e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7605: |xk - xk_prev| = 3.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7610: |xk - xk_prev| = 3.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7615: |xk - xk_prev| = 3.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7620: |xk - xk_prev| = 3.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7625: |xk - xk_prev| = 3.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7630: |xk - xk_prev| = 3.44e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7635: |xk - xk_prev| = 3.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7640: |xk - xk_prev| = 3.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7645: |xk - xk_prev| = 3.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7650: |xk - xk_prev| = 3.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7655: |xk - xk_prev| = 3.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7660: |xk - xk_prev| = 3.43e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7665: |xk - xk_prev| = 3.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7670: |xk - xk_prev| = 3.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7675: |xk - xk_prev| = 3.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7680: |xk - xk_prev| = 3.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7685: |xk - xk_prev| = 3.42e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7690: |xk - xk_prev| = 3.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7695: |xk - xk_prev| = 3.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7700: |xk - xk_prev| = 3.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7705: |xk - xk_prev| = 3.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7710: |xk - xk_prev| = 3.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7715: |xk - xk_prev| = 3.41e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7720: |xk - xk_prev| = 3.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7725: |xk - xk_prev| = 3.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7730: |xk - xk_prev| = 3.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7735: |xk - xk_prev| = 3.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7740: |xk - xk_prev| = 3.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7745: |xk - xk_prev| = 3.40e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7750: |xk - xk_prev| = 3.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7755: |xk - xk_prev| = 3.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7760: |xk - xk_prev| = 3.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7765: |xk - xk_prev| = 3.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7770: |xk - xk_prev| = 3.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7775: |xk - xk_prev| = 3.39e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7780: |xk - xk_prev| = 3.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7785: |xk - xk_prev| = 3.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7790: |xk - xk_prev| = 3.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7795: |xk - xk_prev| = 3.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7800: |xk - xk_prev| = 3.38e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7805: |xk - xk_prev| = 3.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7810: |xk - xk_prev| = 3.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7815: |xk - xk_prev| = 3.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7820: |xk - xk_prev| = 3.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7825: |xk - xk_prev| = 3.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7830: |xk - xk_prev| = 3.37e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7835: |xk - xk_prev| = 3.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7840: |xk - xk_prev| = 3.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7845: |xk - xk_prev| = 3.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7850: |xk - xk_prev| = 3.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7855: |xk - xk_prev| = 3.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7860: |xk - xk_prev| = 3.36e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7865: |xk - xk_prev| = 3.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7870: |xk - xk_prev| = 3.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7875: |xk - xk_prev| = 3.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7880: |xk - xk_prev| = 3.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7885: |xk - xk_prev| = 3.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7890: |xk - xk_prev| = 3.35e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7895: |xk - xk_prev| = 3.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7900: |xk - xk_prev| = 3.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7905: |xk - xk_prev| = 3.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7910: |xk - xk_prev| = 3.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7915: |xk - xk_prev| = 3.34e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7920: |xk - xk_prev| = 3.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7925: |xk - xk_prev| = 3.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7930: |xk - xk_prev| = 3.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7935: |xk - xk_prev| = 3.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7940: |xk - xk_prev| = 3.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7945: |xk - xk_prev| = 3.33e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7950: |xk - xk_prev| = 3.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7955: |xk - xk_prev| = 3.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7960: |xk - xk_prev| = 3.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7965: |xk - xk_prev| = 3.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7970: |xk - xk_prev| = 3.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7975: |xk - xk_prev| = 3.32e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7980: |xk - xk_prev| = 3.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7985: |xk - xk_prev| = 3.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7990: |xk - xk_prev| = 3.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  7995: |xk - xk_prev| = 3.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8000: |xk - xk_prev| = 3.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8005: |xk - xk_prev| = 3.31e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8010: |xk - xk_prev| = 3.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8015: |xk - xk_prev| = 3.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8020: |xk - xk_prev| = 3.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8025: |xk - xk_prev| = 3.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8030: |xk - xk_prev| = 3.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8035: |xk - xk_prev| = 3.30e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8040: |xk - xk_prev| = 3.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8045: |xk - xk_prev| = 3.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8050: |xk - xk_prev| = 3.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8055: |xk - xk_prev| = 3.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8060: |xk - xk_prev| = 3.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8065: |xk - xk_prev| = 3.29e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8070: |xk - xk_prev| = 3.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8075: |xk - xk_prev| = 3.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8080: |xk - xk_prev| = 3.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8085: |xk - xk_prev| = 3.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8090: |xk - xk_prev| = 3.28e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8095: |xk - xk_prev| = 3.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8100: |xk - xk_prev| = 3.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8105: |xk - xk_prev| = 3.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8110: |xk - xk_prev| = 3.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8115: |xk - xk_prev| = 3.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8120: |xk - xk_prev| = 3.27e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8125: |xk - xk_prev| = 3.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8130: |xk - xk_prev| = 3.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8135: |xk - xk_prev| = 3.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8140: |xk - xk_prev| = 3.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8145: |xk - xk_prev| = 3.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8150: |xk - xk_prev| = 3.26e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8155: |xk - xk_prev| = 3.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8160: |xk - xk_prev| = 3.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8165: |xk - xk_prev| = 3.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8170: |xk - xk_prev| = 3.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8175: |xk - xk_prev| = 3.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8180: |xk - xk_prev| = 3.25e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8185: |xk - xk_prev| = 3.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8190: |xk - xk_prev| = 3.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8195: |xk - xk_prev| = 3.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8200: |xk - xk_prev| = 3.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8205: |xk - xk_prev| = 3.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8210: |xk - xk_prev| = 3.24e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8215: |xk - xk_prev| = 3.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8220: |xk - xk_prev| = 3.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8225: |xk - xk_prev| = 3.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8230: |xk - xk_prev| = 3.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8235: |xk - xk_prev| = 3.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8240: |xk - xk_prev| = 3.23e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8245: |xk - xk_prev| = 3.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8250: |xk - xk_prev| = 3.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8255: |xk - xk_prev| = 3.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8260: |xk - xk_prev| = 3.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8265: |xk - xk_prev| = 3.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8270: |xk - xk_prev| = 3.22e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8275: |xk - xk_prev| = 3.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8280: |xk - xk_prev| = 3.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8285: |xk - xk_prev| = 3.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8290: |xk - xk_prev| = 3.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8295: |xk - xk_prev| = 3.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8300: |xk - xk_prev| = 3.21e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8305: |xk - xk_prev| = 3.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8310: |xk - xk_prev| = 3.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8315: |xk - xk_prev| = 3.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8320: |xk - xk_prev| = 3.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8325: |xk - xk_prev| = 3.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8330: |xk - xk_prev| = 3.20e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8335: |xk - xk_prev| = 3.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8340: |xk - xk_prev| = 3.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8345: |xk - xk_prev| = 3.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8350: |xk - xk_prev| = 3.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8355: |xk - xk_prev| = 3.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8360: |xk - xk_prev| = 3.19e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8365: |xk - xk_prev| = 3.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8370: |xk - xk_prev| = 3.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8375: |xk - xk_prev| = 3.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8380: |xk - xk_prev| = 3.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8385: |xk - xk_prev| = 3.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8390: |xk - xk_prev| = 3.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8395: |xk - xk_prev| = 3.18e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8400: |xk - xk_prev| = 3.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8405: |xk - xk_prev| = 3.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8410: |xk - xk_prev| = 3.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8415: |xk - xk_prev| = 3.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8420: |xk - xk_prev| = 3.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8425: |xk - xk_prev| = 3.17e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8430: |xk - xk_prev| = 3.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8435: |xk - xk_prev| = 3.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8440: |xk - xk_prev| = 3.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8445: |xk - xk_prev| = 3.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8450: |xk - xk_prev| = 3.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8455: |xk - xk_prev| = 3.16e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8460: |xk - xk_prev| = 3.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8465: |xk - xk_prev| = 3.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8470: |xk - xk_prev| = 3.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8475: |xk - xk_prev| = 3.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8480: |xk - xk_prev| = 3.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8485: |xk - xk_prev| = 3.15e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8490: |xk - xk_prev| = 3.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8495: |xk - xk_prev| = 3.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8500: |xk - xk_prev| = 3.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8505: |xk - xk_prev| = 3.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8510: |xk - xk_prev| = 3.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8515: |xk - xk_prev| = 3.14e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8520: |xk - xk_prev| = 3.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8525: |xk - xk_prev| = 3.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8530: |xk - xk_prev| = 3.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8535: |xk - xk_prev| = 3.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8540: |xk - xk_prev| = 3.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8545: |xk - xk_prev| = 3.13e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8550: |xk - xk_prev| = 3.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8555: |xk - xk_prev| = 3.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8560: |xk - xk_prev| = 3.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8565: |xk - xk_prev| = 3.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8570: |xk - xk_prev| = 3.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8575: |xk - xk_prev| = 3.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8580: |xk - xk_prev| = 3.12e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8585: |xk - xk_prev| = 3.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8590: |xk - xk_prev| = 3.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8595: |xk - xk_prev| = 3.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8600: |xk - xk_prev| = 3.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8605: |xk - xk_prev| = 3.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8610: |xk - xk_prev| = 3.11e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8615: |xk - xk_prev| = 3.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8620: |xk - xk_prev| = 3.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8625: |xk - xk_prev| = 3.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8630: |xk - xk_prev| = 3.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8635: |xk - xk_prev| = 3.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8640: |xk - xk_prev| = 3.10e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8645: |xk - xk_prev| = 3.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8650: |xk - xk_prev| = 3.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8655: |xk - xk_prev| = 3.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8660: |xk - xk_prev| = 3.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8665: |xk - xk_prev| = 3.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8670: |xk - xk_prev| = 3.09e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8675: |xk - xk_prev| = 3.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8680: |xk - xk_prev| = 3.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8685: |xk - xk_prev| = 3.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8690: |xk - xk_prev| = 3.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8695: |xk - xk_prev| = 3.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8700: |xk - xk_prev| = 3.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8705: |xk - xk_prev| = 3.08e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8710: |xk - xk_prev| = 3.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8715: |xk - xk_prev| = 3.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8720: |xk - xk_prev| = 3.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8725: |xk - xk_prev| = 3.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8730: |xk - xk_prev| = 3.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8735: |xk - xk_prev| = 3.07e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8740: |xk - xk_prev| = 3.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8745: |xk - xk_prev| = 3.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8750: |xk - xk_prev| = 3.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8755: |xk - xk_prev| = 3.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8760: |xk - xk_prev| = 3.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8765: |xk - xk_prev| = 3.06e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8770: |xk - xk_prev| = 3.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8775: |xk - xk_prev| = 3.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8780: |xk - xk_prev| = 3.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8785: |xk - xk_prev| = 3.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8790: |xk - xk_prev| = 3.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8795: |xk - xk_prev| = 3.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8800: |xk - xk_prev| = 3.05e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8805: |xk - xk_prev| = 3.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8810: |xk - xk_prev| = 3.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8815: |xk - xk_prev| = 3.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8820: |xk - xk_prev| = 3.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8825: |xk - xk_prev| = 3.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8830: |xk - xk_prev| = 3.04e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8835: |xk - xk_prev| = 3.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8840: |xk - xk_prev| = 3.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8845: |xk - xk_prev| = 3.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8850: |xk - xk_prev| = 3.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8855: |xk - xk_prev| = 3.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8860: |xk - xk_prev| = 3.03e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8865: |xk - xk_prev| = 3.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8870: |xk - xk_prev| = 3.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8875: |xk - xk_prev| = 3.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8880: |xk - xk_prev| = 3.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8885: |xk - xk_prev| = 3.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8890: |xk - xk_prev| = 3.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8895: |xk - xk_prev| = 3.02e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8900: |xk - xk_prev| = 3.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8905: |xk - xk_prev| = 3.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8910: |xk - xk_prev| = 3.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8915: |xk - xk_prev| = 3.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8920: |xk - xk_prev| = 3.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8925: |xk - xk_prev| = 3.01e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8930: |xk - xk_prev| = 3.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8935: |xk - xk_prev| = 3.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8940: |xk - xk_prev| = 3.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8945: |xk - xk_prev| = 3.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8950: |xk - xk_prev| = 3.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8955: |xk - xk_prev| = 3.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8960: |xk - xk_prev| = 3.00e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8965: |xk - xk_prev| = 2.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8970: |xk - xk_prev| = 2.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8975: |xk - xk_prev| = 2.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8980: |xk - xk_prev| = 2.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8985: |xk - xk_prev| = 2.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8990: |xk - xk_prev| = 2.99e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  8995: |xk - xk_prev| = 2.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9000: |xk - xk_prev| = 2.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9005: |xk - xk_prev| = 2.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9010: |xk - xk_prev| = 2.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9015: |xk - xk_prev| = 2.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9020: |xk - xk_prev| = 2.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9025: |xk - xk_prev| = 2.98e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9030: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9035: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9040: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9045: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9050: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9055: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9060: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9065: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9070: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9075: |xk - xk_prev| = 2.97e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9080: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9085: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9090: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9095: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9100: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9105: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9110: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9115: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9120: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9125: |xk - xk_prev| = 2.96e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9130: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9135: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9140: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9145: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9150: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9155: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9160: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9165: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9170: |xk - xk_prev| = 2.95e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9175: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9180: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9185: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9190: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9195: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9200: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9205: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9210: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9215: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9220: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9225: |xk - xk_prev| = 2.94e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9230: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9235: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9240: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9245: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9250: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9255: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9260: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9265: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9270: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9275: |xk - xk_prev| = 2.93e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9280: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9285: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9290: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9295: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9300: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9305: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9310: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9315: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9320: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9325: |xk - xk_prev| = 2.92e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9330: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9335: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9340: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9345: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9350: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9355: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9360: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9365: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9370: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9375: |xk - xk_prev| = 2.91e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9380: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9385: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9390: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9395: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9400: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9405: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9410: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9415: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9420: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9425: |xk - xk_prev| = 2.90e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9430: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9435: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9440: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9445: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9450: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9455: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9460: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9465: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9470: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9475: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9480: |xk - xk_prev| = 2.89e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9485: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9490: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9495: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9500: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9505: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9510: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9515: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9520: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9525: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9530: |xk - xk_prev| = 2.88e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9535: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9540: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9545: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9550: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9555: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9560: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9565: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9570: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9575: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9580: |xk - xk_prev| = 2.87e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9585: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9590: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9595: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9600: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9605: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9610: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9615: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9620: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9625: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9630: |xk - xk_prev| = 2.86e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9635: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9640: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9645: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9650: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9655: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9660: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9665: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9670: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9675: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9680: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9685: |xk - xk_prev| = 2.85e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9690: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9695: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9700: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9705: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9710: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9715: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9720: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9725: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9730: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9735: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9740: |xk - xk_prev| = 2.84e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9745: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9750: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9755: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9760: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9765: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9770: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9775: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9780: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9785: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9790: |xk - xk_prev| = 2.83e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9795: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9800: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9805: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9810: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9815: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9820: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9825: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9830: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9835: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9840: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9845: |xk - xk_prev| = 2.82e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9850: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9855: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9860: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9865: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9870: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9875: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9880: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9885: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9890: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9895: |xk - xk_prev| = 2.81e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9900: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9905: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9910: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9915: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9920: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9925: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9930: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9935: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9940: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9945: |xk - xk_prev| = 2.80e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9950: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9955: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9960: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9965: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9970: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9975: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9980: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9985: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9990: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step  9995: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n",
            "Step 10000: |xk - xk_prev| = 2.79e-04   x[0,:] = tensor([0.5996, 0.3768, 0.0236, 0.5996, 0.3768, 0.0236])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pYzQz8IYjtZ"
      },
      "source": [
        "## Define N-FPN for Rock Paper Scissors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dcNDG7JUFsm"
      },
      "source": [
        "class RPS_Net(nn.Module):\n",
        "    def __init__(self, action_size=6, context_size=3):\n",
        "        super(RPS_Net, self).__init__()\n",
        "        self.fc_1 = nn.Linear(action_size + context_size, 5 * action_size)\n",
        "        self.fc_2 = nn.Linear(5 * action_size, action_size)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "        self.action_size = action_size\n",
        "\n",
        "\n",
        "    def device(self) -> str:\n",
        "        return next(self.parameters()).data.device\n",
        "\n",
        "\n",
        "    def F(self, x: action, d: context) -> action:\n",
        "        xd  = torch.cat((x,d), dim=1)\n",
        "        Fxd = x + self.fc_2(self.leaky_relu(self.fc_1(xd))) \n",
        "        return Fxd\n",
        "\n",
        "\n",
        "    def project_simplex(self, y: action, action_size=3, num_players=2) -> action:\n",
        "        num_samples = y.shape[0] \n",
        "        proj        = torch.zeros(y.shape)\n",
        "        for i in range(num_players):\n",
        "            ind   = [i * action_size + j for j in range(action_size)]\n",
        "            u     = torch.flip(torch.sort(y[:, ind], dim=1)[0], dims=(1,))\n",
        "            u_sum = torch.cumsum(u, dim=1)\n",
        "            j     = torch.arange(1, action_size + 1, dtype=y.dtype, device=y.device)\n",
        "            pos_u_expr   = u * j + 1.0 - u_sum  > 0 \n",
        "            pos_u_expr   = pos_u_expr.float() \n",
        "            rho          = torch.sum(pos_u_expr, dim=1, keepdim=True)\n",
        "            rho          = rho.long()\n",
        "            lambd        = [(1 - u_sum[sample, rho[sample]-1]) / rho[sample] \n",
        "                            for sample in range(num_samples)]\n",
        "            lambd        = torch.tensor(lambd)\n",
        "            lambd        = lambd.view(lambd.shape[0], 1)\n",
        "            proj[:, ind] = torch.clamp(y[:, ind] + lambd, min=0)\n",
        "        return proj\n",
        "\n",
        "\n",
        "    def forward(self, d: context, fxd_pt_tol=1.0e-5, max_depth=100, \n",
        "                depth_warning=False) -> action: \n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.depth = 0.0\n",
        "            x = torch.zeros((d.shape[0], self.action_size), device=self.device())\n",
        "            x_prev = np.Inf * torch.ones(x.shape, device=self.device())            \n",
        "            all_samp_conv = False\n",
        "            while not all_samp_conv and self.depth < max_depth:\n",
        "                x_prev        = x.clone()   \n",
        "                x             = self.project_simplex(x - self.F(x,d))\n",
        "                res_norm      = torch.max(torch.norm(x - x_prev, dim=1)) \n",
        "                self.depth   += 1.0\n",
        "                all_samp_conv = res_norm <= fxd_pt_tol\n",
        "            \n",
        "        if self.depth >= max_depth and depth_warning:\n",
        "            print(\"\\nWarning: Max Depth Reached - Break Forward Loop\\n\")\n",
        "\n",
        "        attach_gradients = self.training\n",
        "        return self.project_simplex(x - self.F(x,d)) if attach_gradients else x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vW20FtInMT4"
      },
      "source": [
        "## Create Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhdA4WGRWqU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf66eca-5755-49bb-ef65-01ed8f3c97a1"
      },
      "source": [
        "model         = RPS_Net()\n",
        "learning_rate = 1e-3\n",
        "optimizer     = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "fxd_pt_tol    = 1.0e-6  \n",
        "criterion     = nn.MSELoss()\n",
        "max_epochs    = 1000 \n",
        "save_str      = 'NFPN_RPS_data.pth'\n",
        "\n",
        "def num_params(model):\n",
        "    num_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        num_params += parameter.numel()\n",
        "    return num_params\n",
        "\n",
        "print(\"Trainable Parameters: \", num_params(model))\n",
        "print(model)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable Parameters:  486\n",
            "RPS_Net(\n",
            "  (fc_1): Linear(in_features=9, out_features=30, bias=True)\n",
            "  (fc_2): Linear(in_features=30, out_features=6, bias=True)\n",
            "  (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwA-w5YznPss"
      },
      "source": [
        "## Train the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbbXjMFSWtHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5cd008-fed9-4a88-8193-e73efb977973"
      },
      "source": [
        "test_loss_hist  = []  \n",
        "train_loss_hist = [] \n",
        "depth_hist      = [] \n",
        "train_loss_ave  = 0\n",
        "\n",
        "fmt  = '[{:4d}/{:4d}]: train loss = {:7.3e} | test_loss = {:7.3e} | depth ' \n",
        "fmt += '= {:5.1f} | lr = {:5.1e} | fxt_pt_tol = {:5.1e} | time = {:4.1f} sec' \n",
        "print('\\nTraining Fixed Point Network')\n",
        "\n",
        "for epoch in range(max_epochs): \n",
        "    start_time = time.time()\n",
        "    for x_batch, d_batch in train_loader:  \n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        x_pred = model(d_batch, fxd_pt_tol=fxd_pt_tol) \n",
        "        loss   = criterion(x_pred, x_batch)\n",
        "        train_loss_ave = 0.95 * train_loss_ave + 0.05 * loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()  \n",
        "\n",
        "    for x_batch, d_batch in test_loader:\n",
        "        with torch.no_grad():\n",
        "            x_pred    = model(d_batch, fxd_pt_tol=fxd_pt_tol)   \n",
        "            test_loss = criterion(x_pred, x_batch)\n",
        "    \n",
        "    time_epoch = time.time() - start_time\n",
        "\n",
        "    print(fmt.format(epoch+1, max_epochs, train_loss_ave, test_loss.item(), \n",
        "                     model.depth, optimizer.param_groups[0]['lr'], fxd_pt_tol, \n",
        "                     time_epoch))\n",
        "    \n",
        "    test_loss_hist.append(test_loss.item())\n",
        "    train_loss_hist.append(loss.item())\n",
        "    depth_hist.append(model.depth)\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == max_epochs-1:\n",
        "        state = {\n",
        "        'fxd_pt_tol': fxd_pt_tol,\n",
        "        'T_state_dict': model.state_dict(),\n",
        "        'test_loss_hist': test_loss_hist,\n",
        "        'train_loss_hist': train_loss_hist,\n",
        "        'depth_hist': depth_hist\n",
        "        }\n",
        "        torch.save(state, save_str)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Fixed Point Network\n",
            "[   1/1000]: train loss = 8.473e-03 | test_loss = 3.118e-02 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[   2/1000]: train loss = 1.275e-02 | test_loss = 2.256e-02 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[   3/1000]: train loss = 1.429e-02 | test_loss = 1.587e-02 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[   4/1000]: train loss = 1.413e-02 | test_loss = 1.077e-02 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[   5/1000]: train loss = 1.299e-02 | test_loss = 6.964e-03 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[   6/1000]: train loss = 1.136e-02 | test_loss = 4.261e-03 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.1 sec\n",
            "[   7/1000]: train loss = 9.587e-03 | test_loss = 2.497e-03 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[   8/1000]: train loss = 7.895e-03 | test_loss = 1.482e-03 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[   9/1000]: train loss = 6.408e-03 | test_loss = 9.918e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  10/1000]: train loss = 5.173e-03 | test_loss = 7.896e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  11/1000]: train loss = 4.179e-03 | test_loss = 7.058e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  12/1000]: train loss = 3.393e-03 | test_loss = 6.551e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  13/1000]: train loss = 2.770e-03 | test_loss = 6.008e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[  14/1000]: train loss = 2.275e-03 | test_loss = 5.437e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  15/1000]: train loss = 1.878e-03 | test_loss = 4.921e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[  16/1000]: train loss = 1.558e-03 | test_loss = 4.490e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  17/1000]: train loss = 1.301e-03 | test_loss = 4.150e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  18/1000]: train loss = 1.093e-03 | test_loss = 3.787e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[  19/1000]: train loss = 9.246e-04 | test_loss = 3.438e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  20/1000]: train loss = 7.873e-04 | test_loss = 3.099e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  21/1000]: train loss = 6.750e-04 | test_loss = 2.802e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  22/1000]: train loss = 5.838e-04 | test_loss = 2.603e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  23/1000]: train loss = 5.095e-04 | test_loss = 2.436e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[  24/1000]: train loss = 4.489e-04 | test_loss = 2.280e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  25/1000]: train loss = 3.992e-04 | test_loss = 2.158e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[  26/1000]: train loss = 3.585e-04 | test_loss = 2.062e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  27/1000]: train loss = 3.249e-04 | test_loss = 1.966e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  28/1000]: train loss = 2.972e-04 | test_loss = 1.896e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  29/1000]: train loss = 2.741e-04 | test_loss = 1.821e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  30/1000]: train loss = 2.547e-04 | test_loss = 1.768e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  31/1000]: train loss = 2.385e-04 | test_loss = 1.727e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  32/1000]: train loss = 2.246e-04 | test_loss = 1.672e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  33/1000]: train loss = 2.128e-04 | test_loss = 1.631e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[  34/1000]: train loss = 2.024e-04 | test_loss = 1.580e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  35/1000]: train loss = 1.933e-04 | test_loss = 1.545e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  36/1000]: train loss = 1.852e-04 | test_loss = 1.513e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[  37/1000]: train loss = 1.779e-04 | test_loss = 1.477e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  38/1000]: train loss = 1.712e-04 | test_loss = 1.426e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  39/1000]: train loss = 1.647e-04 | test_loss = 1.389e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  40/1000]: train loss = 1.587e-04 | test_loss = 1.353e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  41/1000]: train loss = 1.528e-04 | test_loss = 1.302e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  42/1000]: train loss = 1.471e-04 | test_loss = 1.258e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  43/1000]: train loss = 1.417e-04 | test_loss = 1.214e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  44/1000]: train loss = 1.365e-04 | test_loss = 1.179e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  45/1000]: train loss = 1.313e-04 | test_loss = 1.124e-04 | depth =  13.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  46/1000]: train loss = 1.263e-04 | test_loss = 1.077e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  47/1000]: train loss = 1.213e-04 | test_loss = 1.047e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  48/1000]: train loss = 1.165e-04 | test_loss = 1.004e-04 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  49/1000]: train loss = 1.118e-04 | test_loss = 9.597e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  50/1000]: train loss = 1.072e-04 | test_loss = 9.213e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  51/1000]: train loss = 1.026e-04 | test_loss = 8.941e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  52/1000]: train loss = 9.827e-05 | test_loss = 8.576e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  53/1000]: train loss = 9.401e-05 | test_loss = 8.182e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  54/1000]: train loss = 9.000e-05 | test_loss = 7.928e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  55/1000]: train loss = 8.614e-05 | test_loss = 7.661e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  56/1000]: train loss = 8.251e-05 | test_loss = 7.386e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  57/1000]: train loss = 7.916e-05 | test_loss = 7.118e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  58/1000]: train loss = 7.622e-05 | test_loss = 6.979e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  59/1000]: train loss = 7.355e-05 | test_loss = 6.779e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  60/1000]: train loss = 7.105e-05 | test_loss = 6.528e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  61/1000]: train loss = 6.880e-05 | test_loss = 6.474e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  62/1000]: train loss = 6.675e-05 | test_loss = 6.228e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  63/1000]: train loss = 6.489e-05 | test_loss = 6.152e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  64/1000]: train loss = 6.323e-05 | test_loss = 6.026e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  65/1000]: train loss = 6.174e-05 | test_loss = 5.852e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  66/1000]: train loss = 6.039e-05 | test_loss = 5.664e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  67/1000]: train loss = 5.922e-05 | test_loss = 5.739e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  68/1000]: train loss = 5.795e-05 | test_loss = 5.457e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  69/1000]: train loss = 5.690e-05 | test_loss = 5.413e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  70/1000]: train loss = 5.580e-05 | test_loss = 5.326e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  71/1000]: train loss = 5.479e-05 | test_loss = 5.114e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[  72/1000]: train loss = 5.384e-05 | test_loss = 5.142e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  73/1000]: train loss = 5.290e-05 | test_loss = 5.018e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  74/1000]: train loss = 5.203e-05 | test_loss = 4.860e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  75/1000]: train loss = 5.128e-05 | test_loss = 4.782e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  76/1000]: train loss = 5.057e-05 | test_loss = 4.806e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[  77/1000]: train loss = 4.989e-05 | test_loss = 4.582e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  78/1000]: train loss = 4.925e-05 | test_loss = 4.593e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[  79/1000]: train loss = 4.854e-05 | test_loss = 4.529e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  80/1000]: train loss = 4.791e-05 | test_loss = 4.412e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  81/1000]: train loss = 4.735e-05 | test_loss = 4.502e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  82/1000]: train loss = 4.683e-05 | test_loss = 4.295e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[  83/1000]: train loss = 4.645e-05 | test_loss = 4.426e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  84/1000]: train loss = 4.595e-05 | test_loss = 4.236e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  85/1000]: train loss = 4.544e-05 | test_loss = 4.383e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  86/1000]: train loss = 4.498e-05 | test_loss = 4.213e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  87/1000]: train loss = 4.456e-05 | test_loss = 4.218e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  88/1000]: train loss = 4.418e-05 | test_loss = 4.239e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  89/1000]: train loss = 4.381e-05 | test_loss = 4.120e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  90/1000]: train loss = 4.352e-05 | test_loss = 4.169e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  91/1000]: train loss = 4.321e-05 | test_loss = 4.191e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  92/1000]: train loss = 4.298e-05 | test_loss = 3.998e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  93/1000]: train loss = 4.267e-05 | test_loss = 4.121e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  94/1000]: train loss = 4.235e-05 | test_loss = 4.018e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[  95/1000]: train loss = 4.208e-05 | test_loss = 3.972e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  96/1000]: train loss = 4.194e-05 | test_loss = 4.007e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  97/1000]: train loss = 4.163e-05 | test_loss = 3.919e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[  98/1000]: train loss = 4.143e-05 | test_loss = 3.887e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[  99/1000]: train loss = 4.125e-05 | test_loss = 3.982e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 100/1000]: train loss = 4.102e-05 | test_loss = 3.758e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 101/1000]: train loss = 4.086e-05 | test_loss = 3.995e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 102/1000]: train loss = 4.065e-05 | test_loss = 3.779e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 103/1000]: train loss = 4.045e-05 | test_loss = 3.794e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 104/1000]: train loss = 4.023e-05 | test_loss = 3.822e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 105/1000]: train loss = 3.998e-05 | test_loss = 3.707e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 106/1000]: train loss = 3.978e-05 | test_loss = 3.789e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 107/1000]: train loss = 3.963e-05 | test_loss = 3.676e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 108/1000]: train loss = 3.943e-05 | test_loss = 3.717e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 109/1000]: train loss = 3.917e-05 | test_loss = 3.738e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 110/1000]: train loss = 3.903e-05 | test_loss = 3.557e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 111/1000]: train loss = 3.885e-05 | test_loss = 3.731e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 112/1000]: train loss = 3.866e-05 | test_loss = 3.617e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 113/1000]: train loss = 3.842e-05 | test_loss = 3.634e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 114/1000]: train loss = 3.826e-05 | test_loss = 3.595e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 115/1000]: train loss = 3.812e-05 | test_loss = 3.545e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 116/1000]: train loss = 3.803e-05 | test_loss = 3.568e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 117/1000]: train loss = 3.796e-05 | test_loss = 3.598e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 118/1000]: train loss = 3.789e-05 | test_loss = 3.432e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 119/1000]: train loss = 3.769e-05 | test_loss = 3.603e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 120/1000]: train loss = 3.752e-05 | test_loss = 3.478e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 121/1000]: train loss = 3.735e-05 | test_loss = 3.506e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 122/1000]: train loss = 3.729e-05 | test_loss = 3.443e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 123/1000]: train loss = 3.718e-05 | test_loss = 3.382e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 124/1000]: train loss = 3.695e-05 | test_loss = 3.528e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 125/1000]: train loss = 3.679e-05 | test_loss = 3.358e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 126/1000]: train loss = 3.672e-05 | test_loss = 3.344e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 127/1000]: train loss = 3.663e-05 | test_loss = 3.429e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 128/1000]: train loss = 3.639e-05 | test_loss = 3.335e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 129/1000]: train loss = 3.621e-05 | test_loss = 3.332e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 130/1000]: train loss = 3.605e-05 | test_loss = 3.384e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 131/1000]: train loss = 3.593e-05 | test_loss = 3.286e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 132/1000]: train loss = 3.576e-05 | test_loss = 3.326e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 133/1000]: train loss = 3.563e-05 | test_loss = 3.278e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 134/1000]: train loss = 3.551e-05 | test_loss = 3.316e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 135/1000]: train loss = 3.543e-05 | test_loss = 3.221e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 136/1000]: train loss = 3.531e-05 | test_loss = 3.279e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 137/1000]: train loss = 3.524e-05 | test_loss = 3.287e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 138/1000]: train loss = 3.509e-05 | test_loss = 3.187e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 139/1000]: train loss = 3.497e-05 | test_loss = 3.188e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 140/1000]: train loss = 3.479e-05 | test_loss = 3.203e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 141/1000]: train loss = 3.473e-05 | test_loss = 3.203e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 142/1000]: train loss = 3.461e-05 | test_loss = 3.141e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 143/1000]: train loss = 3.446e-05 | test_loss = 3.181e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 144/1000]: train loss = 3.435e-05 | test_loss = 3.186e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 145/1000]: train loss = 3.416e-05 | test_loss = 3.048e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 146/1000]: train loss = 3.407e-05 | test_loss = 3.185e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 147/1000]: train loss = 3.390e-05 | test_loss = 3.066e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 148/1000]: train loss = 3.380e-05 | test_loss = 3.132e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 149/1000]: train loss = 3.374e-05 | test_loss = 3.078e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 150/1000]: train loss = 3.370e-05 | test_loss = 3.042e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 151/1000]: train loss = 3.360e-05 | test_loss = 3.085e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 152/1000]: train loss = 3.345e-05 | test_loss = 3.017e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 153/1000]: train loss = 3.327e-05 | test_loss = 3.007e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 154/1000]: train loss = 3.312e-05 | test_loss = 3.049e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 155/1000]: train loss = 3.304e-05 | test_loss = 2.970e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 156/1000]: train loss = 3.301e-05 | test_loss = 2.996e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 157/1000]: train loss = 3.290e-05 | test_loss = 2.984e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 158/1000]: train loss = 3.280e-05 | test_loss = 2.947e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 159/1000]: train loss = 3.273e-05 | test_loss = 3.003e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 160/1000]: train loss = 3.259e-05 | test_loss = 2.936e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 161/1000]: train loss = 3.251e-05 | test_loss = 2.955e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 162/1000]: train loss = 3.242e-05 | test_loss = 2.879e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 163/1000]: train loss = 3.231e-05 | test_loss = 2.873e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 164/1000]: train loss = 3.222e-05 | test_loss = 2.908e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 165/1000]: train loss = 3.211e-05 | test_loss = 2.923e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 166/1000]: train loss = 3.213e-05 | test_loss = 2.810e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 167/1000]: train loss = 3.210e-05 | test_loss = 2.903e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 168/1000]: train loss = 3.198e-05 | test_loss = 2.783e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 169/1000]: train loss = 3.189e-05 | test_loss = 2.896e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 170/1000]: train loss = 3.167e-05 | test_loss = 2.800e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 171/1000]: train loss = 3.161e-05 | test_loss = 2.839e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 172/1000]: train loss = 3.154e-05 | test_loss = 2.805e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 173/1000]: train loss = 3.142e-05 | test_loss = 2.803e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 174/1000]: train loss = 3.128e-05 | test_loss = 2.768e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 175/1000]: train loss = 3.130e-05 | test_loss = 2.749e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 176/1000]: train loss = 3.119e-05 | test_loss = 2.767e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 177/1000]: train loss = 3.102e-05 | test_loss = 2.764e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 178/1000]: train loss = 3.089e-05 | test_loss = 2.767e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 179/1000]: train loss = 3.081e-05 | test_loss = 2.702e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 180/1000]: train loss = 3.079e-05 | test_loss = 2.722e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 181/1000]: train loss = 3.068e-05 | test_loss = 2.711e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 182/1000]: train loss = 3.055e-05 | test_loss = 2.676e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 183/1000]: train loss = 3.047e-05 | test_loss = 2.678e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 184/1000]: train loss = 3.039e-05 | test_loss = 2.644e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 185/1000]: train loss = 3.018e-05 | test_loss = 2.684e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 186/1000]: train loss = 3.013e-05 | test_loss = 2.607e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 187/1000]: train loss = 3.003e-05 | test_loss = 2.674e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 188/1000]: train loss = 3.001e-05 | test_loss = 2.582e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 189/1000]: train loss = 2.986e-05 | test_loss = 2.713e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 190/1000]: train loss = 2.976e-05 | test_loss = 2.570e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 191/1000]: train loss = 2.970e-05 | test_loss = 2.608e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 192/1000]: train loss = 2.961e-05 | test_loss = 2.574e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 193/1000]: train loss = 2.955e-05 | test_loss = 2.499e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 194/1000]: train loss = 2.946e-05 | test_loss = 2.580e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 195/1000]: train loss = 2.931e-05 | test_loss = 2.547e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 196/1000]: train loss = 2.919e-05 | test_loss = 2.516e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 197/1000]: train loss = 2.909e-05 | test_loss = 2.513e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 198/1000]: train loss = 2.899e-05 | test_loss = 2.513e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 199/1000]: train loss = 2.890e-05 | test_loss = 2.413e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 200/1000]: train loss = 2.891e-05 | test_loss = 2.522e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 201/1000]: train loss = 2.874e-05 | test_loss = 2.398e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 202/1000]: train loss = 2.857e-05 | test_loss = 2.481e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 203/1000]: train loss = 2.847e-05 | test_loss = 2.375e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 204/1000]: train loss = 2.838e-05 | test_loss = 2.378e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 205/1000]: train loss = 2.832e-05 | test_loss = 2.406e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 206/1000]: train loss = 2.824e-05 | test_loss = 2.305e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 207/1000]: train loss = 2.813e-05 | test_loss = 2.442e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 208/1000]: train loss = 2.802e-05 | test_loss = 2.288e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 209/1000]: train loss = 2.792e-05 | test_loss = 2.369e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 210/1000]: train loss = 2.784e-05 | test_loss = 2.317e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 211/1000]: train loss = 2.777e-05 | test_loss = 2.339e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 212/1000]: train loss = 2.767e-05 | test_loss = 2.275e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 213/1000]: train loss = 2.759e-05 | test_loss = 2.283e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 214/1000]: train loss = 2.750e-05 | test_loss = 2.323e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 215/1000]: train loss = 2.736e-05 | test_loss = 2.258e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 216/1000]: train loss = 2.721e-05 | test_loss = 2.269e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 217/1000]: train loss = 2.713e-05 | test_loss = 2.180e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 218/1000]: train loss = 2.701e-05 | test_loss = 2.263e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 219/1000]: train loss = 2.695e-05 | test_loss = 2.195e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 220/1000]: train loss = 2.685e-05 | test_loss = 2.230e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 221/1000]: train loss = 2.672e-05 | test_loss = 2.150e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 222/1000]: train loss = 2.664e-05 | test_loss = 2.170e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 223/1000]: train loss = 2.646e-05 | test_loss = 2.140e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 224/1000]: train loss = 2.634e-05 | test_loss = 2.150e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 225/1000]: train loss = 2.625e-05 | test_loss = 2.141e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 226/1000]: train loss = 2.620e-05 | test_loss = 2.049e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 227/1000]: train loss = 2.611e-05 | test_loss = 2.176e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 228/1000]: train loss = 2.601e-05 | test_loss = 2.034e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 229/1000]: train loss = 2.587e-05 | test_loss = 2.061e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 230/1000]: train loss = 2.575e-05 | test_loss = 2.066e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 231/1000]: train loss = 2.572e-05 | test_loss = 1.955e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 232/1000]: train loss = 2.559e-05 | test_loss = 2.117e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 233/1000]: train loss = 2.549e-05 | test_loss = 1.997e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 234/1000]: train loss = 2.540e-05 | test_loss = 2.027e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 235/1000]: train loss = 2.528e-05 | test_loss = 1.957e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 236/1000]: train loss = 2.516e-05 | test_loss = 2.016e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 237/1000]: train loss = 2.504e-05 | test_loss = 2.006e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 238/1000]: train loss = 2.489e-05 | test_loss = 1.950e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 239/1000]: train loss = 2.477e-05 | test_loss = 1.913e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 240/1000]: train loss = 2.464e-05 | test_loss = 1.949e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 241/1000]: train loss = 2.451e-05 | test_loss = 1.920e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 242/1000]: train loss = 2.437e-05 | test_loss = 1.890e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 243/1000]: train loss = 2.433e-05 | test_loss = 1.906e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 244/1000]: train loss = 2.420e-05 | test_loss = 1.936e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 245/1000]: train loss = 2.412e-05 | test_loss = 1.834e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 246/1000]: train loss = 2.400e-05 | test_loss = 1.897e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 247/1000]: train loss = 2.382e-05 | test_loss = 1.839e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 248/1000]: train loss = 2.368e-05 | test_loss = 1.858e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 249/1000]: train loss = 2.350e-05 | test_loss = 1.884e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 250/1000]: train loss = 2.337e-05 | test_loss = 1.837e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 251/1000]: train loss = 2.325e-05 | test_loss = 1.797e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 252/1000]: train loss = 2.317e-05 | test_loss = 1.853e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 253/1000]: train loss = 2.308e-05 | test_loss = 1.794e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 254/1000]: train loss = 2.294e-05 | test_loss = 1.792e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 255/1000]: train loss = 2.279e-05 | test_loss = 1.777e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 256/1000]: train loss = 2.267e-05 | test_loss = 1.747e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 257/1000]: train loss = 2.249e-05 | test_loss = 1.776e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 258/1000]: train loss = 2.235e-05 | test_loss = 1.736e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 259/1000]: train loss = 2.217e-05 | test_loss = 1.757e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 260/1000]: train loss = 2.198e-05 | test_loss = 1.679e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 261/1000]: train loss = 2.183e-05 | test_loss = 1.717e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 262/1000]: train loss = 2.168e-05 | test_loss = 1.690e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 263/1000]: train loss = 2.154e-05 | test_loss = 1.650e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 264/1000]: train loss = 2.139e-05 | test_loss = 1.638e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 265/1000]: train loss = 2.119e-05 | test_loss = 1.602e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 266/1000]: train loss = 2.102e-05 | test_loss = 1.637e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 267/1000]: train loss = 2.088e-05 | test_loss = 1.568e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 268/1000]: train loss = 2.071e-05 | test_loss = 1.604e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 269/1000]: train loss = 2.057e-05 | test_loss = 1.538e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 270/1000]: train loss = 2.045e-05 | test_loss = 1.588e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 271/1000]: train loss = 2.032e-05 | test_loss = 1.531e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 272/1000]: train loss = 2.016e-05 | test_loss = 1.552e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 273/1000]: train loss = 2.004e-05 | test_loss = 1.507e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 274/1000]: train loss = 1.993e-05 | test_loss = 1.483e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 275/1000]: train loss = 1.979e-05 | test_loss = 1.526e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 276/1000]: train loss = 1.969e-05 | test_loss = 1.480e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 277/1000]: train loss = 1.951e-05 | test_loss = 1.497e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 278/1000]: train loss = 1.939e-05 | test_loss = 1.454e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 279/1000]: train loss = 1.922e-05 | test_loss = 1.458e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 280/1000]: train loss = 1.907e-05 | test_loss = 1.444e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 281/1000]: train loss = 1.895e-05 | test_loss = 1.369e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 282/1000]: train loss = 1.883e-05 | test_loss = 1.447e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 283/1000]: train loss = 1.873e-05 | test_loss = 1.364e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 284/1000]: train loss = 1.858e-05 | test_loss = 1.408e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 285/1000]: train loss = 1.843e-05 | test_loss = 1.411e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 286/1000]: train loss = 1.826e-05 | test_loss = 1.337e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 287/1000]: train loss = 1.815e-05 | test_loss = 1.333e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 288/1000]: train loss = 1.806e-05 | test_loss = 1.363e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 289/1000]: train loss = 1.787e-05 | test_loss = 1.330e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 290/1000]: train loss = 1.776e-05 | test_loss = 1.367e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 291/1000]: train loss = 1.764e-05 | test_loss = 1.276e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 292/1000]: train loss = 1.754e-05 | test_loss = 1.305e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 293/1000]: train loss = 1.739e-05 | test_loss = 1.276e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 294/1000]: train loss = 1.728e-05 | test_loss = 1.292e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 295/1000]: train loss = 1.716e-05 | test_loss = 1.263e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 296/1000]: train loss = 1.706e-05 | test_loss = 1.289e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 297/1000]: train loss = 1.698e-05 | test_loss = 1.249e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 298/1000]: train loss = 1.685e-05 | test_loss = 1.261e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 299/1000]: train loss = 1.675e-05 | test_loss = 1.204e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 300/1000]: train loss = 1.668e-05 | test_loss = 1.311e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 301/1000]: train loss = 1.656e-05 | test_loss = 1.174e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 302/1000]: train loss = 1.646e-05 | test_loss = 1.214e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 303/1000]: train loss = 1.635e-05 | test_loss = 1.204e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 304/1000]: train loss = 1.627e-05 | test_loss = 1.200e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 305/1000]: train loss = 1.618e-05 | test_loss = 1.192e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 306/1000]: train loss = 1.608e-05 | test_loss = 1.186e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 307/1000]: train loss = 1.599e-05 | test_loss = 1.165e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 308/1000]: train loss = 1.591e-05 | test_loss = 1.192e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 309/1000]: train loss = 1.578e-05 | test_loss = 1.139e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 310/1000]: train loss = 1.573e-05 | test_loss = 1.213e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 311/1000]: train loss = 1.564e-05 | test_loss = 1.126e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 312/1000]: train loss = 1.558e-05 | test_loss = 1.190e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 313/1000]: train loss = 1.550e-05 | test_loss = 1.112e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 314/1000]: train loss = 1.539e-05 | test_loss = 1.179e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 315/1000]: train loss = 1.532e-05 | test_loss = 1.107e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 316/1000]: train loss = 1.524e-05 | test_loss = 1.165e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 317/1000]: train loss = 1.517e-05 | test_loss = 1.080e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 318/1000]: train loss = 1.508e-05 | test_loss = 1.162e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 319/1000]: train loss = 1.498e-05 | test_loss = 1.086e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 320/1000]: train loss = 1.488e-05 | test_loss = 1.124e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 321/1000]: train loss = 1.485e-05 | test_loss = 1.074e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 322/1000]: train loss = 1.479e-05 | test_loss = 1.140e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 323/1000]: train loss = 1.475e-05 | test_loss = 1.050e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 324/1000]: train loss = 1.469e-05 | test_loss = 1.184e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 325/1000]: train loss = 1.462e-05 | test_loss = 1.045e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 326/1000]: train loss = 1.456e-05 | test_loss = 1.120e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 327/1000]: train loss = 1.449e-05 | test_loss = 1.055e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 328/1000]: train loss = 1.444e-05 | test_loss = 1.126e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 329/1000]: train loss = 1.436e-05 | test_loss = 1.041e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 330/1000]: train loss = 1.429e-05 | test_loss = 1.038e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 331/1000]: train loss = 1.420e-05 | test_loss = 1.065e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 332/1000]: train loss = 1.415e-05 | test_loss = 1.046e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 333/1000]: train loss = 1.415e-05 | test_loss = 1.088e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 334/1000]: train loss = 1.408e-05 | test_loss = 1.033e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 335/1000]: train loss = 1.403e-05 | test_loss = 1.003e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 336/1000]: train loss = 1.398e-05 | test_loss = 1.057e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 337/1000]: train loss = 1.394e-05 | test_loss = 9.780e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 338/1000]: train loss = 1.390e-05 | test_loss = 1.089e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 339/1000]: train loss = 1.387e-05 | test_loss = 9.879e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 340/1000]: train loss = 1.382e-05 | test_loss = 1.064e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 341/1000]: train loss = 1.375e-05 | test_loss = 9.895e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 342/1000]: train loss = 1.370e-05 | test_loss = 1.014e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 343/1000]: train loss = 1.365e-05 | test_loss = 1.020e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 344/1000]: train loss = 1.361e-05 | test_loss = 1.012e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 345/1000]: train loss = 1.356e-05 | test_loss = 9.707e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 346/1000]: train loss = 1.349e-05 | test_loss = 1.067e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 347/1000]: train loss = 1.345e-05 | test_loss = 9.518e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 348/1000]: train loss = 1.340e-05 | test_loss = 9.954e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 349/1000]: train loss = 1.337e-05 | test_loss = 9.724e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 350/1000]: train loss = 1.329e-05 | test_loss = 9.608e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 351/1000]: train loss = 1.326e-05 | test_loss = 9.918e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 352/1000]: train loss = 1.323e-05 | test_loss = 9.502e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 353/1000]: train loss = 1.319e-05 | test_loss = 9.535e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 354/1000]: train loss = 1.314e-05 | test_loss = 9.598e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 355/1000]: train loss = 1.310e-05 | test_loss = 9.326e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 356/1000]: train loss = 1.310e-05 | test_loss = 9.519e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 357/1000]: train loss = 1.307e-05 | test_loss = 9.462e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 358/1000]: train loss = 1.300e-05 | test_loss = 9.488e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 359/1000]: train loss = 1.298e-05 | test_loss = 9.771e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 360/1000]: train loss = 1.297e-05 | test_loss = 9.104e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 361/1000]: train loss = 1.295e-05 | test_loss = 9.653e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 362/1000]: train loss = 1.298e-05 | test_loss = 9.621e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 363/1000]: train loss = 1.293e-05 | test_loss = 8.898e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 364/1000]: train loss = 1.287e-05 | test_loss = 9.678e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 365/1000]: train loss = 1.285e-05 | test_loss = 9.031e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 366/1000]: train loss = 1.281e-05 | test_loss = 9.205e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 367/1000]: train loss = 1.277e-05 | test_loss = 9.410e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 368/1000]: train loss = 1.274e-05 | test_loss = 8.794e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 369/1000]: train loss = 1.271e-05 | test_loss = 9.445e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 370/1000]: train loss = 1.269e-05 | test_loss = 8.644e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 371/1000]: train loss = 1.265e-05 | test_loss = 1.029e-05 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 372/1000]: train loss = 1.266e-05 | test_loss = 8.601e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 373/1000]: train loss = 1.258e-05 | test_loss = 9.342e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 374/1000]: train loss = 1.259e-05 | test_loss = 8.950e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 375/1000]: train loss = 1.252e-05 | test_loss = 8.663e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.2 sec\n",
            "[ 376/1000]: train loss = 1.247e-05 | test_loss = 9.519e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 377/1000]: train loss = 1.245e-05 | test_loss = 8.720e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 378/1000]: train loss = 1.242e-05 | test_loss = 9.080e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.1 sec\n",
            "[ 379/1000]: train loss = 1.235e-05 | test_loss = 8.809e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 380/1000]: train loss = 1.234e-05 | test_loss = 8.487e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 381/1000]: train loss = 1.237e-05 | test_loss = 9.931e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 382/1000]: train loss = 1.231e-05 | test_loss = 8.466e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 383/1000]: train loss = 1.232e-05 | test_loss = 9.577e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 384/1000]: train loss = 1.228e-05 | test_loss = 8.406e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 385/1000]: train loss = 1.224e-05 | test_loss = 9.260e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 386/1000]: train loss = 1.218e-05 | test_loss = 8.375e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 387/1000]: train loss = 1.215e-05 | test_loss = 8.546e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 388/1000]: train loss = 1.216e-05 | test_loss = 8.859e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 389/1000]: train loss = 1.213e-05 | test_loss = 8.319e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 390/1000]: train loss = 1.211e-05 | test_loss = 8.573e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 391/1000]: train loss = 1.207e-05 | test_loss = 8.732e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 392/1000]: train loss = 1.204e-05 | test_loss = 8.961e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 393/1000]: train loss = 1.201e-05 | test_loss = 8.412e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 394/1000]: train loss = 1.195e-05 | test_loss = 8.423e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 395/1000]: train loss = 1.191e-05 | test_loss = 8.626e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 396/1000]: train loss = 1.191e-05 | test_loss = 8.121e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 397/1000]: train loss = 1.187e-05 | test_loss = 8.815e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 398/1000]: train loss = 1.183e-05 | test_loss = 8.129e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 399/1000]: train loss = 1.183e-05 | test_loss = 8.584e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 400/1000]: train loss = 1.179e-05 | test_loss = 8.231e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 401/1000]: train loss = 1.175e-05 | test_loss = 8.139e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 402/1000]: train loss = 1.172e-05 | test_loss = 8.553e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 403/1000]: train loss = 1.170e-05 | test_loss = 8.052e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 404/1000]: train loss = 1.170e-05 | test_loss = 8.273e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.1 sec\n",
            "[ 405/1000]: train loss = 1.167e-05 | test_loss = 8.625e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.1 sec\n",
            "[ 406/1000]: train loss = 1.163e-05 | test_loss = 8.091e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 407/1000]: train loss = 1.159e-05 | test_loss = 8.436e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 408/1000]: train loss = 1.155e-05 | test_loss = 8.102e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 409/1000]: train loss = 1.151e-05 | test_loss = 8.554e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 410/1000]: train loss = 1.149e-05 | test_loss = 7.718e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 411/1000]: train loss = 1.147e-05 | test_loss = 8.210e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 412/1000]: train loss = 1.147e-05 | test_loss = 7.879e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 413/1000]: train loss = 1.143e-05 | test_loss = 8.489e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 414/1000]: train loss = 1.139e-05 | test_loss = 7.716e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 415/1000]: train loss = 1.138e-05 | test_loss = 8.387e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 416/1000]: train loss = 1.139e-05 | test_loss = 8.453e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 417/1000]: train loss = 1.138e-05 | test_loss = 7.946e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 418/1000]: train loss = 1.138e-05 | test_loss = 7.640e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 419/1000]: train loss = 1.140e-05 | test_loss = 8.348e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 420/1000]: train loss = 1.139e-05 | test_loss = 8.127e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 421/1000]: train loss = 1.137e-05 | test_loss = 7.504e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 422/1000]: train loss = 1.137e-05 | test_loss = 9.074e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 423/1000]: train loss = 1.138e-05 | test_loss = 7.615e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 424/1000]: train loss = 1.138e-05 | test_loss = 7.545e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 425/1000]: train loss = 1.138e-05 | test_loss = 8.676e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 426/1000]: train loss = 1.130e-05 | test_loss = 7.293e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 427/1000]: train loss = 1.132e-05 | test_loss = 8.260e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 428/1000]: train loss = 1.128e-05 | test_loss = 8.051e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 429/1000]: train loss = 1.125e-05 | test_loss = 7.344e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 430/1000]: train loss = 1.123e-05 | test_loss = 9.057e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 431/1000]: train loss = 1.123e-05 | test_loss = 7.283e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 432/1000]: train loss = 1.117e-05 | test_loss = 7.826e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 433/1000]: train loss = 1.112e-05 | test_loss = 7.916e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 434/1000]: train loss = 1.110e-05 | test_loss = 7.302e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 435/1000]: train loss = 1.109e-05 | test_loss = 7.812e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 436/1000]: train loss = 1.107e-05 | test_loss = 7.833e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 437/1000]: train loss = 1.105e-05 | test_loss = 7.137e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 438/1000]: train loss = 1.107e-05 | test_loss = 8.867e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 439/1000]: train loss = 1.109e-05 | test_loss = 7.242e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 440/1000]: train loss = 1.105e-05 | test_loss = 7.246e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 441/1000]: train loss = 1.102e-05 | test_loss = 7.988e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 442/1000]: train loss = 1.097e-05 | test_loss = 7.131e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 443/1000]: train loss = 1.093e-05 | test_loss = 7.693e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 444/1000]: train loss = 1.087e-05 | test_loss = 7.082e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 445/1000]: train loss = 1.083e-05 | test_loss = 7.602e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 446/1000]: train loss = 1.082e-05 | test_loss = 7.439e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 447/1000]: train loss = 1.083e-05 | test_loss = 7.471e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 448/1000]: train loss = 1.080e-05 | test_loss = 7.372e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 449/1000]: train loss = 1.076e-05 | test_loss = 7.163e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 450/1000]: train loss = 1.074e-05 | test_loss = 7.877e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 451/1000]: train loss = 1.072e-05 | test_loss = 6.992e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 452/1000]: train loss = 1.074e-05 | test_loss = 7.106e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 453/1000]: train loss = 1.073e-05 | test_loss = 7.710e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 454/1000]: train loss = 1.070e-05 | test_loss = 7.585e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 455/1000]: train loss = 1.065e-05 | test_loss = 6.878e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 456/1000]: train loss = 1.064e-05 | test_loss = 7.844e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 457/1000]: train loss = 1.062e-05 | test_loss = 6.908e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 458/1000]: train loss = 1.061e-05 | test_loss = 7.208e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 459/1000]: train loss = 1.058e-05 | test_loss = 7.508e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 460/1000]: train loss = 1.056e-05 | test_loss = 6.969e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 461/1000]: train loss = 1.056e-05 | test_loss = 7.058e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 462/1000]: train loss = 1.056e-05 | test_loss = 7.984e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 463/1000]: train loss = 1.052e-05 | test_loss = 6.780e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 464/1000]: train loss = 1.048e-05 | test_loss = 7.767e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 465/1000]: train loss = 1.048e-05 | test_loss = 6.754e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 466/1000]: train loss = 1.054e-05 | test_loss = 8.435e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 467/1000]: train loss = 1.054e-05 | test_loss = 7.093e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 468/1000]: train loss = 1.055e-05 | test_loss = 6.784e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 469/1000]: train loss = 1.059e-05 | test_loss = 8.184e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 470/1000]: train loss = 1.056e-05 | test_loss = 7.032e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 471/1000]: train loss = 1.048e-05 | test_loss = 6.747e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 472/1000]: train loss = 1.043e-05 | test_loss = 7.630e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 473/1000]: train loss = 1.040e-05 | test_loss = 6.767e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 474/1000]: train loss = 1.039e-05 | test_loss = 6.712e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 475/1000]: train loss = 1.035e-05 | test_loss = 7.101e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 476/1000]: train loss = 1.034e-05 | test_loss = 7.403e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 477/1000]: train loss = 1.031e-05 | test_loss = 6.636e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 478/1000]: train loss = 1.028e-05 | test_loss = 7.493e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 479/1000]: train loss = 1.029e-05 | test_loss = 7.084e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 480/1000]: train loss = 1.029e-05 | test_loss = 6.819e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 481/1000]: train loss = 1.024e-05 | test_loss = 7.206e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 482/1000]: train loss = 1.018e-05 | test_loss = 6.789e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 483/1000]: train loss = 1.014e-05 | test_loss = 6.932e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 484/1000]: train loss = 1.011e-05 | test_loss = 6.874e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 485/1000]: train loss = 1.010e-05 | test_loss = 6.780e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 486/1000]: train loss = 1.011e-05 | test_loss = 6.976e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 487/1000]: train loss = 1.008e-05 | test_loss = 6.882e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 488/1000]: train loss = 1.007e-05 | test_loss = 6.992e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 489/1000]: train loss = 1.007e-05 | test_loss = 6.528e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 490/1000]: train loss = 1.009e-05 | test_loss = 6.754e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 491/1000]: train loss = 1.009e-05 | test_loss = 7.774e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 492/1000]: train loss = 1.011e-05 | test_loss = 6.745e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 493/1000]: train loss = 1.010e-05 | test_loss = 6.552e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 494/1000]: train loss = 1.008e-05 | test_loss = 7.117e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 495/1000]: train loss = 1.008e-05 | test_loss = 6.489e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 496/1000]: train loss = 1.009e-05 | test_loss = 7.031e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 497/1000]: train loss = 1.009e-05 | test_loss = 7.395e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 498/1000]: train loss = 1.006e-05 | test_loss = 6.621e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 499/1000]: train loss = 1.003e-05 | test_loss = 6.731e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 500/1000]: train loss = 9.973e-06 | test_loss = 6.928e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 501/1000]: train loss = 9.947e-06 | test_loss = 6.410e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 502/1000]: train loss = 9.906e-06 | test_loss = 6.805e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 503/1000]: train loss = 9.866e-06 | test_loss = 6.350e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 504/1000]: train loss = 9.883e-06 | test_loss = 7.001e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 505/1000]: train loss = 9.867e-06 | test_loss = 6.784e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 506/1000]: train loss = 9.854e-06 | test_loss = 6.521e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 507/1000]: train loss = 9.863e-06 | test_loss = 6.554e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 508/1000]: train loss = 9.823e-06 | test_loss = 6.548e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 509/1000]: train loss = 9.806e-06 | test_loss = 6.544e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 510/1000]: train loss = 9.769e-06 | test_loss = 6.699e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 511/1000]: train loss = 9.756e-06 | test_loss = 6.800e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 512/1000]: train loss = 9.789e-06 | test_loss = 7.129e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 513/1000]: train loss = 9.799e-06 | test_loss = 6.289e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 514/1000]: train loss = 9.790e-06 | test_loss = 6.813e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 515/1000]: train loss = 9.784e-06 | test_loss = 6.394e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 516/1000]: train loss = 9.753e-06 | test_loss = 6.639e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 517/1000]: train loss = 9.700e-06 | test_loss = 6.516e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 518/1000]: train loss = 9.680e-06 | test_loss = 6.606e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 519/1000]: train loss = 9.650e-06 | test_loss = 6.296e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 520/1000]: train loss = 9.652e-06 | test_loss = 6.459e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 521/1000]: train loss = 9.642e-06 | test_loss = 6.642e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 522/1000]: train loss = 9.633e-06 | test_loss = 6.854e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 523/1000]: train loss = 9.652e-06 | test_loss = 6.239e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 524/1000]: train loss = 9.705e-06 | test_loss = 6.596e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 525/1000]: train loss = 9.693e-06 | test_loss = 7.069e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 526/1000]: train loss = 9.696e-06 | test_loss = 6.441e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 527/1000]: train loss = 9.663e-06 | test_loss = 6.286e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 528/1000]: train loss = 9.610e-06 | test_loss = 7.209e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 529/1000]: train loss = 9.644e-06 | test_loss = 6.418e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 530/1000]: train loss = 9.653e-06 | test_loss = 6.177e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 531/1000]: train loss = 9.644e-06 | test_loss = 7.116e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 532/1000]: train loss = 9.619e-06 | test_loss = 6.343e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 533/1000]: train loss = 9.640e-06 | test_loss = 6.278e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 534/1000]: train loss = 9.683e-06 | test_loss = 7.027e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 535/1000]: train loss = 9.659e-06 | test_loss = 6.692e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 536/1000]: train loss = 9.621e-06 | test_loss = 6.691e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 537/1000]: train loss = 9.532e-06 | test_loss = 6.385e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 538/1000]: train loss = 9.489e-06 | test_loss = 6.208e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 539/1000]: train loss = 9.446e-06 | test_loss = 6.331e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 540/1000]: train loss = 9.435e-06 | test_loss = 6.720e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 541/1000]: train loss = 9.422e-06 | test_loss = 6.141e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 542/1000]: train loss = 9.433e-06 | test_loss = 6.957e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 543/1000]: train loss = 9.416e-06 | test_loss = 6.272e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 544/1000]: train loss = 9.364e-06 | test_loss = 6.521e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 545/1000]: train loss = 9.342e-06 | test_loss = 6.216e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 546/1000]: train loss = 9.332e-06 | test_loss = 7.112e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 547/1000]: train loss = 9.337e-06 | test_loss = 6.481e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 548/1000]: train loss = 9.361e-06 | test_loss = 6.196e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 549/1000]: train loss = 9.389e-06 | test_loss = 6.506e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 550/1000]: train loss = 9.370e-06 | test_loss = 7.451e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 551/1000]: train loss = 9.393e-06 | test_loss = 6.416e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 552/1000]: train loss = 9.369e-06 | test_loss = 7.154e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 553/1000]: train loss = 9.355e-06 | test_loss = 6.417e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 554/1000]: train loss = 9.326e-06 | test_loss = 6.191e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 555/1000]: train loss = 9.305e-06 | test_loss = 6.984e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 556/1000]: train loss = 9.273e-06 | test_loss = 6.426e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 557/1000]: train loss = 9.214e-06 | test_loss = 6.453e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 558/1000]: train loss = 9.179e-06 | test_loss = 6.220e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 559/1000]: train loss = 9.200e-06 | test_loss = 6.548e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 560/1000]: train loss = 9.172e-06 | test_loss = 6.475e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 561/1000]: train loss = 9.145e-06 | test_loss = 6.155e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 562/1000]: train loss = 9.135e-06 | test_loss = 6.243e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 563/1000]: train loss = 9.105e-06 | test_loss = 6.612e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 564/1000]: train loss = 9.084e-06 | test_loss = 6.483e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 565/1000]: train loss = 9.037e-06 | test_loss = 6.074e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 566/1000]: train loss = 8.996e-06 | test_loss = 6.587e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 567/1000]: train loss = 8.966e-06 | test_loss = 6.134e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 568/1000]: train loss = 8.956e-06 | test_loss = 6.473e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 569/1000]: train loss = 8.923e-06 | test_loss = 6.114e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 570/1000]: train loss = 8.898e-06 | test_loss = 6.044e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 571/1000]: train loss = 8.857e-06 | test_loss = 6.030e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 572/1000]: train loss = 8.888e-06 | test_loss = 6.280e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 573/1000]: train loss = 8.911e-06 | test_loss = 5.953e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 574/1000]: train loss = 8.871e-06 | test_loss = 6.145e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 575/1000]: train loss = 8.856e-06 | test_loss = 6.439e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 576/1000]: train loss = 8.857e-06 | test_loss = 5.979e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 577/1000]: train loss = 8.872e-06 | test_loss = 5.802e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 578/1000]: train loss = 8.922e-06 | test_loss = 6.690e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 579/1000]: train loss = 8.923e-06 | test_loss = 6.276e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 580/1000]: train loss = 8.961e-06 | test_loss = 5.930e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 581/1000]: train loss = 8.970e-06 | test_loss = 6.035e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 582/1000]: train loss = 8.903e-06 | test_loss = 6.088e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 583/1000]: train loss = 8.848e-06 | test_loss = 6.234e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 584/1000]: train loss = 8.789e-06 | test_loss = 5.908e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 585/1000]: train loss = 8.770e-06 | test_loss = 6.215e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 586/1000]: train loss = 8.752e-06 | test_loss = 5.824e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 587/1000]: train loss = 8.692e-06 | test_loss = 6.129e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 588/1000]: train loss = 8.652e-06 | test_loss = 5.978e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 589/1000]: train loss = 8.645e-06 | test_loss = 5.768e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 590/1000]: train loss = 8.620e-06 | test_loss = 5.748e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 591/1000]: train loss = 8.580e-06 | test_loss = 5.885e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 592/1000]: train loss = 8.569e-06 | test_loss = 5.850e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 593/1000]: train loss = 8.558e-06 | test_loss = 5.668e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 594/1000]: train loss = 8.561e-06 | test_loss = 5.764e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 595/1000]: train loss = 8.546e-06 | test_loss = 5.611e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 596/1000]: train loss = 8.537e-06 | test_loss = 5.653e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 597/1000]: train loss = 8.511e-06 | test_loss = 5.893e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 598/1000]: train loss = 8.498e-06 | test_loss = 5.856e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 599/1000]: train loss = 8.484e-06 | test_loss = 5.800e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 600/1000]: train loss = 8.439e-06 | test_loss = 5.591e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 601/1000]: train loss = 8.424e-06 | test_loss = 5.901e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 602/1000]: train loss = 8.400e-06 | test_loss = 5.558e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 603/1000]: train loss = 8.406e-06 | test_loss = 5.540e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 604/1000]: train loss = 8.364e-06 | test_loss = 5.813e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.1 sec\n",
            "[ 605/1000]: train loss = 8.371e-06 | test_loss = 5.810e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 606/1000]: train loss = 8.327e-06 | test_loss = 5.405e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 607/1000]: train loss = 8.318e-06 | test_loss = 5.423e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 608/1000]: train loss = 8.315e-06 | test_loss = 5.787e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 609/1000]: train loss = 8.294e-06 | test_loss = 5.641e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 610/1000]: train loss = 8.276e-06 | test_loss = 5.427e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 611/1000]: train loss = 8.248e-06 | test_loss = 5.567e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 612/1000]: train loss = 8.247e-06 | test_loss = 5.884e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 613/1000]: train loss = 8.248e-06 | test_loss = 5.452e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 614/1000]: train loss = 8.214e-06 | test_loss = 5.501e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 615/1000]: train loss = 8.180e-06 | test_loss = 5.447e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 616/1000]: train loss = 8.164e-06 | test_loss = 6.294e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 617/1000]: train loss = 8.149e-06 | test_loss = 5.417e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 618/1000]: train loss = 8.124e-06 | test_loss = 5.434e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 619/1000]: train loss = 8.139e-06 | test_loss = 6.222e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 620/1000]: train loss = 8.143e-06 | test_loss = 5.421e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 621/1000]: train loss = 8.130e-06 | test_loss = 5.422e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 622/1000]: train loss = 8.167e-06 | test_loss = 5.385e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 623/1000]: train loss = 8.158e-06 | test_loss = 5.882e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 624/1000]: train loss = 8.144e-06 | test_loss = 5.686e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 625/1000]: train loss = 8.133e-06 | test_loss = 5.215e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 626/1000]: train loss = 8.105e-06 | test_loss = 5.218e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 627/1000]: train loss = 8.085e-06 | test_loss = 5.442e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 628/1000]: train loss = 8.033e-06 | test_loss = 5.346e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 629/1000]: train loss = 7.982e-06 | test_loss = 5.336e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 630/1000]: train loss = 7.935e-06 | test_loss = 5.079e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 631/1000]: train loss = 7.892e-06 | test_loss = 5.128e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 632/1000]: train loss = 7.871e-06 | test_loss = 5.236e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 633/1000]: train loss = 7.826e-06 | test_loss = 5.033e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 634/1000]: train loss = 7.832e-06 | test_loss = 5.113e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 635/1000]: train loss = 7.824e-06 | test_loss = 5.410e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 636/1000]: train loss = 7.802e-06 | test_loss = 5.111e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 637/1000]: train loss = 7.780e-06 | test_loss = 5.243e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 638/1000]: train loss = 7.764e-06 | test_loss = 4.976e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 639/1000]: train loss = 7.728e-06 | test_loss = 5.083e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 640/1000]: train loss = 7.695e-06 | test_loss = 4.924e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 641/1000]: train loss = 7.655e-06 | test_loss = 4.842e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 642/1000]: train loss = 7.690e-06 | test_loss = 5.152e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 643/1000]: train loss = 7.670e-06 | test_loss = 5.044e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 644/1000]: train loss = 7.657e-06 | test_loss = 4.840e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 645/1000]: train loss = 7.620e-06 | test_loss = 4.854e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 646/1000]: train loss = 7.614e-06 | test_loss = 4.879e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 647/1000]: train loss = 7.597e-06 | test_loss = 5.165e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 648/1000]: train loss = 7.562e-06 | test_loss = 4.734e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 649/1000]: train loss = 7.526e-06 | test_loss = 4.973e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 650/1000]: train loss = 7.478e-06 | test_loss = 4.742e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 651/1000]: train loss = 7.449e-06 | test_loss = 4.835e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 652/1000]: train loss = 7.443e-06 | test_loss = 4.665e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 653/1000]: train loss = 7.418e-06 | test_loss = 4.784e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 654/1000]: train loss = 7.388e-06 | test_loss = 4.670e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 655/1000]: train loss = 7.358e-06 | test_loss = 4.817e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 656/1000]: train loss = 7.332e-06 | test_loss = 4.638e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 657/1000]: train loss = 7.301e-06 | test_loss = 4.723e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 658/1000]: train loss = 7.261e-06 | test_loss = 4.650e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 659/1000]: train loss = 7.224e-06 | test_loss = 4.827e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 660/1000]: train loss = 7.253e-06 | test_loss = 4.571e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 661/1000]: train loss = 7.237e-06 | test_loss = 4.527e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 662/1000]: train loss = 7.202e-06 | test_loss = 4.785e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 663/1000]: train loss = 7.190e-06 | test_loss = 4.671e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 664/1000]: train loss = 7.155e-06 | test_loss = 4.589e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 665/1000]: train loss = 7.144e-06 | test_loss = 4.453e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 666/1000]: train loss = 7.119e-06 | test_loss = 4.636e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 667/1000]: train loss = 7.099e-06 | test_loss = 4.457e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 668/1000]: train loss = 7.095e-06 | test_loss = 4.880e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 669/1000]: train loss = 7.120e-06 | test_loss = 5.129e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 670/1000]: train loss = 7.165e-06 | test_loss = 4.387e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 671/1000]: train loss = 7.177e-06 | test_loss = 4.735e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 672/1000]: train loss = 7.163e-06 | test_loss = 4.580e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 673/1000]: train loss = 7.129e-06 | test_loss = 5.051e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 674/1000]: train loss = 7.109e-06 | test_loss = 4.342e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 675/1000]: train loss = 7.086e-06 | test_loss = 4.385e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 676/1000]: train loss = 7.042e-06 | test_loss = 4.771e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 677/1000]: train loss = 7.033e-06 | test_loss = 4.676e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 678/1000]: train loss = 7.018e-06 | test_loss = 4.373e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 679/1000]: train loss = 7.027e-06 | test_loss = 4.375e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 680/1000]: train loss = 7.025e-06 | test_loss = 4.383e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 681/1000]: train loss = 6.991e-06 | test_loss = 4.715e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 682/1000]: train loss = 6.968e-06 | test_loss = 4.577e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 683/1000]: train loss = 6.962e-06 | test_loss = 4.280e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 684/1000]: train loss = 6.933e-06 | test_loss = 4.292e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 685/1000]: train loss = 6.877e-06 | test_loss = 4.315e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 686/1000]: train loss = 6.840e-06 | test_loss = 4.561e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 687/1000]: train loss = 6.841e-06 | test_loss = 4.581e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 688/1000]: train loss = 6.840e-06 | test_loss = 4.241e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 689/1000]: train loss = 6.803e-06 | test_loss = 4.281e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 690/1000]: train loss = 6.766e-06 | test_loss = 4.247e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 691/1000]: train loss = 6.742e-06 | test_loss = 4.364e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 692/1000]: train loss = 6.692e-06 | test_loss = 4.194e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 693/1000]: train loss = 6.682e-06 | test_loss = 4.256e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 694/1000]: train loss = 6.645e-06 | test_loss = 4.175e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 695/1000]: train loss = 6.621e-06 | test_loss = 4.117e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 696/1000]: train loss = 6.598e-06 | test_loss = 4.328e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 697/1000]: train loss = 6.580e-06 | test_loss = 4.086e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 698/1000]: train loss = 6.624e-06 | test_loss = 4.255e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 699/1000]: train loss = 6.608e-06 | test_loss = 4.555e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 700/1000]: train loss = 6.622e-06 | test_loss = 4.105e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 701/1000]: train loss = 6.606e-06 | test_loss = 4.091e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 702/1000]: train loss = 6.594e-06 | test_loss = 4.146e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 703/1000]: train loss = 6.575e-06 | test_loss = 4.458e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 704/1000]: train loss = 6.555e-06 | test_loss = 4.282e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 705/1000]: train loss = 6.565e-06 | test_loss = 4.094e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 706/1000]: train loss = 6.548e-06 | test_loss = 4.187e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 707/1000]: train loss = 6.537e-06 | test_loss = 4.313e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 708/1000]: train loss = 6.520e-06 | test_loss = 4.097e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 709/1000]: train loss = 6.479e-06 | test_loss = 3.997e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 710/1000]: train loss = 6.435e-06 | test_loss = 3.959e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 711/1000]: train loss = 6.427e-06 | test_loss = 4.111e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 712/1000]: train loss = 6.396e-06 | test_loss = 4.143e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 713/1000]: train loss = 6.404e-06 | test_loss = 3.947e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 714/1000]: train loss = 6.403e-06 | test_loss = 4.052e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 715/1000]: train loss = 6.408e-06 | test_loss = 4.033e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 716/1000]: train loss = 6.382e-06 | test_loss = 4.022e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 717/1000]: train loss = 6.340e-06 | test_loss = 3.904e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 718/1000]: train loss = 6.311e-06 | test_loss = 4.183e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 719/1000]: train loss = 6.290e-06 | test_loss = 3.908e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 720/1000]: train loss = 6.258e-06 | test_loss = 4.154e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 721/1000]: train loss = 6.262e-06 | test_loss = 4.053e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 722/1000]: train loss = 6.245e-06 | test_loss = 3.867e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 723/1000]: train loss = 6.230e-06 | test_loss = 3.898e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 724/1000]: train loss = 6.201e-06 | test_loss = 3.903e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 725/1000]: train loss = 6.199e-06 | test_loss = 4.051e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 726/1000]: train loss = 6.194e-06 | test_loss = 3.826e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 727/1000]: train loss = 6.155e-06 | test_loss = 3.867e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 728/1000]: train loss = 6.157e-06 | test_loss = 4.024e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 729/1000]: train loss = 6.169e-06 | test_loss = 3.883e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 730/1000]: train loss = 6.152e-06 | test_loss = 4.032e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 731/1000]: train loss = 6.139e-06 | test_loss = 3.962e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 732/1000]: train loss = 6.131e-06 | test_loss = 3.824e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 733/1000]: train loss = 6.098e-06 | test_loss = 3.803e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 734/1000]: train loss = 6.070e-06 | test_loss = 4.044e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 735/1000]: train loss = 6.062e-06 | test_loss = 3.783e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 736/1000]: train loss = 6.056e-06 | test_loss = 3.835e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 737/1000]: train loss = 6.024e-06 | test_loss = 3.829e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 738/1000]: train loss = 5.988e-06 | test_loss = 4.181e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 739/1000]: train loss = 6.020e-06 | test_loss = 4.042e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 740/1000]: train loss = 6.024e-06 | test_loss = 3.768e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 741/1000]: train loss = 6.005e-06 | test_loss = 3.754e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 742/1000]: train loss = 6.003e-06 | test_loss = 3.761e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 743/1000]: train loss = 5.991e-06 | test_loss = 4.050e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 744/1000]: train loss = 6.017e-06 | test_loss = 3.932e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 745/1000]: train loss = 6.012e-06 | test_loss = 4.014e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 746/1000]: train loss = 6.039e-06 | test_loss = 3.887e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 747/1000]: train loss = 6.068e-06 | test_loss = 3.671e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 748/1000]: train loss = 6.071e-06 | test_loss = 3.859e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 749/1000]: train loss = 6.049e-06 | test_loss = 3.836e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 750/1000]: train loss = 5.994e-06 | test_loss = 3.786e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 751/1000]: train loss = 5.960e-06 | test_loss = 3.733e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 752/1000]: train loss = 5.957e-06 | test_loss = 3.668e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 753/1000]: train loss = 5.968e-06 | test_loss = 3.824e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 754/1000]: train loss = 5.955e-06 | test_loss = 3.586e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 755/1000]: train loss = 5.932e-06 | test_loss = 3.629e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 756/1000]: train loss = 5.903e-06 | test_loss = 3.733e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 757/1000]: train loss = 5.901e-06 | test_loss = 3.949e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 758/1000]: train loss = 5.902e-06 | test_loss = 4.455e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 759/1000]: train loss = 5.906e-06 | test_loss = 3.587e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 760/1000]: train loss = 5.881e-06 | test_loss = 3.582e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 761/1000]: train loss = 5.881e-06 | test_loss = 3.659e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 762/1000]: train loss = 5.856e-06 | test_loss = 3.767e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 763/1000]: train loss = 5.825e-06 | test_loss = 3.542e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 764/1000]: train loss = 5.808e-06 | test_loss = 3.578e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 765/1000]: train loss = 5.795e-06 | test_loss = 3.482e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 766/1000]: train loss = 5.762e-06 | test_loss = 3.578e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 767/1000]: train loss = 5.741e-06 | test_loss = 3.704e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 768/1000]: train loss = 5.717e-06 | test_loss = 3.482e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 769/1000]: train loss = 5.687e-06 | test_loss = 3.471e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 770/1000]: train loss = 5.661e-06 | test_loss = 3.441e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 771/1000]: train loss = 5.661e-06 | test_loss = 3.396e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 772/1000]: train loss = 5.679e-06 | test_loss = 3.475e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 773/1000]: train loss = 5.669e-06 | test_loss = 3.804e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 774/1000]: train loss = 5.683e-06 | test_loss = 3.667e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 775/1000]: train loss = 5.652e-06 | test_loss = 3.624e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 776/1000]: train loss = 5.649e-06 | test_loss = 3.366e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 777/1000]: train loss = 5.629e-06 | test_loss = 3.413e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 778/1000]: train loss = 5.671e-06 | test_loss = 3.359e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 779/1000]: train loss = 5.639e-06 | test_loss = 3.385e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 780/1000]: train loss = 5.603e-06 | test_loss = 3.337e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 781/1000]: train loss = 5.606e-06 | test_loss = 3.488e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 782/1000]: train loss = 5.624e-06 | test_loss = 3.291e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 783/1000]: train loss = 5.686e-06 | test_loss = 3.663e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 784/1000]: train loss = 5.671e-06 | test_loss = 3.644e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 785/1000]: train loss = 5.657e-06 | test_loss = 3.588e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 786/1000]: train loss = 5.648e-06 | test_loss = 3.257e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 787/1000]: train loss = 5.593e-06 | test_loss = 3.236e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 788/1000]: train loss = 5.558e-06 | test_loss = 3.372e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 789/1000]: train loss = 5.529e-06 | test_loss = 3.353e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 790/1000]: train loss = 5.504e-06 | test_loss = 3.248e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 791/1000]: train loss = 5.475e-06 | test_loss = 3.322e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 792/1000]: train loss = 5.452e-06 | test_loss = 3.252e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 793/1000]: train loss = 5.425e-06 | test_loss = 3.246e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 794/1000]: train loss = 5.420e-06 | test_loss = 3.466e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 795/1000]: train loss = 5.427e-06 | test_loss = 3.198e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 796/1000]: train loss = 5.473e-06 | test_loss = 3.281e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 797/1000]: train loss = 5.478e-06 | test_loss = 3.185e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 798/1000]: train loss = 5.488e-06 | test_loss = 3.519e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 799/1000]: train loss = 5.507e-06 | test_loss = 3.361e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 800/1000]: train loss = 5.553e-06 | test_loss = 3.239e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 801/1000]: train loss = 5.553e-06 | test_loss = 4.515e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 802/1000]: train loss = 5.605e-06 | test_loss = 3.596e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 803/1000]: train loss = 5.587e-06 | test_loss = 3.425e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 804/1000]: train loss = 5.527e-06 | test_loss = 3.177e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 805/1000]: train loss = 5.475e-06 | test_loss = 3.127e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 806/1000]: train loss = 5.451e-06 | test_loss = 3.281e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 807/1000]: train loss = 5.424e-06 | test_loss = 3.164e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 808/1000]: train loss = 5.421e-06 | test_loss = 3.393e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 809/1000]: train loss = 5.417e-06 | test_loss = 3.391e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 810/1000]: train loss = 5.391e-06 | test_loss = 3.194e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 811/1000]: train loss = 5.317e-06 | test_loss = 3.125e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 812/1000]: train loss = 5.292e-06 | test_loss = 3.102e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 813/1000]: train loss = 5.269e-06 | test_loss = 3.052e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 814/1000]: train loss = 5.251e-06 | test_loss = 3.104e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 815/1000]: train loss = 5.246e-06 | test_loss = 3.133e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 816/1000]: train loss = 5.236e-06 | test_loss = 3.122e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 817/1000]: train loss = 5.222e-06 | test_loss = 3.124e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 818/1000]: train loss = 5.239e-06 | test_loss = 3.044e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 819/1000]: train loss = 5.252e-06 | test_loss = 3.158e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 820/1000]: train loss = 5.246e-06 | test_loss = 3.282e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 821/1000]: train loss = 5.233e-06 | test_loss = 3.042e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 822/1000]: train loss = 5.189e-06 | test_loss = 3.013e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 823/1000]: train loss = 5.175e-06 | test_loss = 3.080e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 824/1000]: train loss = 5.150e-06 | test_loss = 3.050e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 825/1000]: train loss = 5.139e-06 | test_loss = 3.006e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 826/1000]: train loss = 5.117e-06 | test_loss = 3.018e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 827/1000]: train loss = 5.081e-06 | test_loss = 3.108e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 828/1000]: train loss = 5.123e-06 | test_loss = 3.559e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 829/1000]: train loss = 5.153e-06 | test_loss = 3.282e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 830/1000]: train loss = 5.173e-06 | test_loss = 3.080e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 831/1000]: train loss = 5.183e-06 | test_loss = 3.098e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 832/1000]: train loss = 5.193e-06 | test_loss = 3.118e-06 | depth =  12.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 833/1000]: train loss = 5.184e-06 | test_loss = 3.347e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 834/1000]: train loss = 5.179e-06 | test_loss = 3.011e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 835/1000]: train loss = 5.131e-06 | test_loss = 3.040e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 836/1000]: train loss = 5.116e-06 | test_loss = 3.086e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 837/1000]: train loss = 5.093e-06 | test_loss = 3.044e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 838/1000]: train loss = 5.078e-06 | test_loss = 2.967e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 839/1000]: train loss = 5.069e-06 | test_loss = 3.136e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 840/1000]: train loss = 5.062e-06 | test_loss = 3.047e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 841/1000]: train loss = 5.062e-06 | test_loss = 3.114e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 842/1000]: train loss = 5.117e-06 | test_loss = 3.007e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 843/1000]: train loss = 5.126e-06 | test_loss = 3.385e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 844/1000]: train loss = 5.114e-06 | test_loss = 3.575e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 845/1000]: train loss = 5.145e-06 | test_loss = 3.358e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 846/1000]: train loss = 5.107e-06 | test_loss = 2.924e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 847/1000]: train loss = 5.056e-06 | test_loss = 2.914e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 848/1000]: train loss = 5.010e-06 | test_loss = 2.906e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 849/1000]: train loss = 4.967e-06 | test_loss = 3.116e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 850/1000]: train loss = 4.960e-06 | test_loss = 3.005e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 851/1000]: train loss = 4.960e-06 | test_loss = 2.977e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 852/1000]: train loss = 4.948e-06 | test_loss = 3.089e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 853/1000]: train loss = 4.942e-06 | test_loss = 2.873e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 854/1000]: train loss = 4.948e-06 | test_loss = 3.021e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 855/1000]: train loss = 4.924e-06 | test_loss = 3.195e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 856/1000]: train loss = 4.919e-06 | test_loss = 2.902e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  1.0 sec\n",
            "[ 857/1000]: train loss = 4.914e-06 | test_loss = 3.176e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 858/1000]: train loss = 4.915e-06 | test_loss = 2.902e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 859/1000]: train loss = 4.930e-06 | test_loss = 2.810e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 860/1000]: train loss = 4.930e-06 | test_loss = 2.932e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 861/1000]: train loss = 4.897e-06 | test_loss = 2.836e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 862/1000]: train loss = 4.884e-06 | test_loss = 2.882e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 863/1000]: train loss = 4.861e-06 | test_loss = 2.828e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 864/1000]: train loss = 4.840e-06 | test_loss = 2.778e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 865/1000]: train loss = 4.814e-06 | test_loss = 2.750e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 866/1000]: train loss = 4.799e-06 | test_loss = 2.795e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 867/1000]: train loss = 4.808e-06 | test_loss = 2.791e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 868/1000]: train loss = 4.822e-06 | test_loss = 2.780e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 869/1000]: train loss = 4.860e-06 | test_loss = 2.823e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 870/1000]: train loss = 4.830e-06 | test_loss = 2.768e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 871/1000]: train loss = 4.837e-06 | test_loss = 2.831e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 872/1000]: train loss = 4.820e-06 | test_loss = 2.734e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 873/1000]: train loss = 4.796e-06 | test_loss = 2.809e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 874/1000]: train loss = 4.783e-06 | test_loss = 2.895e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 875/1000]: train loss = 4.795e-06 | test_loss = 2.831e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 876/1000]: train loss = 4.788e-06 | test_loss = 3.090e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 877/1000]: train loss = 4.774e-06 | test_loss = 2.867e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 878/1000]: train loss = 4.780e-06 | test_loss = 2.756e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 879/1000]: train loss = 4.775e-06 | test_loss = 2.693e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 880/1000]: train loss = 4.757e-06 | test_loss = 2.790e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 881/1000]: train loss = 4.759e-06 | test_loss = 2.761e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 882/1000]: train loss = 4.748e-06 | test_loss = 2.649e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 883/1000]: train loss = 4.769e-06 | test_loss = 2.912e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 884/1000]: train loss = 4.831e-06 | test_loss = 3.224e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 885/1000]: train loss = 4.885e-06 | test_loss = 2.893e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 886/1000]: train loss = 4.853e-06 | test_loss = 3.152e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 887/1000]: train loss = 4.850e-06 | test_loss = 2.813e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 888/1000]: train loss = 4.840e-06 | test_loss = 2.684e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 889/1000]: train loss = 4.807e-06 | test_loss = 2.666e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 890/1000]: train loss = 4.799e-06 | test_loss = 2.644e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 891/1000]: train loss = 4.827e-06 | test_loss = 2.619e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 892/1000]: train loss = 4.826e-06 | test_loss = 2.659e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 893/1000]: train loss = 4.794e-06 | test_loss = 2.779e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 894/1000]: train loss = 4.754e-06 | test_loss = 2.631e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 895/1000]: train loss = 4.723e-06 | test_loss = 2.892e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 896/1000]: train loss = 4.730e-06 | test_loss = 3.035e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 897/1000]: train loss = 4.765e-06 | test_loss = 2.858e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 898/1000]: train loss = 4.797e-06 | test_loss = 2.731e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 899/1000]: train loss = 4.783e-06 | test_loss = 2.575e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 900/1000]: train loss = 4.722e-06 | test_loss = 2.745e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 901/1000]: train loss = 4.763e-06 | test_loss = 2.626e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 902/1000]: train loss = 4.746e-06 | test_loss = 2.634e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 903/1000]: train loss = 4.732e-06 | test_loss = 2.715e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 904/1000]: train loss = 4.739e-06 | test_loss = 2.595e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 905/1000]: train loss = 4.761e-06 | test_loss = 2.611e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 906/1000]: train loss = 4.737e-06 | test_loss = 2.547e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 907/1000]: train loss = 4.716e-06 | test_loss = 2.651e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 908/1000]: train loss = 4.680e-06 | test_loss = 2.787e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 909/1000]: train loss = 4.661e-06 | test_loss = 2.599e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 910/1000]: train loss = 4.621e-06 | test_loss = 2.560e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 911/1000]: train loss = 4.608e-06 | test_loss = 2.583e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 912/1000]: train loss = 4.563e-06 | test_loss = 2.758e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 913/1000]: train loss = 4.539e-06 | test_loss = 2.593e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 914/1000]: train loss = 4.519e-06 | test_loss = 2.576e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 915/1000]: train loss = 4.489e-06 | test_loss = 2.539e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 916/1000]: train loss = 4.502e-06 | test_loss = 2.732e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 917/1000]: train loss = 4.510e-06 | test_loss = 2.588e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 918/1000]: train loss = 4.518e-06 | test_loss = 2.561e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 919/1000]: train loss = 4.504e-06 | test_loss = 2.524e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 920/1000]: train loss = 4.487e-06 | test_loss = 2.574e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 921/1000]: train loss = 4.481e-06 | test_loss = 2.502e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 922/1000]: train loss = 4.483e-06 | test_loss = 2.545e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 923/1000]: train loss = 4.474e-06 | test_loss = 2.544e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 924/1000]: train loss = 4.463e-06 | test_loss = 2.634e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 925/1000]: train loss = 4.554e-06 | test_loss = 3.580e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 926/1000]: train loss = 4.641e-06 | test_loss = 3.495e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 927/1000]: train loss = 4.691e-06 | test_loss = 2.930e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 928/1000]: train loss = 4.658e-06 | test_loss = 2.822e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 929/1000]: train loss = 4.641e-06 | test_loss = 2.565e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 930/1000]: train loss = 4.606e-06 | test_loss = 2.485e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 931/1000]: train loss = 4.577e-06 | test_loss = 2.512e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 932/1000]: train loss = 4.536e-06 | test_loss = 2.671e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 933/1000]: train loss = 4.511e-06 | test_loss = 2.487e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 934/1000]: train loss = 4.494e-06 | test_loss = 2.472e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 935/1000]: train loss = 4.480e-06 | test_loss = 2.496e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 936/1000]: train loss = 4.472e-06 | test_loss = 2.501e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 937/1000]: train loss = 4.454e-06 | test_loss = 2.651e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 938/1000]: train loss = 4.441e-06 | test_loss = 2.507e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 939/1000]: train loss = 4.430e-06 | test_loss = 2.528e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 940/1000]: train loss = 4.466e-06 | test_loss = 2.587e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 941/1000]: train loss = 4.482e-06 | test_loss = 3.122e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 942/1000]: train loss = 4.606e-06 | test_loss = 3.214e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 943/1000]: train loss = 4.610e-06 | test_loss = 2.908e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 944/1000]: train loss = 4.593e-06 | test_loss = 2.853e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 945/1000]: train loss = 4.563e-06 | test_loss = 2.674e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 946/1000]: train loss = 4.505e-06 | test_loss = 2.481e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 947/1000]: train loss = 4.462e-06 | test_loss = 2.434e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 948/1000]: train loss = 4.423e-06 | test_loss = 2.450e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 949/1000]: train loss = 4.419e-06 | test_loss = 2.469e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 950/1000]: train loss = 4.417e-06 | test_loss = 2.525e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 951/1000]: train loss = 4.443e-06 | test_loss = 2.586e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 952/1000]: train loss = 4.454e-06 | test_loss = 2.685e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 953/1000]: train loss = 4.421e-06 | test_loss = 2.605e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 954/1000]: train loss = 4.419e-06 | test_loss = 2.779e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 955/1000]: train loss = 4.421e-06 | test_loss = 2.495e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 956/1000]: train loss = 4.433e-06 | test_loss = 2.411e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 957/1000]: train loss = 4.429e-06 | test_loss = 2.420e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 958/1000]: train loss = 4.444e-06 | test_loss = 2.445e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.9 sec\n",
            "[ 959/1000]: train loss = 4.461e-06 | test_loss = 2.408e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 960/1000]: train loss = 4.462e-06 | test_loss = 2.416e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 961/1000]: train loss = 4.457e-06 | test_loss = 2.391e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 962/1000]: train loss = 4.438e-06 | test_loss = 2.464e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 963/1000]: train loss = 4.419e-06 | test_loss = 2.457e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 964/1000]: train loss = 4.399e-06 | test_loss = 2.480e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 965/1000]: train loss = 4.401e-06 | test_loss = 2.465e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 966/1000]: train loss = 4.427e-06 | test_loss = 3.013e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 967/1000]: train loss = 4.514e-06 | test_loss = 2.876e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 968/1000]: train loss = 4.519e-06 | test_loss = 2.526e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 969/1000]: train loss = 4.491e-06 | test_loss = 2.425e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 970/1000]: train loss = 4.461e-06 | test_loss = 2.414e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 971/1000]: train loss = 4.426e-06 | test_loss = 2.782e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 972/1000]: train loss = 4.429e-06 | test_loss = 2.417e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 973/1000]: train loss = 4.436e-06 | test_loss = 2.687e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 974/1000]: train loss = 4.404e-06 | test_loss = 2.757e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 975/1000]: train loss = 4.382e-06 | test_loss = 2.431e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 976/1000]: train loss = 4.346e-06 | test_loss = 2.416e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 977/1000]: train loss = 4.345e-06 | test_loss = 2.468e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 978/1000]: train loss = 4.317e-06 | test_loss = 2.346e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 979/1000]: train loss = 4.318e-06 | test_loss = 2.347e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 980/1000]: train loss = 4.290e-06 | test_loss = 2.380e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 981/1000]: train loss = 4.324e-06 | test_loss = 2.422e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 982/1000]: train loss = 4.350e-06 | test_loss = 2.396e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 983/1000]: train loss = 4.338e-06 | test_loss = 2.377e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 984/1000]: train loss = 4.307e-06 | test_loss = 2.417e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 985/1000]: train loss = 4.282e-06 | test_loss = 2.424e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 986/1000]: train loss = 4.271e-06 | test_loss = 2.390e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 987/1000]: train loss = 4.281e-06 | test_loss = 2.353e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 988/1000]: train loss = 4.283e-06 | test_loss = 2.365e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 989/1000]: train loss = 4.274e-06 | test_loss = 2.388e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 990/1000]: train loss = 4.268e-06 | test_loss = 2.335e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 991/1000]: train loss = 4.242e-06 | test_loss = 2.348e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.8 sec\n",
            "[ 992/1000]: train loss = 4.225e-06 | test_loss = 2.322e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 993/1000]: train loss = 4.218e-06 | test_loss = 2.454e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 994/1000]: train loss = 4.219e-06 | test_loss = 2.367e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 995/1000]: train loss = 4.219e-06 | test_loss = 2.304e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 996/1000]: train loss = 4.244e-06 | test_loss = 2.478e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 997/1000]: train loss = 4.253e-06 | test_loss = 2.511e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 998/1000]: train loss = 4.260e-06 | test_loss = 2.308e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[ 999/1000]: train loss = 4.265e-06 | test_loss = 2.433e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n",
            "[1000/1000]: train loss = 4.265e-06 | test_loss = 2.332e-06 | depth =  11.0 | lr = 1.0e-03 | fxt_pt_tol = 1.0e-06 | time =  0.7 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHSv2nSuo_1b"
      },
      "source": [
        "## Plot Convergence of Test Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sn9R47FgfHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "7824d6b8-b9cb-45be-92bd-8a9615792d10"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig1 = plt.figure(1)\n",
        "plt.plot(train_loss_hist, linewidth=3)\n",
        "plt.plot(test_loss_hist, linewidth=3)\n",
        "plt.yscale('log')\n",
        "plt.legend(['training loss', 'testing loss'], fontsize=15)\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.ylabel('Mean Squared Error', fontsize=15)\n",
        "plt.savefig('N_FPN_RPS_test_loss.pdf')\n",
        "\n",
        "\n",
        "filename = 'N_FPN_RPS_test_loss.csv'\n",
        "with open(filename, 'w') as f: \n",
        "  for epoch, loss in enumerate(test_loss_hist):     \n",
        "    f.write('%0.5e,%0.5e\\n' % (epoch + 1, loss)) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU7-Fzpzny8L"
      },
      "source": [
        "## Simulate Play of N-FPN Against Selfish Player\n",
        "\n",
        "Here we pit two players against each other. \n",
        "\n",
        "Case 1:\n",
        "* Nash Player 1 knows the context $d$ and payoff matrix $B(d)$\n",
        "* N-FPN Player 2 knows the context $d$ and historical observations (training data)\n",
        "\n",
        "\n",
        "Case 2:\n",
        "* Nash Player 1 knows the context $d$ and payoff matrix $B(d)$\n",
        "* Nash Player 2 knows the context $d$ and payoff matrix $B(d)$\n",
        "\n",
        "\n",
        "Each player's action profile is on the simplex. Each round of play is executed by sampling each player's decision (\"rock\", \"paper\", or \"scissors\") according to their action profile. We then plot the average reward of Player 2 over time. If the N-FPN is \"good\", then the average reward of each player will eventually converge to 0 (since rock-paper-scissors is a zero sum game)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqZVZEcbo-J0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7807c166-c346-4fc5-b2ce-68e857d8445a"
      },
      "source": [
        "def sample_distribution(prob_vec) -> action:\n",
        "    '''Sample from a discrete probability distribution\n",
        "\n",
        "       Create a cumulative distribution vector and sample a point p uniformly\n",
        "       from [0,1]. Then p will have a value between two of the cumulative\n",
        "       entries, which indicates the sample index to pick for the sampling.\n",
        "    '''\n",
        "    p_sample      = torch.rand(1) \n",
        "    dist_vec      = torch.cumsum(prob_vec, dim=0)\n",
        "    action_sample = torch.zeros(prob_vec.shape)\n",
        "    for idx, ref in enumerate(dist_vec):\n",
        "        if ref > p_sample: \n",
        "            action_sample[idx] = 1.0\n",
        "            return action_sample\n",
        "    print(\"Error: Unable to assign action\")\n",
        "\n",
        "num_games   = 500\n",
        "player_size = 3\n",
        "num_samples = 50\n",
        "rewards_nash_nfpn = torch.zeros(num_samples, num_games)\n",
        "rewards_nash_nash = torch.zeros(num_samples, num_games)\n",
        "rewards_nash_unif = torch.zeros(num_samples, num_games)\n",
        "x_uniform         = torch.tensor([1.0/3, 1.0/3, 1.0/3])\n",
        "\n",
        "for context in range(num_samples):\n",
        "    print(\"Playing Games for Context {:2d} of {:2d}\".format(context + 1, \n",
        "                                                            num_samples))\n",
        "    d_sample = sample_context(num_samples=1)\n",
        "    Bd       = create_payoff_matrix(d_sample)\n",
        "    x_nash   = get_nash_eq(d_sample) \n",
        "    x_nfpn   = model(d_sample)\n",
        "    for idx in range(num_games):\n",
        "        action_nash1 = sample_distribution(x_nash[0, :player_size])\n",
        "        action_nash1 = action_nash1.view(1, player_size, 1)\n",
        "        action_nash2 = sample_distribution(x_nash[0, player_size:])\n",
        "        action_nash2 = action_nash2.view(1, player_size, 1)       \n",
        "        action_nfpn  = sample_distribution(x_nfpn[0, player_size:])\n",
        "        action_nfpn  = action_nfpn.view(1, player_size, 1)\n",
        "        action_unif  = sample_distribution(x_uniform)\n",
        "        action_unif  = action_unif.view(1, player_size, 1)        \n",
        "        Bd_nfpn      = torch.bmm(Bd, action_nfpn)\n",
        "        Bd_nash2     = torch.bmm(Bd, action_nash2)\n",
        "        Bd_unif      = torch.bmm(Bd, action_unif)    \n",
        "        reward_nash_nfpn = torch.bmm(action_nash1.permute(0, 2, 1), Bd_nfpn)[0,0,0]\n",
        "        reward_nash_nash = torch.bmm(action_nash1.permute(0, 2, 1), Bd_nash2)[0,0,0]\n",
        "        reward_nash_unif = torch.bmm(action_nash1.permute(0, 2, 1), Bd_unif)[0,0,0]\n",
        "        rewards_nash_nfpn[context, idx] = (reward_nash_nfpn)\n",
        "        rewards_nash_nash[context, idx] = (reward_nash_nash)\n",
        "        rewards_nash_unif[context, idx] = (reward_nash_unif) \n",
        "\n",
        "lin_space    = torch.cumsum(torch.ones(rewards_nash_nfpn.shape), dim=1) \n",
        "nash_vs_nfpn = torch.mean(rewards_nash_nfpn ** 2, dim=0, keepdim=True) ** 0.5\n",
        "nash_vs_nfpn = torch.cumsum(nash_vs_nfpn, dim=1) / lin_space\n",
        "nash_vs_nash = torch.mean(rewards_nash_nash ** 2, dim=0, keepdim=True) ** 0.5\n",
        "nash_vs_nash = torch.cumsum(nash_vs_nash, dim=1) / lin_space\n",
        "nash_vs_unif = torch.mean(rewards_nash_unif ** 2, dim=0, keepdim=True) ** 0.5\n",
        "nash_vs_unif = torch.cumsum(nash_vs_unif, dim=1) / lin_space\n",
        "\n",
        "fig1 = plt.figure(1)\n",
        "plt.plot(nash_vs_unif[0,5:], '--', linewidth=2) \n",
        "plt.plot(nash_vs_nfpn[0,5:], linewidth=2)\n",
        "plt.plot(nash_vs_nash[0,5:],  '--', linewidth=2) \n",
        "plt.legend(['Nash vs Uniform', 'Nash vs NFPN', 'Nash vs Nash'], fontsize=15)\n",
        "plt.xlabel('Games Played', fontsize=15)\n",
        "plt.ylabel('Variance $y^k$', fontsize=15)\n",
        "plt.savefig('N_FPN_RPS_nash_reward.pdf') \n",
        "\n",
        "filename = 'N_FPN_RPS_nash_vs_nfpn.csv'\n",
        "with open(filename, 'w') as f: \n",
        "  for game, cost in enumerate(nash_vs_nfpn[0, :]):     \n",
        "    f.write('%0.5e,%0.5e\\n' % (game + 1, cost)) \n",
        "\n",
        "filename = 'N_FPN_RPS_nash_vs_nash.csv'\n",
        "with open(filename, 'w') as f: \n",
        "  for game, cost in enumerate(nash_vs_nash[0, :]):     \n",
        "    f.write('%0.5e,%0.5e\\n' % (game + 1, cost))    \n",
        "\n",
        "filename = 'N_FPN_RPS_nash_vs_unif.csv'\n",
        "with open(filename, 'w') as f: \n",
        "  for game, cost in enumerate(nash_vs_unif[0, :]):     \n",
        "    f.write('%0.5e,%0.5e\\n' % (game + 1, cost))       "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Playing Games for Context  1 of 50\n",
            "Playing Games for Context  2 of 50\n",
            "Playing Games for Context  3 of 50\n",
            "Playing Games for Context  4 of 50\n",
            "Playing Games for Context  5 of 50\n",
            "Playing Games for Context  6 of 50\n",
            "Playing Games for Context  7 of 50\n",
            "Playing Games for Context  8 of 50\n",
            "Playing Games for Context  9 of 50\n",
            "Playing Games for Context 10 of 50\n",
            "Playing Games for Context 11 of 50\n",
            "Playing Games for Context 12 of 50\n",
            "Playing Games for Context 13 of 50\n",
            "Playing Games for Context 14 of 50\n",
            "Playing Games for Context 15 of 50\n",
            "Playing Games for Context 16 of 50\n",
            "Playing Games for Context 17 of 50\n",
            "Playing Games for Context 18 of 50\n",
            "Playing Games for Context 19 of 50\n",
            "Playing Games for Context 20 of 50\n",
            "Playing Games for Context 21 of 50\n",
            "Playing Games for Context 22 of 50\n",
            "Playing Games for Context 23 of 50\n",
            "Playing Games for Context 24 of 50\n",
            "Playing Games for Context 25 of 50\n",
            "Playing Games for Context 26 of 50\n",
            "Playing Games for Context 27 of 50\n",
            "Playing Games for Context 28 of 50\n",
            "Playing Games for Context 29 of 50\n",
            "Playing Games for Context 30 of 50\n",
            "Playing Games for Context 31 of 50\n",
            "Playing Games for Context 32 of 50\n",
            "Playing Games for Context 33 of 50\n",
            "Playing Games for Context 34 of 50\n",
            "Playing Games for Context 35 of 50\n",
            "Playing Games for Context 36 of 50\n",
            "Playing Games for Context 37 of 50\n",
            "Playing Games for Context 38 of 50\n",
            "Playing Games for Context 39 of 50\n",
            "Playing Games for Context 40 of 50\n",
            "Playing Games for Context 41 of 50\n",
            "Playing Games for Context 42 of 50\n",
            "Playing Games for Context 43 of 50\n",
            "Playing Games for Context 44 of 50\n",
            "Playing Games for Context 45 of 50\n",
            "Playing Games for Context 46 of 50\n",
            "Playing Games for Context 47 of 50\n",
            "Playing Games for Context 48 of 50\n",
            "Playing Games for Context 49 of 50\n",
            "Playing Games for Context 50 of 50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}